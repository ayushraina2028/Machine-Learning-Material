{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_parquet('gun0_chunk_0.parquet', dtype_backend = 'pyarrow')[['X_jet','m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X_jet', 'm'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# set device to cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X = torch.tensor(df['X_jet'].values, dtype = torch.float32)\n",
    "y = torch.tensor(df['m'].values, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6000, 8, 125, 125]) torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4800, 8, 125, 125]) torch.Size([4800])\n",
      "torch.Size([1200, 8, 125, 125]) torch.Size([1200])\n"
     ]
    }
   ],
   "source": [
    "# Separating into training and test data\n",
    "testLen = 0.2*X.shape[0]\n",
    "X_train = X[:int(X.shape[0]-testLen)]\n",
    "y_train = y[:int(X.shape[0]-testLen)]\n",
    "\n",
    "X_test = X[int(X.shape[0]-testLen):]\n",
    "y_test = y[int(X.shape[0]-testLen):]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3840, 8, 125, 125]) torch.Size([3840])\n",
      "torch.Size([960, 8, 125, 125]) torch.Size([960])\n"
     ]
    }
   ],
   "source": [
    "# Separating into training and validation data\n",
    "valLen = 0.2*X_train.shape[0]\n",
    "\n",
    "X_valid = X_train[:int(valLen)]\n",
    "y_valid = y_train[:int(valLen)]\n",
    "\n",
    "X_train = X_train[int(valLen):]\n",
    "y_train = y_train[int(valLen):]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3840, 8, 125, 125]) torch.Size([960, 8, 125, 125]) torch.Size([1200, 8, 125, 125])\n",
      "torch.Size([3840]) torch.Size([960]) torch.Size([1200])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.permute(0,3,2,1)\n",
    "X_test = X_test.permute(0,3,2,1)\n",
    "X_valid = X_valid.permute(0,3,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3840, 125, 125, 8]) torch.Size([960, 125, 125, 8]) torch.Size([1200, 125, 125, 8])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, X_test.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the Train and Validation data\n",
    "X_train_mean = X_train.mean()\n",
    "X_train_std = X_train.std()\n",
    "\n",
    "X_train = (X_train - X_train_mean) / (X_train_std + 1e-6)\n",
    "X_valid = (X_valid - X_train_mean) / (X_train_std + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "trainSet = TensorDataset(X_train, y_train)\n",
    "validSet = TensorDataset(X_valid, y_valid)\n",
    "testSet = TensorDataset(X_test, y_test)\n",
    "\n",
    "X_train = None\n",
    "y_train = None\n",
    "X_valid = None\n",
    "\n",
    "batchSize = 32\n",
    "trainLoader = DataLoader(trainSet, batch_size = batchSize, shuffle = True)\n",
    "validLoader = DataLoader(validSet, batch_size = batchSize, shuffle = True)\n",
    "testLoader = DataLoader(testSet, batch_size = batchSize, shuffle = True)\n",
    "\n",
    "trainSet = None\n",
    "validSet = None\n",
    "testSet = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 125, 125, 8]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for i in trainLoader:\n",
    "    print(i[0].shape, i[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 125, 125]           1,168\n",
      "              ReLU-2         [-1, 16, 125, 125]               0\n",
      "       BatchNorm2d-3         [-1, 16, 125, 125]              32\n",
      "            Conv2d-4         [-1, 16, 125, 125]           2,320\n",
      "              ReLU-5         [-1, 16, 125, 125]               0\n",
      "       BatchNorm2d-6         [-1, 16, 125, 125]              32\n",
      "         MaxPool2d-7           [-1, 16, 41, 41]               0\n",
      "           Dropout-8           [-1, 16, 41, 41]               0\n",
      "            Conv2d-9           [-1, 32, 41, 41]           4,640\n",
      "             ReLU-10           [-1, 32, 41, 41]               0\n",
      "      BatchNorm2d-11           [-1, 32, 41, 41]              64\n",
      "           Conv2d-12           [-1, 32, 41, 41]           9,248\n",
      "             ReLU-13           [-1, 32, 41, 41]               0\n",
      "      BatchNorm2d-14           [-1, 32, 41, 41]              64\n",
      "        MaxPool2d-15           [-1, 32, 13, 13]               0\n",
      "          Dropout-16           [-1, 32, 13, 13]               0\n",
      "           Conv2d-17           [-1, 64, 13, 13]          18,496\n",
      "             ReLU-18           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-19           [-1, 64, 13, 13]             128\n",
      "           Conv2d-20           [-1, 64, 13, 13]          36,928\n",
      "             ReLU-21           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-22           [-1, 64, 13, 13]             128\n",
      "        MaxPool2d-23             [-1, 64, 4, 4]               0\n",
      "          Dropout-24             [-1, 64, 4, 4]               0\n",
      "           Linear-25                    [-1, 1]           1,025\n",
      "================================================================\n",
      "Total params: 74,273\n",
      "Trainable params: 74,273\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.48\n",
      "Forward/backward pass size (MB): 14.91\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 15.67\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, base_hidden_units, weight_decay):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.base_hidden_units = base_hidden_units\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=8, out_channels=base_hidden_units, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm1 = nn.BatchNorm2d(base_hidden_units)\n",
    "\n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=base_hidden_units, out_channels=base_hidden_units, kernel_size=3, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(base_hidden_units)\n",
    "\n",
    "        # Pool + Dropout\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "\n",
    "        # Convolutional Layer 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=base_hidden_units, out_channels=base_hidden_units*2, kernel_size=3, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(base_hidden_units*2)\n",
    "\n",
    "        # Convolutional Layer 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=base_hidden_units*2, out_channels=base_hidden_units*2, kernel_size=3, padding=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(base_hidden_units*2)\n",
    "\n",
    "        # Pool + Dropout\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    "        # Convolutional Layer 5\n",
    "        self.conv5 = nn.Conv2d(in_channels=base_hidden_units*2, out_channels=base_hidden_units*4, kernel_size=3, padding=1)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(base_hidden_units*4)\n",
    "\n",
    "        # Convolutional Layer 6\n",
    "        self.conv6 = nn.Conv2d(in_channels=base_hidden_units*4, out_channels=base_hidden_units*4, kernel_size=3, padding=1)\n",
    "        self.batchnorm6 = nn.BatchNorm2d(base_hidden_units*4)\n",
    "\n",
    "        # Pool + Dropout\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "\n",
    "        # Fully Connected Layer 1\n",
    "        self.fc = nn.Linear(base_hidden_units*4 * 4 * 4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm2(x)\n",
    "\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm4(x)\n",
    "\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm5(x)\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm6(x)\n",
    "\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = x.view(-1, self.base_hidden_units*4 * 4 * 4)  # Flatten\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "base_hidden_units = 16\n",
    "weight_decay = 2\n",
    "model = CustomCNN(base_hidden_units, weight_decay).to(device)\n",
    "\n",
    "# Print model summary\n",
    "summary(model, input_size=(8, 125, 125))  # Assuming input image size is 32x32x3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()  # use mean squared error loss\n",
    "#use sgd optimizer\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=0.00002, weight_decay=weight_decay, momentum=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (conv5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Loop\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 125, 125, 8])\n"
     ]
    }
   ],
   "source": [
    "for image,label in trainLoader:\n",
    "    print(image.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoss = []\n",
    "trainAccuracy = []\n",
    "\n",
    "validLoss = []\n",
    "validAccuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322.2349548339844\n",
      "Epoch [1/50], Batch 1/120, Train Loss: 322.2350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6351/114619117.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  arr = [torch.tensor(i).permute(2, 0, 1) for i in images]\n",
      "/tmp/ipykernel_6351/114619117.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = criterion(outputs.squeeze(), torch.tensor(labels, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623.5928649902344\n",
      "Epoch [1/50], Batch 2/120, Train Loss: 301.3579\n",
      "892.7886657714844\n",
      "Epoch [1/50], Batch 3/120, Train Loss: 269.1958\n",
      "1190.5266418457031\n",
      "Epoch [1/50], Batch 4/120, Train Loss: 297.7380\n",
      "1511.0756225585938\n",
      "Epoch [1/50], Batch 5/120, Train Loss: 320.5490\n",
      "1768.7218322753906\n",
      "Epoch [1/50], Batch 6/120, Train Loss: 257.6462\n",
      "2047.9097595214844\n",
      "Epoch [1/50], Batch 7/120, Train Loss: 279.1879\n",
      "2325.080841064453\n",
      "Epoch [1/50], Batch 8/120, Train Loss: 277.1711\n",
      "2617.6341247558594\n",
      "Epoch [1/50], Batch 9/120, Train Loss: 292.5533\n",
      "2910.2870178222656\n",
      "Epoch [1/50], Batch 10/120, Train Loss: 292.6529\n",
      "3219.6951293945312\n",
      "Epoch [1/50], Batch 11/120, Train Loss: 309.4081\n",
      "3508.31787109375\n",
      "Epoch [1/50], Batch 12/120, Train Loss: 288.6227\n",
      "3792.9236450195312\n",
      "Epoch [1/50], Batch 13/120, Train Loss: 284.6058\n",
      "4095.08642578125\n",
      "Epoch [1/50], Batch 14/120, Train Loss: 302.1628\n",
      "4360.4202880859375\n",
      "Epoch [1/50], Batch 15/120, Train Loss: 265.3339\n",
      "4667.4547119140625\n",
      "Epoch [1/50], Batch 16/120, Train Loss: 307.0344\n",
      "4956.336364746094\n",
      "Epoch [1/50], Batch 17/120, Train Loss: 288.8817\n",
      "5224.384429931641\n",
      "Epoch [1/50], Batch 18/120, Train Loss: 268.0481\n",
      "5557.163970947266\n",
      "Epoch [1/50], Batch 19/120, Train Loss: 332.7795\n",
      "5893.8642578125\n",
      "Epoch [1/50], Batch 20/120, Train Loss: 336.7003\n",
      "6196.342315673828\n",
      "Epoch [1/50], Batch 21/120, Train Loss: 302.4781\n",
      "6472.430877685547\n",
      "Epoch [1/50], Batch 22/120, Train Loss: 276.0886\n",
      "6808.646667480469\n",
      "Epoch [1/50], Batch 23/120, Train Loss: 336.2158\n",
      "7123.43896484375\n",
      "Epoch [1/50], Batch 24/120, Train Loss: 314.7923\n",
      "7435.967590332031\n",
      "Epoch [1/50], Batch 25/120, Train Loss: 312.5286\n",
      "7737.6146240234375\n",
      "Epoch [1/50], Batch 26/120, Train Loss: 301.6470\n",
      "8047.748229980469\n",
      "Epoch [1/50], Batch 27/120, Train Loss: 310.1336\n",
      "8322.156158447266\n",
      "Epoch [1/50], Batch 28/120, Train Loss: 274.4079\n",
      "8606.403900146484\n",
      "Epoch [1/50], Batch 29/120, Train Loss: 284.2477\n",
      "8848.584686279297\n",
      "Epoch [1/50], Batch 30/120, Train Loss: 242.1808\n",
      "9154.037872314453\n",
      "Epoch [1/50], Batch 31/120, Train Loss: 305.4532\n",
      "9457.921112060547\n",
      "Epoch [1/50], Batch 32/120, Train Loss: 303.8832\n",
      "9783.268096923828\n",
      "Epoch [1/50], Batch 33/120, Train Loss: 325.3470\n",
      "10073.282257080078\n",
      "Epoch [1/50], Batch 34/120, Train Loss: 290.0142\n",
      "10381.25439453125\n",
      "Epoch [1/50], Batch 35/120, Train Loss: 307.9721\n",
      "10696.591400146484\n",
      "Epoch [1/50], Batch 36/120, Train Loss: 315.3370\n",
      "11012.212432861328\n",
      "Epoch [1/50], Batch 37/120, Train Loss: 315.6210\n",
      "11259.002502441406\n",
      "Epoch [1/50], Batch 38/120, Train Loss: 246.7901\n",
      "11518.957580566406\n",
      "Epoch [1/50], Batch 39/120, Train Loss: 259.9551\n",
      "11818.29150390625\n",
      "Epoch [1/50], Batch 40/120, Train Loss: 299.3339\n",
      "12109.994567871094\n",
      "Epoch [1/50], Batch 41/120, Train Loss: 291.7031\n",
      "12413.706359863281\n",
      "Epoch [1/50], Batch 42/120, Train Loss: 303.7118\n",
      "12716.010620117188\n",
      "Epoch [1/50], Batch 43/120, Train Loss: 302.3043\n",
      "13034.719329833984\n",
      "Epoch [1/50], Batch 44/120, Train Loss: 318.7087\n",
      "13331.79232788086\n",
      "Epoch [1/50], Batch 45/120, Train Loss: 297.0730\n",
      "13587.260070800781\n",
      "Epoch [1/50], Batch 46/120, Train Loss: 255.4677\n",
      "13866.201446533203\n",
      "Epoch [1/50], Batch 47/120, Train Loss: 278.9414\n",
      "14179.300079345703\n",
      "Epoch [1/50], Batch 48/120, Train Loss: 313.0986\n",
      "14494.28256225586\n",
      "Epoch [1/50], Batch 49/120, Train Loss: 314.9825\n",
      "14752.273529052734\n",
      "Epoch [1/50], Batch 50/120, Train Loss: 257.9910\n",
      "15012.10952758789\n",
      "Epoch [1/50], Batch 51/120, Train Loss: 259.8360\n",
      "15291.608001708984\n",
      "Epoch [1/50], Batch 52/120, Train Loss: 279.4985\n",
      "15573.37158203125\n",
      "Epoch [1/50], Batch 53/120, Train Loss: 281.7636\n",
      "15836.602661132812\n",
      "Epoch [1/50], Batch 54/120, Train Loss: 263.2311\n",
      "16106.361236572266\n",
      "Epoch [1/50], Batch 55/120, Train Loss: 269.7586\n",
      "16388.595947265625\n",
      "Epoch [1/50], Batch 56/120, Train Loss: 282.2347\n",
      "16638.355499267578\n",
      "Epoch [1/50], Batch 57/120, Train Loss: 249.7596\n",
      "16942.646850585938\n",
      "Epoch [1/50], Batch 58/120, Train Loss: 304.2914\n",
      "17200.715911865234\n",
      "Epoch [1/50], Batch 59/120, Train Loss: 258.0691\n",
      "17527.04507446289\n",
      "Epoch [1/50], Batch 60/120, Train Loss: 326.3292\n",
      "17800.48602294922\n",
      "Epoch [1/50], Batch 61/120, Train Loss: 273.4409\n",
      "18142.8125\n",
      "Epoch [1/50], Batch 62/120, Train Loss: 342.3265\n",
      "18458.545776367188\n",
      "Epoch [1/50], Batch 63/120, Train Loss: 315.7333\n",
      "18719.229125976562\n",
      "Epoch [1/50], Batch 64/120, Train Loss: 260.6833\n",
      "19044.43084716797\n",
      "Epoch [1/50], Batch 65/120, Train Loss: 325.2017\n",
      "19341.482696533203\n",
      "Epoch [1/50], Batch 66/120, Train Loss: 297.0518\n",
      "19620.187103271484\n",
      "Epoch [1/50], Batch 67/120, Train Loss: 278.7044\n",
      "19908.41763305664\n",
      "Epoch [1/50], Batch 68/120, Train Loss: 288.2305\n",
      "20161.28335571289\n",
      "Epoch [1/50], Batch 69/120, Train Loss: 252.8657\n",
      "20445.64175415039\n",
      "Epoch [1/50], Batch 70/120, Train Loss: 284.3584\n",
      "20722.049346923828\n",
      "Epoch [1/50], Batch 71/120, Train Loss: 276.4076\n",
      "21000.666625976562\n",
      "Epoch [1/50], Batch 72/120, Train Loss: 278.6173\n",
      "21295.529541015625\n",
      "Epoch [1/50], Batch 73/120, Train Loss: 294.8629\n",
      "21601.375396728516\n",
      "Epoch [1/50], Batch 74/120, Train Loss: 305.8459\n",
      "21904.262237548828\n",
      "Epoch [1/50], Batch 75/120, Train Loss: 302.8868\n",
      "22189.240753173828\n",
      "Epoch [1/50], Batch 76/120, Train Loss: 284.9785\n",
      "22516.161499023438\n",
      "Epoch [1/50], Batch 77/120, Train Loss: 326.9207\n",
      "22781.340057373047\n",
      "Epoch [1/50], Batch 78/120, Train Loss: 265.1786\n",
      "23054.486114501953\n",
      "Epoch [1/50], Batch 79/120, Train Loss: 273.1461\n",
      "23318.130828857422\n",
      "Epoch [1/50], Batch 80/120, Train Loss: 263.6447\n",
      "23602.035400390625\n",
      "Epoch [1/50], Batch 81/120, Train Loss: 283.9046\n",
      "23876.745819091797\n",
      "Epoch [1/50], Batch 82/120, Train Loss: 274.7104\n",
      "24161.806365966797\n",
      "Epoch [1/50], Batch 83/120, Train Loss: 285.0605\n",
      "24439.934844970703\n",
      "Epoch [1/50], Batch 84/120, Train Loss: 278.1285\n",
      "24749.29898071289\n",
      "Epoch [1/50], Batch 85/120, Train Loss: 309.3641\n",
      "25033.144500732422\n",
      "Epoch [1/50], Batch 86/120, Train Loss: 283.8455\n",
      "25309.99887084961\n",
      "Epoch [1/50], Batch 87/120, Train Loss: 276.8544\n",
      "25593.09066772461\n",
      "Epoch [1/50], Batch 88/120, Train Loss: 283.0918\n",
      "25931.105010986328\n",
      "Epoch [1/50], Batch 89/120, Train Loss: 338.0143\n",
      "26222.822326660156\n",
      "Epoch [1/50], Batch 90/120, Train Loss: 291.7173\n",
      "26507.74658203125\n",
      "Epoch [1/50], Batch 91/120, Train Loss: 284.9243\n",
      "26794.704467773438\n",
      "Epoch [1/50], Batch 92/120, Train Loss: 286.9579\n",
      "27058.71954345703\n",
      "Epoch [1/50], Batch 93/120, Train Loss: 264.0151\n",
      "27347.391479492188\n",
      "Epoch [1/50], Batch 94/120, Train Loss: 288.6719\n",
      "27610.91961669922\n",
      "Epoch [1/50], Batch 95/120, Train Loss: 263.5281\n",
      "27878.81268310547\n",
      "Epoch [1/50], Batch 96/120, Train Loss: 267.8931\n",
      "28122.451736450195\n",
      "Epoch [1/50], Batch 97/120, Train Loss: 243.6391\n",
      "28377.44825744629\n",
      "Epoch [1/50], Batch 98/120, Train Loss: 254.9965\n",
      "28668.57179260254\n",
      "Epoch [1/50], Batch 99/120, Train Loss: 291.1235\n",
      "28944.751174926758\n",
      "Epoch [1/50], Batch 100/120, Train Loss: 276.1794\n",
      "29203.809036254883\n",
      "Epoch [1/50], Batch 101/120, Train Loss: 259.0579\n",
      "29472.57160949707\n",
      "Epoch [1/50], Batch 102/120, Train Loss: 268.7626\n",
      "29776.830673217773\n",
      "Epoch [1/50], Batch 103/120, Train Loss: 304.2591\n",
      "30055.301559448242\n",
      "Epoch [1/50], Batch 104/120, Train Loss: 278.4709\n",
      "30363.538497924805\n",
      "Epoch [1/50], Batch 105/120, Train Loss: 308.2369\n",
      "30649.84422302246\n",
      "Epoch [1/50], Batch 106/120, Train Loss: 286.3057\n",
      "30919.613967895508\n",
      "Epoch [1/50], Batch 107/120, Train Loss: 269.7697\n",
      "31160.50242614746\n",
      "Epoch [1/50], Batch 108/120, Train Loss: 240.8885\n",
      "31437.184616088867\n",
      "Epoch [1/50], Batch 109/120, Train Loss: 276.6822\n",
      "31721.69206237793\n",
      "Epoch [1/50], Batch 110/120, Train Loss: 284.5074\n",
      "31977.769790649414\n",
      "Epoch [1/50], Batch 111/120, Train Loss: 256.0777\n",
      "32260.048782348633\n",
      "Epoch [1/50], Batch 112/120, Train Loss: 282.2790\n",
      "32511.4141998291\n",
      "Epoch [1/50], Batch 113/120, Train Loss: 251.3654\n",
      "32820.302322387695\n",
      "Epoch [1/50], Batch 114/120, Train Loss: 308.8881\n",
      "33093.118392944336\n",
      "Epoch [1/50], Batch 115/120, Train Loss: 272.8161\n",
      "33376.66716003418\n",
      "Epoch [1/50], Batch 116/120, Train Loss: 283.5488\n",
      "33628.472091674805\n",
      "Epoch [1/50], Batch 117/120, Train Loss: 251.8049\n",
      "33917.88856506348\n",
      "Epoch [1/50], Batch 118/120, Train Loss: 289.4165\n",
      "34208.18827819824\n",
      "Epoch [1/50], Batch 119/120, Train Loss: 290.2997\n",
      "34480.80632019043\n",
      "Epoch [1/50], Batch 120/120, Train Loss: 272.6180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6351/114619117.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  arr = [torch.tensor(i).permute(2, 0, 1) for i in images]\n",
      "/home/ayushraina/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 287.3401, Validation Loss: 284.4569\n",
      "263.9321594238281\n",
      "Epoch [2/50], Batch 1/120, Train Loss: 263.9322\n",
      "557.2290344238281\n",
      "Epoch [2/50], Batch 2/120, Train Loss: 293.2969\n",
      "788.4902038574219\n",
      "Epoch [2/50], Batch 3/120, Train Loss: 231.2612\n",
      "1072.6208190917969\n",
      "Epoch [2/50], Batch 4/120, Train Loss: 284.1306\n",
      "1346.7705688476562\n",
      "Epoch [2/50], Batch 5/120, Train Loss: 274.1497\n",
      "1667.2386779785156\n",
      "Epoch [2/50], Batch 6/120, Train Loss: 320.4681\n",
      "1968.9349060058594\n",
      "Epoch [2/50], Batch 7/120, Train Loss: 301.6962\n",
      "2253.048797607422\n",
      "Epoch [2/50], Batch 8/120, Train Loss: 284.1139\n",
      "2541.2828063964844\n",
      "Epoch [2/50], Batch 9/120, Train Loss: 288.2340\n",
      "2834.1403198242188\n",
      "Epoch [2/50], Batch 10/120, Train Loss: 292.8575\n",
      "3109.5439453125\n",
      "Epoch [2/50], Batch 11/120, Train Loss: 275.4036\n",
      "3368.6038208007812\n",
      "Epoch [2/50], Batch 12/120, Train Loss: 259.0599\n",
      "3633.6786499023438\n",
      "Epoch [2/50], Batch 13/120, Train Loss: 265.0748\n",
      "3924.7630615234375\n",
      "Epoch [2/50], Batch 14/120, Train Loss: 291.0844\n",
      "4242.3807373046875\n",
      "Epoch [2/50], Batch 15/120, Train Loss: 317.6177\n",
      "4527.726654052734\n",
      "Epoch [2/50], Batch 16/120, Train Loss: 285.3459\n",
      "4786.570526123047\n",
      "Epoch [2/50], Batch 17/120, Train Loss: 258.8439\n",
      "5055.5772705078125\n",
      "Epoch [2/50], Batch 18/120, Train Loss: 269.0067\n",
      "5328.703552246094\n",
      "Epoch [2/50], Batch 19/120, Train Loss: 273.1263\n",
      "5582.2337646484375\n",
      "Epoch [2/50], Batch 20/120, Train Loss: 253.5302\n",
      "5872.707824707031\n",
      "Epoch [2/50], Batch 21/120, Train Loss: 290.4741\n",
      "6150.320770263672\n",
      "Epoch [2/50], Batch 22/120, Train Loss: 277.6129\n",
      "6416.915924072266\n",
      "Epoch [2/50], Batch 23/120, Train Loss: 266.5952\n",
      "6682.2857666015625\n",
      "Epoch [2/50], Batch 24/120, Train Loss: 265.3698\n",
      "6936.292938232422\n",
      "Epoch [2/50], Batch 25/120, Train Loss: 254.0072\n",
      "7182.637756347656\n",
      "Epoch [2/50], Batch 26/120, Train Loss: 246.3448\n",
      "7443.311676025391\n",
      "Epoch [2/50], Batch 27/120, Train Loss: 260.6739\n",
      "7729.256500244141\n",
      "Epoch [2/50], Batch 28/120, Train Loss: 285.9448\n",
      "8013.441436767578\n",
      "Epoch [2/50], Batch 29/120, Train Loss: 284.1849\n",
      "8288.514129638672\n",
      "Epoch [2/50], Batch 30/120, Train Loss: 275.0727\n",
      "8590.308837890625\n",
      "Epoch [2/50], Batch 31/120, Train Loss: 301.7947\n",
      "8846.475219726562\n",
      "Epoch [2/50], Batch 32/120, Train Loss: 256.1664\n",
      "9159.372863769531\n",
      "Epoch [2/50], Batch 33/120, Train Loss: 312.8976\n",
      "9442.636779785156\n",
      "Epoch [2/50], Batch 34/120, Train Loss: 283.2639\n",
      "9733.553985595703\n",
      "Epoch [2/50], Batch 35/120, Train Loss: 290.9172\n",
      "10031.346710205078\n",
      "Epoch [2/50], Batch 36/120, Train Loss: 297.7927\n",
      "10320.391143798828\n",
      "Epoch [2/50], Batch 37/120, Train Loss: 289.0444\n",
      "10599.738372802734\n",
      "Epoch [2/50], Batch 38/120, Train Loss: 279.3472\n",
      "10898.807525634766\n",
      "Epoch [2/50], Batch 39/120, Train Loss: 299.0692\n",
      "11170.838562011719\n",
      "Epoch [2/50], Batch 40/120, Train Loss: 272.0310\n",
      "11481.174194335938\n",
      "Epoch [2/50], Batch 41/120, Train Loss: 310.3356\n",
      "11814.665740966797\n",
      "Epoch [2/50], Batch 42/120, Train Loss: 333.4915\n",
      "12118.403015136719\n",
      "Epoch [2/50], Batch 43/120, Train Loss: 303.7373\n",
      "12367.95913696289\n",
      "Epoch [2/50], Batch 44/120, Train Loss: 249.5561\n",
      "12665.042572021484\n",
      "Epoch [2/50], Batch 45/120, Train Loss: 297.0834\n",
      "12934.1455078125\n",
      "Epoch [2/50], Batch 46/120, Train Loss: 269.1029\n",
      "13266.329895019531\n",
      "Epoch [2/50], Batch 47/120, Train Loss: 332.1844\n",
      "13526.305236816406\n",
      "Epoch [2/50], Batch 48/120, Train Loss: 259.9753\n",
      "13800.4931640625\n",
      "Epoch [2/50], Batch 49/120, Train Loss: 274.1879\n",
      "14075.048828125\n",
      "Epoch [2/50], Batch 50/120, Train Loss: 274.5557\n",
      "14367.700958251953\n",
      "Epoch [2/50], Batch 51/120, Train Loss: 292.6521\n",
      "14631.845611572266\n",
      "Epoch [2/50], Batch 52/120, Train Loss: 264.1447\n",
      "14914.024139404297\n",
      "Epoch [2/50], Batch 53/120, Train Loss: 282.1785\n",
      "15189.072998046875\n",
      "Epoch [2/50], Batch 54/120, Train Loss: 275.0489\n",
      "15467.589050292969\n",
      "Epoch [2/50], Batch 55/120, Train Loss: 278.5161\n",
      "15712.206756591797\n",
      "Epoch [2/50], Batch 56/120, Train Loss: 244.6177\n",
      "15982.12631225586\n",
      "Epoch [2/50], Batch 57/120, Train Loss: 269.9196\n",
      "16268.89926147461\n",
      "Epoch [2/50], Batch 58/120, Train Loss: 286.7729\n",
      "16532.495208740234\n",
      "Epoch [2/50], Batch 59/120, Train Loss: 263.5959\n",
      "16764.659393310547\n",
      "Epoch [2/50], Batch 60/120, Train Loss: 232.1642\n",
      "16993.36683654785\n",
      "Epoch [2/50], Batch 61/120, Train Loss: 228.7074\n",
      "17271.903762817383\n",
      "Epoch [2/50], Batch 62/120, Train Loss: 278.5369\n",
      "17552.703536987305\n",
      "Epoch [2/50], Batch 63/120, Train Loss: 280.7998\n",
      "17859.37355041504\n",
      "Epoch [2/50], Batch 64/120, Train Loss: 306.6700\n",
      "18069.875595092773\n",
      "Epoch [2/50], Batch 65/120, Train Loss: 210.5020\n",
      "18320.2716217041\n",
      "Epoch [2/50], Batch 66/120, Train Loss: 250.3960\n",
      "18563.996459960938\n",
      "Epoch [2/50], Batch 67/120, Train Loss: 243.7248\n",
      "18804.94564819336\n",
      "Epoch [2/50], Batch 68/120, Train Loss: 240.9492\n",
      "19057.56007385254\n",
      "Epoch [2/50], Batch 69/120, Train Loss: 252.6144\n",
      "19317.18049621582\n",
      "Epoch [2/50], Batch 70/120, Train Loss: 259.6204\n",
      "19572.723175048828\n",
      "Epoch [2/50], Batch 71/120, Train Loss: 255.5427\n",
      "19837.050048828125\n",
      "Epoch [2/50], Batch 72/120, Train Loss: 264.3269\n",
      "20113.872344970703\n",
      "Epoch [2/50], Batch 73/120, Train Loss: 276.8223\n",
      "20408.24496459961\n",
      "Epoch [2/50], Batch 74/120, Train Loss: 294.3726\n",
      "20670.10678100586\n",
      "Epoch [2/50], Batch 75/120, Train Loss: 261.8618\n",
      "20951.643035888672\n",
      "Epoch [2/50], Batch 76/120, Train Loss: 281.5363\n",
      "21211.551177978516\n",
      "Epoch [2/50], Batch 77/120, Train Loss: 259.9081\n",
      "21488.055145263672\n",
      "Epoch [2/50], Batch 78/120, Train Loss: 276.5040\n",
      "21784.000457763672\n",
      "Epoch [2/50], Batch 79/120, Train Loss: 295.9453\n",
      "22037.375610351562\n",
      "Epoch [2/50], Batch 80/120, Train Loss: 253.3752\n",
      "22319.694946289062\n",
      "Epoch [2/50], Batch 81/120, Train Loss: 282.3193\n",
      "22622.06381225586\n",
      "Epoch [2/50], Batch 82/120, Train Loss: 302.3689\n",
      "22913.143951416016\n",
      "Epoch [2/50], Batch 83/120, Train Loss: 291.0801\n",
      "23210.47589111328\n",
      "Epoch [2/50], Batch 84/120, Train Loss: 297.3319\n",
      "23486.819091796875\n",
      "Epoch [2/50], Batch 85/120, Train Loss: 276.3432\n",
      "23781.652770996094\n",
      "Epoch [2/50], Batch 86/120, Train Loss: 294.8337\n",
      "24066.171447753906\n",
      "Epoch [2/50], Batch 87/120, Train Loss: 284.5187\n",
      "24346.730682373047\n",
      "Epoch [2/50], Batch 88/120, Train Loss: 280.5592\n",
      "24580.990203857422\n",
      "Epoch [2/50], Batch 89/120, Train Loss: 234.2595\n",
      "24898.477172851562\n",
      "Epoch [2/50], Batch 90/120, Train Loss: 317.4870\n",
      "25194.089141845703\n",
      "Epoch [2/50], Batch 91/120, Train Loss: 295.6120\n",
      "25487.90444946289\n",
      "Epoch [2/50], Batch 92/120, Train Loss: 293.8153\n",
      "25746.49380493164\n",
      "Epoch [2/50], Batch 93/120, Train Loss: 258.5894\n",
      "26025.996856689453\n",
      "Epoch [2/50], Batch 94/120, Train Loss: 279.5031\n",
      "26332.84994506836\n",
      "Epoch [2/50], Batch 95/120, Train Loss: 306.8531\n",
      "26598.755981445312\n",
      "Epoch [2/50], Batch 96/120, Train Loss: 265.9060\n",
      "26869.20135498047\n",
      "Epoch [2/50], Batch 97/120, Train Loss: 270.4454\n",
      "27143.06475830078\n",
      "Epoch [2/50], Batch 98/120, Train Loss: 273.8634\n",
      "27385.535110473633\n",
      "Epoch [2/50], Batch 99/120, Train Loss: 242.4704\n",
      "27633.569580078125\n",
      "Epoch [2/50], Batch 100/120, Train Loss: 248.0345\n",
      "27923.310028076172\n",
      "Epoch [2/50], Batch 101/120, Train Loss: 289.7404\n",
      "28194.564025878906\n",
      "Epoch [2/50], Batch 102/120, Train Loss: 271.2540\n",
      "28470.82891845703\n",
      "Epoch [2/50], Batch 103/120, Train Loss: 276.2649\n",
      "28737.846252441406\n",
      "Epoch [2/50], Batch 104/120, Train Loss: 267.0173\n",
      "29015.710205078125\n",
      "Epoch [2/50], Batch 105/120, Train Loss: 277.8640\n",
      "29314.827850341797\n",
      "Epoch [2/50], Batch 106/120, Train Loss: 299.1176\n",
      "29597.236846923828\n",
      "Epoch [2/50], Batch 107/120, Train Loss: 282.4090\n",
      "29875.960327148438\n",
      "Epoch [2/50], Batch 108/120, Train Loss: 278.7235\n",
      "30132.776824951172\n",
      "Epoch [2/50], Batch 109/120, Train Loss: 256.8165\n",
      "30416.019073486328\n",
      "Epoch [2/50], Batch 110/120, Train Loss: 283.2422\n",
      "30717.691436767578\n",
      "Epoch [2/50], Batch 111/120, Train Loss: 301.6724\n",
      "31022.938446044922\n",
      "Epoch [2/50], Batch 112/120, Train Loss: 305.2470\n",
      "31269.597595214844\n",
      "Epoch [2/50], Batch 113/120, Train Loss: 246.6591\n",
      "31567.038330078125\n",
      "Epoch [2/50], Batch 114/120, Train Loss: 297.4407\n",
      "31836.2890625\n",
      "Epoch [2/50], Batch 115/120, Train Loss: 269.2507\n",
      "32116.37744140625\n",
      "Epoch [2/50], Batch 116/120, Train Loss: 280.0884\n",
      "32392.80795288086\n",
      "Epoch [2/50], Batch 117/120, Train Loss: 276.4305\n",
      "32654.669555664062\n",
      "Epoch [2/50], Batch 118/120, Train Loss: 261.8616\n",
      "32909.71789550781\n",
      "Epoch [2/50], Batch 119/120, Train Loss: 255.0483\n",
      "33154.398376464844\n",
      "Epoch [2/50], Batch 120/120, Train Loss: 244.6805\n",
      "Epoch [2/50], Train Loss: 276.2867, Validation Loss: 272.6125\n",
      "285.4637145996094\n",
      "Epoch [3/50], Batch 1/120, Train Loss: 285.4637\n",
      "517.4783477783203\n",
      "Epoch [3/50], Batch 2/120, Train Loss: 232.0146\n",
      "770.0143280029297\n",
      "Epoch [3/50], Batch 3/120, Train Loss: 252.5360\n",
      "1036.8189544677734\n",
      "Epoch [3/50], Batch 4/120, Train Loss: 266.8046\n",
      "1301.248275756836\n",
      "Epoch [3/50], Batch 5/120, Train Loss: 264.4293\n",
      "1550.0811920166016\n",
      "Epoch [3/50], Batch 6/120, Train Loss: 248.8329\n",
      "1787.1999969482422\n",
      "Epoch [3/50], Batch 7/120, Train Loss: 237.1188\n",
      "2073.715866088867\n",
      "Epoch [3/50], Batch 8/120, Train Loss: 286.5159\n",
      "2316.6548614501953\n",
      "Epoch [3/50], Batch 9/120, Train Loss: 242.9390\n",
      "2589.039749145508\n",
      "Epoch [3/50], Batch 10/120, Train Loss: 272.3849\n",
      "2843.3751373291016\n",
      "Epoch [3/50], Batch 11/120, Train Loss: 254.3354\n",
      "3104.548599243164\n",
      "Epoch [3/50], Batch 12/120, Train Loss: 261.1735\n",
      "3371.5401763916016\n",
      "Epoch [3/50], Batch 13/120, Train Loss: 266.9916\n",
      "3635.7003021240234\n",
      "Epoch [3/50], Batch 14/120, Train Loss: 264.1601\n",
      "3939.0858306884766\n",
      "Epoch [3/50], Batch 15/120, Train Loss: 303.3855\n",
      "4195.264938354492\n",
      "Epoch [3/50], Batch 16/120, Train Loss: 256.1791\n",
      "4426.73551940918\n",
      "Epoch [3/50], Batch 17/120, Train Loss: 231.4706\n",
      "4687.091049194336\n",
      "Epoch [3/50], Batch 18/120, Train Loss: 260.3555\n",
      "4935.656387329102\n",
      "Epoch [3/50], Batch 19/120, Train Loss: 248.5653\n",
      "5214.030654907227\n",
      "Epoch [3/50], Batch 20/120, Train Loss: 278.3743\n",
      "5451.241836547852\n",
      "Epoch [3/50], Batch 21/120, Train Loss: 237.2112\n",
      "5729.61833190918\n",
      "Epoch [3/50], Batch 22/120, Train Loss: 278.3765\n",
      "5990.567581176758\n",
      "Epoch [3/50], Batch 23/120, Train Loss: 260.9492\n",
      "6256.190536499023\n",
      "Epoch [3/50], Batch 24/120, Train Loss: 265.6230\n",
      "6553.633377075195\n",
      "Epoch [3/50], Batch 25/120, Train Loss: 297.4428\n",
      "6847.682266235352\n",
      "Epoch [3/50], Batch 26/120, Train Loss: 294.0489\n",
      "7148.747299194336\n",
      "Epoch [3/50], Batch 27/120, Train Loss: 301.0650\n",
      "7419.428329467773\n",
      "Epoch [3/50], Batch 28/120, Train Loss: 270.6810\n",
      "7673.798477172852\n",
      "Epoch [3/50], Batch 29/120, Train Loss: 254.3701\n",
      "7940.327896118164\n",
      "Epoch [3/50], Batch 30/120, Train Loss: 266.5294\n",
      "8239.582015991211\n",
      "Epoch [3/50], Batch 31/120, Train Loss: 299.2541\n",
      "8486.816757202148\n",
      "Epoch [3/50], Batch 32/120, Train Loss: 247.2347\n",
      "8775.527694702148\n",
      "Epoch [3/50], Batch 33/120, Train Loss: 288.7109\n",
      "9015.314208984375\n",
      "Epoch [3/50], Batch 34/120, Train Loss: 239.7865\n",
      "9280.367004394531\n",
      "Epoch [3/50], Batch 35/120, Train Loss: 265.0528\n",
      "9535.294494628906\n",
      "Epoch [3/50], Batch 36/120, Train Loss: 254.9275\n",
      "9767.333679199219\n",
      "Epoch [3/50], Batch 37/120, Train Loss: 232.0392\n",
      "9994.086120605469\n",
      "Epoch [3/50], Batch 38/120, Train Loss: 226.7524\n",
      "10268.290222167969\n",
      "Epoch [3/50], Batch 39/120, Train Loss: 274.2041\n",
      "10573.405578613281\n",
      "Epoch [3/50], Batch 40/120, Train Loss: 305.1154\n",
      "10828.479690551758\n",
      "Epoch [3/50], Batch 41/120, Train Loss: 255.0741\n",
      "11118.756301879883\n",
      "Epoch [3/50], Batch 42/120, Train Loss: 290.2766\n",
      "11396.358596801758\n",
      "Epoch [3/50], Batch 43/120, Train Loss: 277.6023\n",
      "11678.568222045898\n",
      "Epoch [3/50], Batch 44/120, Train Loss: 282.2096\n",
      "11931.259796142578\n",
      "Epoch [3/50], Batch 45/120, Train Loss: 252.6916\n",
      "12212.215759277344\n",
      "Epoch [3/50], Batch 46/120, Train Loss: 280.9560\n",
      "12494.03628540039\n",
      "Epoch [3/50], Batch 47/120, Train Loss: 281.8205\n",
      "12756.697174072266\n",
      "Epoch [3/50], Batch 48/120, Train Loss: 262.6609\n",
      "13022.902740478516\n",
      "Epoch [3/50], Batch 49/120, Train Loss: 266.2056\n",
      "13296.143524169922\n",
      "Epoch [3/50], Batch 50/120, Train Loss: 273.2408\n",
      "13562.03775024414\n",
      "Epoch [3/50], Batch 51/120, Train Loss: 265.8942\n",
      "13844.232330322266\n",
      "Epoch [3/50], Batch 52/120, Train Loss: 282.1946\n",
      "14100.439239501953\n",
      "Epoch [3/50], Batch 53/120, Train Loss: 256.2069\n",
      "14385.514404296875\n",
      "Epoch [3/50], Batch 54/120, Train Loss: 285.0752\n",
      "14643.404602050781\n",
      "Epoch [3/50], Batch 55/120, Train Loss: 257.8902\n",
      "14925.947021484375\n",
      "Epoch [3/50], Batch 56/120, Train Loss: 282.5424\n",
      "15202.177337646484\n",
      "Epoch [3/50], Batch 57/120, Train Loss: 276.2303\n",
      "15472.219696044922\n",
      "Epoch [3/50], Batch 58/120, Train Loss: 270.0424\n",
      "15726.172775268555\n",
      "Epoch [3/50], Batch 59/120, Train Loss: 253.9531\n",
      "16002.688827514648\n",
      "Epoch [3/50], Batch 60/120, Train Loss: 276.5161\n",
      "16290.24430847168\n",
      "Epoch [3/50], Batch 61/120, Train Loss: 287.5555\n",
      "16555.925674438477\n",
      "Epoch [3/50], Batch 62/120, Train Loss: 265.6814\n",
      "16825.69807434082\n",
      "Epoch [3/50], Batch 63/120, Train Loss: 269.7724\n",
      "17081.059463500977\n",
      "Epoch [3/50], Batch 64/120, Train Loss: 255.3614\n",
      "17353.096939086914\n",
      "Epoch [3/50], Batch 65/120, Train Loss: 272.0375\n",
      "17611.160873413086\n",
      "Epoch [3/50], Batch 66/120, Train Loss: 258.0639\n",
      "17871.750381469727\n",
      "Epoch [3/50], Batch 67/120, Train Loss: 260.5895\n",
      "18101.316787719727\n",
      "Epoch [3/50], Batch 68/120, Train Loss: 229.5664\n",
      "18353.497116088867\n",
      "Epoch [3/50], Batch 69/120, Train Loss: 252.1803\n",
      "18619.04930114746\n",
      "Epoch [3/50], Batch 70/120, Train Loss: 265.5522\n",
      "18846.687423706055\n",
      "Epoch [3/50], Batch 71/120, Train Loss: 227.6381\n",
      "19122.519271850586\n",
      "Epoch [3/50], Batch 72/120, Train Loss: 275.8318\n",
      "19392.903121948242\n",
      "Epoch [3/50], Batch 73/120, Train Loss: 270.3839\n",
      "19645.218536376953\n",
      "Epoch [3/50], Batch 74/120, Train Loss: 252.3154\n",
      "19913.538635253906\n",
      "Epoch [3/50], Batch 75/120, Train Loss: 268.3201\n",
      "20203.838806152344\n",
      "Epoch [3/50], Batch 76/120, Train Loss: 290.3002\n",
      "20471.305908203125\n",
      "Epoch [3/50], Batch 77/120, Train Loss: 267.4671\n",
      "20701.606979370117\n",
      "Epoch [3/50], Batch 78/120, Train Loss: 230.3011\n",
      "21007.58103942871\n",
      "Epoch [3/50], Batch 79/120, Train Loss: 305.9741\n",
      "21249.380432128906\n",
      "Epoch [3/50], Batch 80/120, Train Loss: 241.7994\n",
      "21534.885040283203\n",
      "Epoch [3/50], Batch 81/120, Train Loss: 285.5046\n",
      "21804.23373413086\n",
      "Epoch [3/50], Batch 82/120, Train Loss: 269.3487\n",
      "22089.259735107422\n",
      "Epoch [3/50], Batch 83/120, Train Loss: 285.0260\n",
      "22310.4814453125\n",
      "Epoch [3/50], Batch 84/120, Train Loss: 221.2217\n",
      "22616.497924804688\n",
      "Epoch [3/50], Batch 85/120, Train Loss: 306.0165\n",
      "22881.377899169922\n",
      "Epoch [3/50], Batch 86/120, Train Loss: 264.8800\n",
      "23133.03953552246\n",
      "Epoch [3/50], Batch 87/120, Train Loss: 251.6616\n",
      "23405.195510864258\n",
      "Epoch [3/50], Batch 88/120, Train Loss: 272.1560\n",
      "23642.85984802246\n",
      "Epoch [3/50], Batch 89/120, Train Loss: 237.6643\n",
      "23905.842514038086\n",
      "Epoch [3/50], Batch 90/120, Train Loss: 262.9827\n",
      "24161.09848022461\n",
      "Epoch [3/50], Batch 91/120, Train Loss: 255.2560\n",
      "24426.408416748047\n",
      "Epoch [3/50], Batch 92/120, Train Loss: 265.3099\n",
      "24685.017578125\n",
      "Epoch [3/50], Batch 93/120, Train Loss: 258.6092\n",
      "24999.798736572266\n",
      "Epoch [3/50], Batch 94/120, Train Loss: 314.7812\n",
      "25250.378997802734\n",
      "Epoch [3/50], Batch 95/120, Train Loss: 250.5803\n",
      "25486.57061767578\n",
      "Epoch [3/50], Batch 96/120, Train Loss: 236.1916\n",
      "25783.561462402344\n",
      "Epoch [3/50], Batch 97/120, Train Loss: 296.9908\n",
      "26058.003540039062\n",
      "Epoch [3/50], Batch 98/120, Train Loss: 274.4421\n",
      "26321.83935546875\n",
      "Epoch [3/50], Batch 99/120, Train Loss: 263.8358\n",
      "26573.50929260254\n",
      "Epoch [3/50], Batch 100/120, Train Loss: 251.6699\n",
      "26861.185989379883\n",
      "Epoch [3/50], Batch 101/120, Train Loss: 287.6767\n",
      "27139.683853149414\n",
      "Epoch [3/50], Batch 102/120, Train Loss: 278.4979\n",
      "27411.409133911133\n",
      "Epoch [3/50], Batch 103/120, Train Loss: 271.7253\n",
      "27668.891006469727\n",
      "Epoch [3/50], Batch 104/120, Train Loss: 257.4819\n",
      "27911.525787353516\n",
      "Epoch [3/50], Batch 105/120, Train Loss: 242.6348\n",
      "28155.276275634766\n",
      "Epoch [3/50], Batch 106/120, Train Loss: 243.7505\n",
      "28390.42205810547\n",
      "Epoch [3/50], Batch 107/120, Train Loss: 235.1458\n",
      "28666.946197509766\n",
      "Epoch [3/50], Batch 108/120, Train Loss: 276.5241\n",
      "28915.339111328125\n",
      "Epoch [3/50], Batch 109/120, Train Loss: 248.3929\n",
      "29179.77618408203\n",
      "Epoch [3/50], Batch 110/120, Train Loss: 264.4371\n",
      "29479.9013671875\n",
      "Epoch [3/50], Batch 111/120, Train Loss: 300.1252\n",
      "29748.88558959961\n",
      "Epoch [3/50], Batch 112/120, Train Loss: 268.9842\n",
      "30015.058563232422\n",
      "Epoch [3/50], Batch 113/120, Train Loss: 266.1730\n",
      "30244.113861083984\n",
      "Epoch [3/50], Batch 114/120, Train Loss: 229.0553\n",
      "30501.241729736328\n",
      "Epoch [3/50], Batch 115/120, Train Loss: 257.1279\n",
      "30783.822296142578\n",
      "Epoch [3/50], Batch 116/120, Train Loss: 282.5806\n",
      "31011.647979736328\n",
      "Epoch [3/50], Batch 117/120, Train Loss: 227.8257\n",
      "31278.69223022461\n",
      "Epoch [3/50], Batch 118/120, Train Loss: 267.0443\n",
      "31567.938690185547\n",
      "Epoch [3/50], Batch 119/120, Train Loss: 289.2465\n",
      "31819.790802001953\n",
      "Epoch [3/50], Batch 120/120, Train Loss: 251.8521\n",
      "Epoch [3/50], Train Loss: 265.1649, Validation Loss: 260.6096\n",
      "296.364501953125\n",
      "Epoch [4/50], Batch 1/120, Train Loss: 296.3645\n",
      "572.5511474609375\n",
      "Epoch [4/50], Batch 2/120, Train Loss: 276.1866\n",
      "817.2020721435547\n",
      "Epoch [4/50], Batch 3/120, Train Loss: 244.6509\n",
      "1060.8170623779297\n",
      "Epoch [4/50], Batch 4/120, Train Loss: 243.6150\n",
      "1316.7133026123047\n",
      "Epoch [4/50], Batch 5/120, Train Loss: 255.8962\n",
      "1562.9495391845703\n",
      "Epoch [4/50], Batch 6/120, Train Loss: 246.2362\n",
      "1785.4676055908203\n",
      "Epoch [4/50], Batch 7/120, Train Loss: 222.5181\n",
      "2011.7744598388672\n",
      "Epoch [4/50], Batch 8/120, Train Loss: 226.3069\n",
      "2296.144760131836\n",
      "Epoch [4/50], Batch 9/120, Train Loss: 284.3703\n",
      "2514.1219024658203\n",
      "Epoch [4/50], Batch 10/120, Train Loss: 217.9771\n",
      "2765.6226196289062\n",
      "Epoch [4/50], Batch 11/120, Train Loss: 251.5007\n",
      "3070.2306213378906\n",
      "Epoch [4/50], Batch 12/120, Train Loss: 304.6080\n",
      "3352.9766540527344\n",
      "Epoch [4/50], Batch 13/120, Train Loss: 282.7460\n",
      "3592.692367553711\n",
      "Epoch [4/50], Batch 14/120, Train Loss: 239.7157\n",
      "3868.504898071289\n",
      "Epoch [4/50], Batch 15/120, Train Loss: 275.8125\n",
      "4134.041458129883\n",
      "Epoch [4/50], Batch 16/120, Train Loss: 265.5366\n",
      "4365.37255859375\n",
      "Epoch [4/50], Batch 17/120, Train Loss: 231.3311\n",
      "4636.656005859375\n",
      "Epoch [4/50], Batch 18/120, Train Loss: 271.2834\n",
      "4916.6566162109375\n",
      "Epoch [4/50], Batch 19/120, Train Loss: 280.0006\n",
      "5200.545654296875\n",
      "Epoch [4/50], Batch 20/120, Train Loss: 283.8890\n",
      "5444.853546142578\n",
      "Epoch [4/50], Batch 21/120, Train Loss: 244.3079\n",
      "5702.428924560547\n",
      "Epoch [4/50], Batch 22/120, Train Loss: 257.5754\n",
      "5969.909210205078\n",
      "Epoch [4/50], Batch 23/120, Train Loss: 267.4803\n",
      "6252.902435302734\n",
      "Epoch [4/50], Batch 24/120, Train Loss: 282.9932\n",
      "6555.924987792969\n",
      "Epoch [4/50], Batch 25/120, Train Loss: 303.0226\n",
      "6829.7578125\n",
      "Epoch [4/50], Batch 26/120, Train Loss: 273.8328\n",
      "7063.9466552734375\n",
      "Epoch [4/50], Batch 27/120, Train Loss: 234.1888\n",
      "7333.478698730469\n",
      "Epoch [4/50], Batch 28/120, Train Loss: 269.5320\n",
      "7586.144943237305\n",
      "Epoch [4/50], Batch 29/120, Train Loss: 252.6662\n",
      "7826.701889038086\n",
      "Epoch [4/50], Batch 30/120, Train Loss: 240.5569\n",
      "8076.644134521484\n",
      "Epoch [4/50], Batch 31/120, Train Loss: 249.9422\n",
      "8347.315704345703\n",
      "Epoch [4/50], Batch 32/120, Train Loss: 270.6716\n",
      "8586.396209716797\n",
      "Epoch [4/50], Batch 33/120, Train Loss: 239.0805\n",
      "8846.459655761719\n",
      "Epoch [4/50], Batch 34/120, Train Loss: 260.0634\n",
      "9088.849914550781\n",
      "Epoch [4/50], Batch 35/120, Train Loss: 242.3903\n",
      "9326.316375732422\n",
      "Epoch [4/50], Batch 36/120, Train Loss: 237.4665\n",
      "9579.290939331055\n",
      "Epoch [4/50], Batch 37/120, Train Loss: 252.9746\n",
      "9832.819198608398\n",
      "Epoch [4/50], Batch 38/120, Train Loss: 253.5283\n",
      "10084.36018371582\n",
      "Epoch [4/50], Batch 39/120, Train Loss: 251.5410\n",
      "10372.896438598633\n",
      "Epoch [4/50], Batch 40/120, Train Loss: 288.5363\n",
      "10605.873291015625\n",
      "Epoch [4/50], Batch 41/120, Train Loss: 232.9769\n",
      "10864.062225341797\n",
      "Epoch [4/50], Batch 42/120, Train Loss: 258.1889\n",
      "11092.084167480469\n",
      "Epoch [4/50], Batch 43/120, Train Loss: 228.0219\n",
      "11312.22866821289\n",
      "Epoch [4/50], Batch 44/120, Train Loss: 220.1445\n",
      "11556.77359008789\n",
      "Epoch [4/50], Batch 45/120, Train Loss: 244.5449\n",
      "11834.797058105469\n",
      "Epoch [4/50], Batch 46/120, Train Loss: 278.0235\n",
      "12081.045928955078\n",
      "Epoch [4/50], Batch 47/120, Train Loss: 246.2489\n",
      "12295.920043945312\n",
      "Epoch [4/50], Batch 48/120, Train Loss: 214.8741\n",
      "12606.575134277344\n",
      "Epoch [4/50], Batch 49/120, Train Loss: 310.6551\n",
      "12883.466552734375\n",
      "Epoch [4/50], Batch 50/120, Train Loss: 276.8914\n",
      "13159.055877685547\n",
      "Epoch [4/50], Batch 51/120, Train Loss: 275.5893\n",
      "13415.76254272461\n",
      "Epoch [4/50], Batch 52/120, Train Loss: 256.7067\n",
      "13641.888610839844\n",
      "Epoch [4/50], Batch 53/120, Train Loss: 226.1261\n",
      "13869.18490600586\n",
      "Epoch [4/50], Batch 54/120, Train Loss: 227.2963\n",
      "14161.163055419922\n",
      "Epoch [4/50], Batch 55/120, Train Loss: 291.9781\n",
      "14410.483444213867\n",
      "Epoch [4/50], Batch 56/120, Train Loss: 249.3204\n",
      "14649.886047363281\n",
      "Epoch [4/50], Batch 57/120, Train Loss: 239.4026\n",
      "14927.684448242188\n",
      "Epoch [4/50], Batch 58/120, Train Loss: 277.7984\n",
      "15193.588439941406\n",
      "Epoch [4/50], Batch 59/120, Train Loss: 265.9040\n",
      "15487.308044433594\n",
      "Epoch [4/50], Batch 60/120, Train Loss: 293.7196\n",
      "15720.533416748047\n",
      "Epoch [4/50], Batch 61/120, Train Loss: 233.2254\n",
      "15954.149383544922\n",
      "Epoch [4/50], Batch 62/120, Train Loss: 233.6160\n",
      "16205.413116455078\n",
      "Epoch [4/50], Batch 63/120, Train Loss: 251.2637\n",
      "16455.373474121094\n",
      "Epoch [4/50], Batch 64/120, Train Loss: 249.9604\n",
      "16707.96469116211\n",
      "Epoch [4/50], Batch 65/120, Train Loss: 252.5912\n",
      "16953.15657043457\n",
      "Epoch [4/50], Batch 66/120, Train Loss: 245.1919\n",
      "17246.290969848633\n",
      "Epoch [4/50], Batch 67/120, Train Loss: 293.1344\n",
      "17458.3074798584\n",
      "Epoch [4/50], Batch 68/120, Train Loss: 212.0165\n",
      "17727.709274291992\n",
      "Epoch [4/50], Batch 69/120, Train Loss: 269.4018\n",
      "17952.328735351562\n",
      "Epoch [4/50], Batch 70/120, Train Loss: 224.6195\n",
      "18185.468551635742\n",
      "Epoch [4/50], Batch 71/120, Train Loss: 233.1398\n",
      "18467.535934448242\n",
      "Epoch [4/50], Batch 72/120, Train Loss: 282.0674\n",
      "18752.14305114746\n",
      "Epoch [4/50], Batch 73/120, Train Loss: 284.6071\n",
      "18996.328491210938\n",
      "Epoch [4/50], Batch 74/120, Train Loss: 244.1854\n",
      "19254.98602294922\n",
      "Epoch [4/50], Batch 75/120, Train Loss: 258.6575\n",
      "19524.760650634766\n",
      "Epoch [4/50], Batch 76/120, Train Loss: 269.7746\n",
      "19737.057495117188\n",
      "Epoch [4/50], Batch 77/120, Train Loss: 212.2968\n",
      "19999.00180053711\n",
      "Epoch [4/50], Batch 78/120, Train Loss: 261.9443\n",
      "20264.229766845703\n",
      "Epoch [4/50], Batch 79/120, Train Loss: 265.2280\n",
      "20543.66778564453\n",
      "Epoch [4/50], Batch 80/120, Train Loss: 279.4380\n",
      "20781.70083618164\n",
      "Epoch [4/50], Batch 81/120, Train Loss: 238.0331\n",
      "21034.005432128906\n",
      "Epoch [4/50], Batch 82/120, Train Loss: 252.3046\n",
      "21266.06866455078\n",
      "Epoch [4/50], Batch 83/120, Train Loss: 232.0632\n",
      "21543.20343017578\n",
      "Epoch [4/50], Batch 84/120, Train Loss: 277.1348\n",
      "21816.37384033203\n",
      "Epoch [4/50], Batch 85/120, Train Loss: 273.1704\n",
      "22057.7392578125\n",
      "Epoch [4/50], Batch 86/120, Train Loss: 241.3654\n",
      "22286.75453186035\n",
      "Epoch [4/50], Batch 87/120, Train Loss: 229.0153\n",
      "22556.402420043945\n",
      "Epoch [4/50], Batch 88/120, Train Loss: 269.6479\n",
      "22780.530471801758\n",
      "Epoch [4/50], Batch 89/120, Train Loss: 224.1281\n",
      "23008.648208618164\n",
      "Epoch [4/50], Batch 90/120, Train Loss: 228.1177\n",
      "23265.906204223633\n",
      "Epoch [4/50], Batch 91/120, Train Loss: 257.2580\n",
      "23526.12043762207\n",
      "Epoch [4/50], Batch 92/120, Train Loss: 260.2142\n",
      "23778.1883392334\n",
      "Epoch [4/50], Batch 93/120, Train Loss: 252.0679\n",
      "24007.300720214844\n",
      "Epoch [4/50], Batch 94/120, Train Loss: 229.1124\n",
      "24243.070587158203\n",
      "Epoch [4/50], Batch 95/120, Train Loss: 235.7699\n",
      "24510.645294189453\n",
      "Epoch [4/50], Batch 96/120, Train Loss: 267.5747\n",
      "24705.65625\n",
      "Epoch [4/50], Batch 97/120, Train Loss: 195.0110\n",
      "24942.0145111084\n",
      "Epoch [4/50], Batch 98/120, Train Loss: 236.3583\n",
      "25180.367111206055\n",
      "Epoch [4/50], Batch 99/120, Train Loss: 238.3526\n",
      "25361.87825012207\n",
      "Epoch [4/50], Batch 100/120, Train Loss: 181.5111\n",
      "25633.939712524414\n",
      "Epoch [4/50], Batch 101/120, Train Loss: 272.0615\n",
      "25868.572296142578\n",
      "Epoch [4/50], Batch 102/120, Train Loss: 234.6326\n",
      "26098.669067382812\n",
      "Epoch [4/50], Batch 103/120, Train Loss: 230.0968\n",
      "26320.56134033203\n",
      "Epoch [4/50], Batch 104/120, Train Loss: 221.8923\n",
      "26592.40673828125\n",
      "Epoch [4/50], Batch 105/120, Train Loss: 271.8454\n",
      "26834.22833251953\n",
      "Epoch [4/50], Batch 106/120, Train Loss: 241.8216\n",
      "27104.324798583984\n",
      "Epoch [4/50], Batch 107/120, Train Loss: 270.0965\n",
      "27351.247955322266\n",
      "Epoch [4/50], Batch 108/120, Train Loss: 246.9232\n",
      "27555.275390625\n",
      "Epoch [4/50], Batch 109/120, Train Loss: 204.0274\n",
      "27826.004302978516\n",
      "Epoch [4/50], Batch 110/120, Train Loss: 270.7289\n",
      "28042.235137939453\n",
      "Epoch [4/50], Batch 111/120, Train Loss: 216.2308\n",
      "28292.977905273438\n",
      "Epoch [4/50], Batch 112/120, Train Loss: 250.7428\n",
      "28598.390197753906\n",
      "Epoch [4/50], Batch 113/120, Train Loss: 305.4123\n",
      "28869.953063964844\n",
      "Epoch [4/50], Batch 114/120, Train Loss: 271.5629\n",
      "29137.39520263672\n",
      "Epoch [4/50], Batch 115/120, Train Loss: 267.4421\n",
      "29386.580123901367\n",
      "Epoch [4/50], Batch 116/120, Train Loss: 249.1849\n",
      "29616.776489257812\n",
      "Epoch [4/50], Batch 117/120, Train Loss: 230.1964\n",
      "29836.06185913086\n",
      "Epoch [4/50], Batch 118/120, Train Loss: 219.2854\n",
      "30124.59341430664\n",
      "Epoch [4/50], Batch 119/120, Train Loss: 288.5316\n",
      "30348.303466796875\n",
      "Epoch [4/50], Batch 120/120, Train Loss: 223.7101\n",
      "Epoch [4/50], Train Loss: 252.9025, Validation Loss: 247.7583\n",
      "224.37876892089844\n",
      "Epoch [5/50], Batch 1/120, Train Loss: 224.3788\n",
      "473.4580841064453\n",
      "Epoch [5/50], Batch 2/120, Train Loss: 249.0793\n",
      "737.5819854736328\n",
      "Epoch [5/50], Batch 3/120, Train Loss: 264.1239\n",
      "973.3888549804688\n",
      "Epoch [5/50], Batch 4/120, Train Loss: 235.8069\n",
      "1210.6566009521484\n",
      "Epoch [5/50], Batch 5/120, Train Loss: 237.2677\n",
      "1436.311752319336\n",
      "Epoch [5/50], Batch 6/120, Train Loss: 225.6552\n",
      "1707.9071197509766\n",
      "Epoch [5/50], Batch 7/120, Train Loss: 271.5954\n",
      "1959.227066040039\n",
      "Epoch [5/50], Batch 8/120, Train Loss: 251.3199\n",
      "2189.272445678711\n",
      "Epoch [5/50], Batch 9/120, Train Loss: 230.0454\n",
      "2380.7503967285156\n",
      "Epoch [5/50], Batch 10/120, Train Loss: 191.4780\n",
      "2627.3045959472656\n",
      "Epoch [5/50], Batch 11/120, Train Loss: 246.5542\n",
      "2915.283660888672\n",
      "Epoch [5/50], Batch 12/120, Train Loss: 287.9791\n",
      "3103.8228759765625\n",
      "Epoch [5/50], Batch 13/120, Train Loss: 188.5392\n",
      "3322.4954528808594\n",
      "Epoch [5/50], Batch 14/120, Train Loss: 218.6726\n",
      "3568.15869140625\n",
      "Epoch [5/50], Batch 15/120, Train Loss: 245.6632\n",
      "3816.8350677490234\n",
      "Epoch [5/50], Batch 16/120, Train Loss: 248.6764\n",
      "4074.445114135742\n",
      "Epoch [5/50], Batch 17/120, Train Loss: 257.6100\n",
      "4319.733016967773\n",
      "Epoch [5/50], Batch 18/120, Train Loss: 245.2879\n",
      "4574.827499389648\n",
      "Epoch [5/50], Batch 19/120, Train Loss: 255.0945\n",
      "4850.854782104492\n",
      "Epoch [5/50], Batch 20/120, Train Loss: 276.0273\n",
      "5089.669479370117\n",
      "Epoch [5/50], Batch 21/120, Train Loss: 238.8147\n",
      "5330.319686889648\n",
      "Epoch [5/50], Batch 22/120, Train Loss: 240.6502\n",
      "5558.666091918945\n",
      "Epoch [5/50], Batch 23/120, Train Loss: 228.3464\n",
      "5792.56022644043\n",
      "Epoch [5/50], Batch 24/120, Train Loss: 233.8941\n",
      "6036.068984985352\n",
      "Epoch [5/50], Batch 25/120, Train Loss: 243.5088\n",
      "6269.22184753418\n",
      "Epoch [5/50], Batch 26/120, Train Loss: 233.1529\n",
      "6481.9783935546875\n",
      "Epoch [5/50], Batch 27/120, Train Loss: 212.7565\n",
      "6711.554107666016\n",
      "Epoch [5/50], Batch 28/120, Train Loss: 229.5757\n",
      "6958.939392089844\n",
      "Epoch [5/50], Batch 29/120, Train Loss: 247.3853\n",
      "7175.833587646484\n",
      "Epoch [5/50], Batch 30/120, Train Loss: 216.8942\n",
      "7414.953552246094\n",
      "Epoch [5/50], Batch 31/120, Train Loss: 239.1200\n",
      "7661.047210693359\n",
      "Epoch [5/50], Batch 32/120, Train Loss: 246.0937\n",
      "7880.887451171875\n",
      "Epoch [5/50], Batch 33/120, Train Loss: 219.8402\n",
      "8162.30615234375\n",
      "Epoch [5/50], Batch 34/120, Train Loss: 281.4187\n",
      "8416.843551635742\n",
      "Epoch [5/50], Batch 35/120, Train Loss: 254.5374\n",
      "8667.719467163086\n",
      "Epoch [5/50], Batch 36/120, Train Loss: 250.8759\n",
      "8905.281646728516\n",
      "Epoch [5/50], Batch 37/120, Train Loss: 237.5622\n",
      "9116.120895385742\n",
      "Epoch [5/50], Batch 38/120, Train Loss: 210.8392\n",
      "9380.205795288086\n",
      "Epoch [5/50], Batch 39/120, Train Loss: 264.0849\n",
      "9608.00180053711\n",
      "Epoch [5/50], Batch 40/120, Train Loss: 227.7960\n",
      "9848.454711914062\n",
      "Epoch [5/50], Batch 41/120, Train Loss: 240.4529\n",
      "10046.991180419922\n",
      "Epoch [5/50], Batch 42/120, Train Loss: 198.5365\n",
      "10302.986999511719\n",
      "Epoch [5/50], Batch 43/120, Train Loss: 255.9958\n",
      "10537.438598632812\n",
      "Epoch [5/50], Batch 44/120, Train Loss: 234.4516\n",
      "10793.903900146484\n",
      "Epoch [5/50], Batch 45/120, Train Loss: 256.4653\n",
      "11020.535369873047\n",
      "Epoch [5/50], Batch 46/120, Train Loss: 226.6315\n",
      "11275.777572631836\n",
      "Epoch [5/50], Batch 47/120, Train Loss: 255.2422\n",
      "11532.574569702148\n",
      "Epoch [5/50], Batch 48/120, Train Loss: 256.7970\n",
      "11759.969375610352\n",
      "Epoch [5/50], Batch 49/120, Train Loss: 227.3948\n",
      "12029.883316040039\n",
      "Epoch [5/50], Batch 50/120, Train Loss: 269.9139\n",
      "12310.386489868164\n",
      "Epoch [5/50], Batch 51/120, Train Loss: 280.5032\n",
      "12529.514205932617\n",
      "Epoch [5/50], Batch 52/120, Train Loss: 219.1277\n",
      "12739.363510131836\n",
      "Epoch [5/50], Batch 53/120, Train Loss: 209.8493\n",
      "12983.93635559082\n",
      "Epoch [5/50], Batch 54/120, Train Loss: 244.5728\n",
      "13235.159286499023\n",
      "Epoch [5/50], Batch 55/120, Train Loss: 251.2229\n",
      "13485.263092041016\n",
      "Epoch [5/50], Batch 56/120, Train Loss: 250.1038\n",
      "13732.394287109375\n",
      "Epoch [5/50], Batch 57/120, Train Loss: 247.1312\n",
      "13954.611190795898\n",
      "Epoch [5/50], Batch 58/120, Train Loss: 222.2169\n",
      "14194.23356628418\n",
      "Epoch [5/50], Batch 59/120, Train Loss: 239.6224\n",
      "14427.335891723633\n",
      "Epoch [5/50], Batch 60/120, Train Loss: 233.1023\n",
      "14673.676773071289\n",
      "Epoch [5/50], Batch 61/120, Train Loss: 246.3409\n",
      "14922.347412109375\n",
      "Epoch [5/50], Batch 62/120, Train Loss: 248.6706\n",
      "15166.531875610352\n",
      "Epoch [5/50], Batch 63/120, Train Loss: 244.1845\n",
      "15428.57453918457\n",
      "Epoch [5/50], Batch 64/120, Train Loss: 262.0427\n",
      "15646.825378417969\n",
      "Epoch [5/50], Batch 65/120, Train Loss: 218.2508\n",
      "15830.65835571289\n",
      "Epoch [5/50], Batch 66/120, Train Loss: 183.8330\n",
      "16099.477966308594\n",
      "Epoch [5/50], Batch 67/120, Train Loss: 268.8196\n",
      "16336.67219543457\n",
      "Epoch [5/50], Batch 68/120, Train Loss: 237.1942\n",
      "16560.3585357666\n",
      "Epoch [5/50], Batch 69/120, Train Loss: 223.6863\n",
      "16778.8416595459\n",
      "Epoch [5/50], Batch 70/120, Train Loss: 218.4831\n",
      "17070.230239868164\n",
      "Epoch [5/50], Batch 71/120, Train Loss: 291.3886\n",
      "17313.31607055664\n",
      "Epoch [5/50], Batch 72/120, Train Loss: 243.0858\n",
      "17575.613708496094\n",
      "Epoch [5/50], Batch 73/120, Train Loss: 262.2976\n",
      "17807.160385131836\n",
      "Epoch [5/50], Batch 74/120, Train Loss: 231.5467\n",
      "18032.662673950195\n",
      "Epoch [5/50], Batch 75/120, Train Loss: 225.5023\n",
      "18273.418060302734\n",
      "Epoch [5/50], Batch 76/120, Train Loss: 240.7554\n",
      "18512.689086914062\n",
      "Epoch [5/50], Batch 77/120, Train Loss: 239.2710\n",
      "18793.973724365234\n",
      "Epoch [5/50], Batch 78/120, Train Loss: 281.2846\n",
      "19052.51254272461\n",
      "Epoch [5/50], Batch 79/120, Train Loss: 258.5388\n",
      "19253.863830566406\n",
      "Epoch [5/50], Batch 80/120, Train Loss: 201.3513\n",
      "19475.938110351562\n",
      "Epoch [5/50], Batch 81/120, Train Loss: 222.0743\n",
      "19744.19351196289\n",
      "Epoch [5/50], Batch 82/120, Train Loss: 268.2554\n",
      "19971.636260986328\n",
      "Epoch [5/50], Batch 83/120, Train Loss: 227.4427\n",
      "20222.070861816406\n",
      "Epoch [5/50], Batch 84/120, Train Loss: 250.4346\n",
      "20466.957122802734\n",
      "Epoch [5/50], Batch 85/120, Train Loss: 244.8863\n",
      "20664.95782470703\n",
      "Epoch [5/50], Batch 86/120, Train Loss: 198.0007\n",
      "20918.964965820312\n",
      "Epoch [5/50], Batch 87/120, Train Loss: 254.0071\n",
      "21176.077545166016\n",
      "Epoch [5/50], Batch 88/120, Train Loss: 257.1126\n",
      "21376.93360900879\n",
      "Epoch [5/50], Batch 89/120, Train Loss: 200.8561\n",
      "21608.817901611328\n",
      "Epoch [5/50], Batch 90/120, Train Loss: 231.8843\n",
      "21828.512786865234\n",
      "Epoch [5/50], Batch 91/120, Train Loss: 219.6949\n",
      "22060.603607177734\n",
      "Epoch [5/50], Batch 92/120, Train Loss: 232.0908\n",
      "22311.800064086914\n",
      "Epoch [5/50], Batch 93/120, Train Loss: 251.1965\n",
      "22540.554443359375\n",
      "Epoch [5/50], Batch 94/120, Train Loss: 228.7544\n",
      "22709.12339782715\n",
      "Epoch [5/50], Batch 95/120, Train Loss: 168.5690\n",
      "22964.77458190918\n",
      "Epoch [5/50], Batch 96/120, Train Loss: 255.6512\n",
      "23211.3009185791\n",
      "Epoch [5/50], Batch 97/120, Train Loss: 246.5263\n",
      "23466.28660583496\n",
      "Epoch [5/50], Batch 98/120, Train Loss: 254.9857\n",
      "23673.225784301758\n",
      "Epoch [5/50], Batch 99/120, Train Loss: 206.9392\n",
      "23909.77847290039\n",
      "Epoch [5/50], Batch 100/120, Train Loss: 236.5527\n",
      "24161.332809448242\n",
      "Epoch [5/50], Batch 101/120, Train Loss: 251.5543\n",
      "24369.08087158203\n",
      "Epoch [5/50], Batch 102/120, Train Loss: 207.7481\n",
      "24601.885284423828\n",
      "Epoch [5/50], Batch 103/120, Train Loss: 232.8044\n",
      "24808.718948364258\n",
      "Epoch [5/50], Batch 104/120, Train Loss: 206.8337\n",
      "25032.116622924805\n",
      "Epoch [5/50], Batch 105/120, Train Loss: 223.3977\n",
      "25251.38623046875\n",
      "Epoch [5/50], Batch 106/120, Train Loss: 219.2696\n",
      "25462.90347290039\n",
      "Epoch [5/50], Batch 107/120, Train Loss: 211.5172\n",
      "25678.435821533203\n",
      "Epoch [5/50], Batch 108/120, Train Loss: 215.5323\n",
      "25947.7421875\n",
      "Epoch [5/50], Batch 109/120, Train Loss: 269.3064\n",
      "26213.297119140625\n",
      "Epoch [5/50], Batch 110/120, Train Loss: 265.5549\n",
      "26425.578521728516\n",
      "Epoch [5/50], Batch 111/120, Train Loss: 212.2814\n",
      "26671.078247070312\n",
      "Epoch [5/50], Batch 112/120, Train Loss: 245.4997\n",
      "26921.587005615234\n",
      "Epoch [5/50], Batch 113/120, Train Loss: 250.5088\n",
      "27170.362213134766\n",
      "Epoch [5/50], Batch 114/120, Train Loss: 248.7752\n",
      "27431.796356201172\n",
      "Epoch [5/50], Batch 115/120, Train Loss: 261.4341\n",
      "27679.447692871094\n",
      "Epoch [5/50], Batch 116/120, Train Loss: 247.6513\n",
      "27911.92108154297\n",
      "Epoch [5/50], Batch 117/120, Train Loss: 232.4734\n",
      "28198.639770507812\n",
      "Epoch [5/50], Batch 118/120, Train Loss: 286.7187\n",
      "28454.677764892578\n",
      "Epoch [5/50], Batch 119/120, Train Loss: 256.0380\n",
      "28629.779876708984\n",
      "Epoch [5/50], Batch 120/120, Train Loss: 175.1021\n",
      "Epoch [5/50], Train Loss: 238.5815, Validation Loss: 231.1172\n",
      "244.30471801757812\n",
      "Epoch [6/50], Batch 1/120, Train Loss: 244.3047\n",
      "465.6103515625\n",
      "Epoch [6/50], Batch 2/120, Train Loss: 221.3056\n",
      "673.3201446533203\n",
      "Epoch [6/50], Batch 3/120, Train Loss: 207.7098\n",
      "913.2986297607422\n",
      "Epoch [6/50], Batch 4/120, Train Loss: 239.9785\n",
      "1128.7993469238281\n",
      "Epoch [6/50], Batch 5/120, Train Loss: 215.5007\n",
      "1373.8229370117188\n",
      "Epoch [6/50], Batch 6/120, Train Loss: 245.0236\n",
      "1610.7666931152344\n",
      "Epoch [6/50], Batch 7/120, Train Loss: 236.9438\n",
      "1841.193115234375\n",
      "Epoch [6/50], Batch 8/120, Train Loss: 230.4264\n",
      "2037.1503601074219\n",
      "Epoch [6/50], Batch 9/120, Train Loss: 195.9572\n",
      "2281.8594665527344\n",
      "Epoch [6/50], Batch 10/120, Train Loss: 244.7091\n",
      "2522.9486694335938\n",
      "Epoch [6/50], Batch 11/120, Train Loss: 241.0892\n",
      "2729.7933959960938\n",
      "Epoch [6/50], Batch 12/120, Train Loss: 206.8447\n",
      "2967.53857421875\n",
      "Epoch [6/50], Batch 13/120, Train Loss: 237.7452\n",
      "3194.127227783203\n",
      "Epoch [6/50], Batch 14/120, Train Loss: 226.5887\n",
      "3427.149688720703\n",
      "Epoch [6/50], Batch 15/120, Train Loss: 233.0225\n",
      "3627.5943603515625\n",
      "Epoch [6/50], Batch 16/120, Train Loss: 200.4447\n",
      "3861.147445678711\n",
      "Epoch [6/50], Batch 17/120, Train Loss: 233.5531\n",
      "4080.2308502197266\n",
      "Epoch [6/50], Batch 18/120, Train Loss: 219.0834\n",
      "4306.535446166992\n",
      "Epoch [6/50], Batch 19/120, Train Loss: 226.3046\n",
      "4540.303848266602\n",
      "Epoch [6/50], Batch 20/120, Train Loss: 233.7684\n",
      "4797.744613647461\n",
      "Epoch [6/50], Batch 21/120, Train Loss: 257.4408\n",
      "5003.810989379883\n",
      "Epoch [6/50], Batch 22/120, Train Loss: 206.0664\n",
      "5220.427688598633\n",
      "Epoch [6/50], Batch 23/120, Train Loss: 216.6167\n",
      "5442.160308837891\n",
      "Epoch [6/50], Batch 24/120, Train Loss: 221.7326\n",
      "5641.0885009765625\n",
      "Epoch [6/50], Batch 25/120, Train Loss: 198.9282\n",
      "5874.837005615234\n",
      "Epoch [6/50], Batch 26/120, Train Loss: 233.7485\n",
      "6117.053192138672\n",
      "Epoch [6/50], Batch 27/120, Train Loss: 242.2162\n",
      "6302.984924316406\n",
      "Epoch [6/50], Batch 28/120, Train Loss: 185.9317\n",
      "6499.974075317383\n",
      "Epoch [6/50], Batch 29/120, Train Loss: 196.9892\n",
      "6700.717208862305\n",
      "Epoch [6/50], Batch 30/120, Train Loss: 200.7431\n",
      "6934.0855712890625\n",
      "Epoch [6/50], Batch 31/120, Train Loss: 233.3684\n",
      "7154.438827514648\n",
      "Epoch [6/50], Batch 32/120, Train Loss: 220.3533\n",
      "7385.515151977539\n",
      "Epoch [6/50], Batch 33/120, Train Loss: 231.0763\n",
      "7560.756942749023\n",
      "Epoch [6/50], Batch 34/120, Train Loss: 175.2418\n",
      "7778.632080078125\n",
      "Epoch [6/50], Batch 35/120, Train Loss: 217.8751\n",
      "8021.796875\n",
      "Epoch [6/50], Batch 36/120, Train Loss: 243.1648\n",
      "8245.329498291016\n",
      "Epoch [6/50], Batch 37/120, Train Loss: 223.5326\n",
      "8495.020126342773\n",
      "Epoch [6/50], Batch 38/120, Train Loss: 249.6906\n",
      "8739.500961303711\n",
      "Epoch [6/50], Batch 39/120, Train Loss: 244.4808\n",
      "8948.693313598633\n",
      "Epoch [6/50], Batch 40/120, Train Loss: 209.1924\n",
      "9163.509719848633\n",
      "Epoch [6/50], Batch 41/120, Train Loss: 214.8164\n",
      "9375.242233276367\n",
      "Epoch [6/50], Batch 42/120, Train Loss: 211.7325\n",
      "9620.067977905273\n",
      "Epoch [6/50], Batch 43/120, Train Loss: 244.8257\n",
      "9842.417358398438\n",
      "Epoch [6/50], Batch 44/120, Train Loss: 222.3494\n",
      "10076.202224731445\n",
      "Epoch [6/50], Batch 45/120, Train Loss: 233.7849\n",
      "10297.59066772461\n",
      "Epoch [6/50], Batch 46/120, Train Loss: 221.3884\n",
      "10482.338775634766\n",
      "Epoch [6/50], Batch 47/120, Train Loss: 184.7481\n",
      "10755.194122314453\n",
      "Epoch [6/50], Batch 48/120, Train Loss: 272.8553\n",
      "10976.705780029297\n",
      "Epoch [6/50], Batch 49/120, Train Loss: 221.5117\n",
      "11163.845672607422\n",
      "Epoch [6/50], Batch 50/120, Train Loss: 187.1399\n",
      "11400.113006591797\n",
      "Epoch [6/50], Batch 51/120, Train Loss: 236.2673\n",
      "11623.463134765625\n",
      "Epoch [6/50], Batch 52/120, Train Loss: 223.3501\n",
      "11840.525772094727\n",
      "Epoch [6/50], Batch 53/120, Train Loss: 217.0626\n",
      "12053.711029052734\n",
      "Epoch [6/50], Batch 54/120, Train Loss: 213.1853\n",
      "12267.859176635742\n",
      "Epoch [6/50], Batch 55/120, Train Loss: 214.1481\n",
      "12495.758071899414\n",
      "Epoch [6/50], Batch 56/120, Train Loss: 227.8989\n",
      "12733.496963500977\n",
      "Epoch [6/50], Batch 57/120, Train Loss: 237.7389\n",
      "13009.069229125977\n",
      "Epoch [6/50], Batch 58/120, Train Loss: 275.5723\n",
      "13269.831253051758\n",
      "Epoch [6/50], Batch 59/120, Train Loss: 260.7620\n",
      "13564.667251586914\n",
      "Epoch [6/50], Batch 60/120, Train Loss: 294.8360\n",
      "13774.81802368164\n",
      "Epoch [6/50], Batch 61/120, Train Loss: 210.1508\n",
      "13996.756958007812\n",
      "Epoch [6/50], Batch 62/120, Train Loss: 221.9389\n",
      "14228.28288269043\n",
      "Epoch [6/50], Batch 63/120, Train Loss: 231.5259\n",
      "14464.8427734375\n",
      "Epoch [6/50], Batch 64/120, Train Loss: 236.5599\n",
      "14686.290939331055\n",
      "Epoch [6/50], Batch 65/120, Train Loss: 221.4482\n",
      "14952.733901977539\n",
      "Epoch [6/50], Batch 66/120, Train Loss: 266.4430\n",
      "15164.873046875\n",
      "Epoch [6/50], Batch 67/120, Train Loss: 212.1391\n",
      "15426.58755493164\n",
      "Epoch [6/50], Batch 68/120, Train Loss: 261.7145\n",
      "15626.026397705078\n",
      "Epoch [6/50], Batch 69/120, Train Loss: 199.4388\n",
      "15858.182861328125\n",
      "Epoch [6/50], Batch 70/120, Train Loss: 232.1565\n",
      "16043.702850341797\n",
      "Epoch [6/50], Batch 71/120, Train Loss: 185.5200\n",
      "16246.294677734375\n",
      "Epoch [6/50], Batch 72/120, Train Loss: 202.5918\n",
      "16484.002838134766\n",
      "Epoch [6/50], Batch 73/120, Train Loss: 237.7082\n",
      "16704.382125854492\n",
      "Epoch [6/50], Batch 74/120, Train Loss: 220.3793\n",
      "16914.809036254883\n",
      "Epoch [6/50], Batch 75/120, Train Loss: 210.4269\n",
      "17118.590530395508\n",
      "Epoch [6/50], Batch 76/120, Train Loss: 203.7815\n",
      "17336.092376708984\n",
      "Epoch [6/50], Batch 77/120, Train Loss: 217.5018\n",
      "17543.11215209961\n",
      "Epoch [6/50], Batch 78/120, Train Loss: 207.0198\n",
      "17776.262603759766\n",
      "Epoch [6/50], Batch 79/120, Train Loss: 233.1505\n",
      "17978.246124267578\n",
      "Epoch [6/50], Batch 80/120, Train Loss: 201.9835\n",
      "18216.464965820312\n",
      "Epoch [6/50], Batch 81/120, Train Loss: 238.2188\n",
      "18434.47329711914\n",
      "Epoch [6/50], Batch 82/120, Train Loss: 218.0083\n",
      "18626.639450073242\n",
      "Epoch [6/50], Batch 83/120, Train Loss: 192.1662\n",
      "18847.85725402832\n",
      "Epoch [6/50], Batch 84/120, Train Loss: 221.2178\n",
      "19060.937591552734\n",
      "Epoch [6/50], Batch 85/120, Train Loss: 213.0803\n",
      "19268.73193359375\n",
      "Epoch [6/50], Batch 86/120, Train Loss: 207.7943\n",
      "19504.32778930664\n",
      "Epoch [6/50], Batch 87/120, Train Loss: 235.5959\n",
      "19743.57879638672\n",
      "Epoch [6/50], Batch 88/120, Train Loss: 239.2510\n",
      "19962.16175842285\n",
      "Epoch [6/50], Batch 89/120, Train Loss: 218.5830\n",
      "20170.55857849121\n",
      "Epoch [6/50], Batch 90/120, Train Loss: 208.3968\n",
      "20404.687576293945\n",
      "Epoch [6/50], Batch 91/120, Train Loss: 234.1290\n",
      "20647.40805053711\n",
      "Epoch [6/50], Batch 92/120, Train Loss: 242.7205\n",
      "20867.134155273438\n",
      "Epoch [6/50], Batch 93/120, Train Loss: 219.7261\n",
      "21088.026794433594\n",
      "Epoch [6/50], Batch 94/120, Train Loss: 220.8926\n",
      "21300.121337890625\n",
      "Epoch [6/50], Batch 95/120, Train Loss: 212.0945\n",
      "21498.232482910156\n",
      "Epoch [6/50], Batch 96/120, Train Loss: 198.1111\n",
      "21717.298706054688\n",
      "Epoch [6/50], Batch 97/120, Train Loss: 219.0662\n",
      "21926.595794677734\n",
      "Epoch [6/50], Batch 98/120, Train Loss: 209.2971\n",
      "22111.523559570312\n",
      "Epoch [6/50], Batch 99/120, Train Loss: 184.9278\n",
      "22353.074264526367\n",
      "Epoch [6/50], Batch 100/120, Train Loss: 241.5507\n",
      "22603.846145629883\n",
      "Epoch [6/50], Batch 101/120, Train Loss: 250.7719\n",
      "22808.086044311523\n",
      "Epoch [6/50], Batch 102/120, Train Loss: 204.2399\n",
      "23038.86033630371\n",
      "Epoch [6/50], Batch 103/120, Train Loss: 230.7743\n",
      "23251.715713500977\n",
      "Epoch [6/50], Batch 104/120, Train Loss: 212.8554\n",
      "23432.65640258789\n",
      "Epoch [6/50], Batch 105/120, Train Loss: 180.9407\n",
      "23666.19110107422\n",
      "Epoch [6/50], Batch 106/120, Train Loss: 233.5347\n",
      "23856.720642089844\n",
      "Epoch [6/50], Batch 107/120, Train Loss: 190.5295\n",
      "24074.143173217773\n",
      "Epoch [6/50], Batch 108/120, Train Loss: 217.4225\n",
      "24318.789169311523\n",
      "Epoch [6/50], Batch 109/120, Train Loss: 244.6460\n",
      "24530.49835205078\n",
      "Epoch [6/50], Batch 110/120, Train Loss: 211.7092\n",
      "24779.77520751953\n",
      "Epoch [6/50], Batch 111/120, Train Loss: 249.2769\n",
      "24993.547409057617\n",
      "Epoch [6/50], Batch 112/120, Train Loss: 213.7722\n",
      "25206.958450317383\n",
      "Epoch [6/50], Batch 113/120, Train Loss: 213.4110\n",
      "25418.692092895508\n",
      "Epoch [6/50], Batch 114/120, Train Loss: 211.7336\n",
      "25627.250061035156\n",
      "Epoch [6/50], Batch 115/120, Train Loss: 208.5580\n",
      "25818.55876159668\n",
      "Epoch [6/50], Batch 116/120, Train Loss: 191.3087\n",
      "26070.73826599121\n",
      "Epoch [6/50], Batch 117/120, Train Loss: 252.1795\n",
      "26257.784072875977\n",
      "Epoch [6/50], Batch 118/120, Train Loss: 187.0458\n",
      "26437.096572875977\n",
      "Epoch [6/50], Batch 119/120, Train Loss: 179.3125\n",
      "26638.54100036621\n",
      "Epoch [6/50], Batch 120/120, Train Loss: 201.4444\n",
      "Epoch [6/50], Train Loss: 221.9878, Validation Loss: 214.1920\n",
      "204.17767333984375\n",
      "Epoch [7/50], Batch 1/120, Train Loss: 204.1777\n",
      "448.17388916015625\n",
      "Epoch [7/50], Batch 2/120, Train Loss: 243.9962\n",
      "657.0871429443359\n",
      "Epoch [7/50], Batch 3/120, Train Loss: 208.9133\n",
      "847.8143768310547\n",
      "Epoch [7/50], Batch 4/120, Train Loss: 190.7272\n",
      "1073.138412475586\n",
      "Epoch [7/50], Batch 5/120, Train Loss: 225.3240\n",
      "1306.2924041748047\n",
      "Epoch [7/50], Batch 6/120, Train Loss: 233.1540\n",
      "1481.8969421386719\n",
      "Epoch [7/50], Batch 7/120, Train Loss: 175.6045\n",
      "1741.9963989257812\n",
      "Epoch [7/50], Batch 8/120, Train Loss: 260.0995\n",
      "1966.4053649902344\n",
      "Epoch [7/50], Batch 9/120, Train Loss: 224.4090\n",
      "2198.944595336914\n",
      "Epoch [7/50], Batch 10/120, Train Loss: 232.5392\n",
      "2389.4772186279297\n",
      "Epoch [7/50], Batch 11/120, Train Loss: 190.5326\n",
      "2598.9650115966797\n",
      "Epoch [7/50], Batch 12/120, Train Loss: 209.4878\n",
      "2820.9930725097656\n",
      "Epoch [7/50], Batch 13/120, Train Loss: 222.0281\n",
      "3010.7348022460938\n",
      "Epoch [7/50], Batch 14/120, Train Loss: 189.7417\n",
      "3246.4081115722656\n",
      "Epoch [7/50], Batch 15/120, Train Loss: 235.6733\n",
      "3464.8223419189453\n",
      "Epoch [7/50], Batch 16/120, Train Loss: 218.4142\n",
      "3694.675735473633\n",
      "Epoch [7/50], Batch 17/120, Train Loss: 229.8534\n",
      "3889.183059692383\n",
      "Epoch [7/50], Batch 18/120, Train Loss: 194.5073\n",
      "4092.839309692383\n",
      "Epoch [7/50], Batch 19/120, Train Loss: 203.6562\n",
      "4277.475448608398\n",
      "Epoch [7/50], Batch 20/120, Train Loss: 184.6361\n",
      "4469.591644287109\n",
      "Epoch [7/50], Batch 21/120, Train Loss: 192.1162\n",
      "4712.217529296875\n",
      "Epoch [7/50], Batch 22/120, Train Loss: 242.6259\n",
      "4907.241195678711\n",
      "Epoch [7/50], Batch 23/120, Train Loss: 195.0237\n",
      "5097.81657409668\n",
      "Epoch [7/50], Batch 24/120, Train Loss: 190.5754\n",
      "5288.130111694336\n",
      "Epoch [7/50], Batch 25/120, Train Loss: 190.3135\n",
      "5536.849517822266\n",
      "Epoch [7/50], Batch 26/120, Train Loss: 248.7194\n",
      "5728.159393310547\n",
      "Epoch [7/50], Batch 27/120, Train Loss: 191.3099\n",
      "5917.062393188477\n",
      "Epoch [7/50], Batch 28/120, Train Loss: 188.9030\n",
      "6058.717422485352\n",
      "Epoch [7/50], Batch 29/120, Train Loss: 141.6550\n",
      "6296.442291259766\n",
      "Epoch [7/50], Batch 30/120, Train Loss: 237.7249\n",
      "6529.254913330078\n",
      "Epoch [7/50], Batch 31/120, Train Loss: 232.8126\n",
      "6737.476013183594\n",
      "Epoch [7/50], Batch 32/120, Train Loss: 208.2211\n",
      "6904.702362060547\n",
      "Epoch [7/50], Batch 33/120, Train Loss: 167.2263\n",
      "7120.571304321289\n",
      "Epoch [7/50], Batch 34/120, Train Loss: 215.8689\n",
      "7305.134750366211\n",
      "Epoch [7/50], Batch 35/120, Train Loss: 184.5634\n",
      "7529.49560546875\n",
      "Epoch [7/50], Batch 36/120, Train Loss: 224.3609\n",
      "7721.9127197265625\n",
      "Epoch [7/50], Batch 37/120, Train Loss: 192.4171\n",
      "7915.301666259766\n",
      "Epoch [7/50], Batch 38/120, Train Loss: 193.3889\n",
      "8129.822235107422\n",
      "Epoch [7/50], Batch 39/120, Train Loss: 214.5206\n",
      "8333.76171875\n",
      "Epoch [7/50], Batch 40/120, Train Loss: 203.9395\n",
      "8578.152526855469\n",
      "Epoch [7/50], Batch 41/120, Train Loss: 244.3908\n",
      "8776.758911132812\n",
      "Epoch [7/50], Batch 42/120, Train Loss: 198.6064\n",
      "8967.957321166992\n",
      "Epoch [7/50], Batch 43/120, Train Loss: 191.1984\n",
      "9205.861618041992\n",
      "Epoch [7/50], Batch 44/120, Train Loss: 237.9043\n",
      "9422.44758605957\n",
      "Epoch [7/50], Batch 45/120, Train Loss: 216.5860\n",
      "9629.851425170898\n",
      "Epoch [7/50], Batch 46/120, Train Loss: 207.4038\n",
      "9842.444473266602\n",
      "Epoch [7/50], Batch 47/120, Train Loss: 212.5930\n",
      "10091.185256958008\n",
      "Epoch [7/50], Batch 48/120, Train Loss: 248.7408\n",
      "10292.671859741211\n",
      "Epoch [7/50], Batch 49/120, Train Loss: 201.4866\n",
      "10536.765411376953\n",
      "Epoch [7/50], Batch 50/120, Train Loss: 244.0936\n",
      "10756.503601074219\n",
      "Epoch [7/50], Batch 51/120, Train Loss: 219.7382\n",
      "10941.942672729492\n",
      "Epoch [7/50], Batch 52/120, Train Loss: 185.4391\n",
      "11163.297760009766\n",
      "Epoch [7/50], Batch 53/120, Train Loss: 221.3551\n",
      "11348.1435546875\n",
      "Epoch [7/50], Batch 54/120, Train Loss: 184.8458\n",
      "11522.328796386719\n",
      "Epoch [7/50], Batch 55/120, Train Loss: 174.1852\n",
      "11729.922058105469\n",
      "Epoch [7/50], Batch 56/120, Train Loss: 207.5933\n",
      "11938.14111328125\n",
      "Epoch [7/50], Batch 57/120, Train Loss: 208.2191\n",
      "12131.59765625\n",
      "Epoch [7/50], Batch 58/120, Train Loss: 193.4565\n",
      "12343.064208984375\n",
      "Epoch [7/50], Batch 59/120, Train Loss: 211.4666\n",
      "12557.171936035156\n",
      "Epoch [7/50], Batch 60/120, Train Loss: 214.1077\n",
      "12774.817626953125\n",
      "Epoch [7/50], Batch 61/120, Train Loss: 217.6457\n",
      "12967.114120483398\n",
      "Epoch [7/50], Batch 62/120, Train Loss: 192.2965\n",
      "13235.488082885742\n",
      "Epoch [7/50], Batch 63/120, Train Loss: 268.3740\n",
      "13430.805892944336\n",
      "Epoch [7/50], Batch 64/120, Train Loss: 195.3178\n",
      "13644.489639282227\n",
      "Epoch [7/50], Batch 65/120, Train Loss: 213.6837\n",
      "13843.413772583008\n",
      "Epoch [7/50], Batch 66/120, Train Loss: 198.9241\n",
      "14051.516815185547\n",
      "Epoch [7/50], Batch 67/120, Train Loss: 208.1030\n",
      "14242.286926269531\n",
      "Epoch [7/50], Batch 68/120, Train Loss: 190.7701\n",
      "14435.547271728516\n",
      "Epoch [7/50], Batch 69/120, Train Loss: 193.2603\n",
      "14657.186447143555\n",
      "Epoch [7/50], Batch 70/120, Train Loss: 221.6392\n",
      "14838.323226928711\n",
      "Epoch [7/50], Batch 71/120, Train Loss: 181.1368\n",
      "15054.404266357422\n",
      "Epoch [7/50], Batch 72/120, Train Loss: 216.0810\n",
      "15278.323486328125\n",
      "Epoch [7/50], Batch 73/120, Train Loss: 223.9192\n",
      "15466.375701904297\n",
      "Epoch [7/50], Batch 74/120, Train Loss: 188.0522\n",
      "15654.04019165039\n",
      "Epoch [7/50], Batch 75/120, Train Loss: 187.6645\n",
      "15857.889297485352\n",
      "Epoch [7/50], Batch 76/120, Train Loss: 203.8491\n",
      "16037.288482666016\n",
      "Epoch [7/50], Batch 77/120, Train Loss: 179.3992\n",
      "16246.645904541016\n",
      "Epoch [7/50], Batch 78/120, Train Loss: 209.3574\n",
      "16455.605438232422\n",
      "Epoch [7/50], Batch 79/120, Train Loss: 208.9595\n",
      "16647.92449951172\n",
      "Epoch [7/50], Batch 80/120, Train Loss: 192.3191\n",
      "16822.308303833008\n",
      "Epoch [7/50], Batch 81/120, Train Loss: 174.3838\n",
      "17022.866653442383\n",
      "Epoch [7/50], Batch 82/120, Train Loss: 200.5583\n",
      "17233.7459564209\n",
      "Epoch [7/50], Batch 83/120, Train Loss: 210.8793\n",
      "17420.867218017578\n",
      "Epoch [7/50], Batch 84/120, Train Loss: 187.1213\n",
      "17626.325958251953\n",
      "Epoch [7/50], Batch 85/120, Train Loss: 205.4587\n",
      "17786.075134277344\n",
      "Epoch [7/50], Batch 86/120, Train Loss: 159.7492\n",
      "17965.920684814453\n",
      "Epoch [7/50], Batch 87/120, Train Loss: 179.8456\n",
      "18160.96157836914\n",
      "Epoch [7/50], Batch 88/120, Train Loss: 195.0409\n",
      "18373.21063232422\n",
      "Epoch [7/50], Batch 89/120, Train Loss: 212.2491\n",
      "18584.81967163086\n",
      "Epoch [7/50], Batch 90/120, Train Loss: 211.6090\n",
      "18794.81217956543\n",
      "Epoch [7/50], Batch 91/120, Train Loss: 209.9925\n",
      "18998.697494506836\n",
      "Epoch [7/50], Batch 92/120, Train Loss: 203.8853\n",
      "19229.469345092773\n",
      "Epoch [7/50], Batch 93/120, Train Loss: 230.7719\n",
      "19397.840393066406\n",
      "Epoch [7/50], Batch 94/120, Train Loss: 168.3710\n",
      "19625.32891845703\n",
      "Epoch [7/50], Batch 95/120, Train Loss: 227.4885\n",
      "19842.734161376953\n",
      "Epoch [7/50], Batch 96/120, Train Loss: 217.4052\n",
      "20059.418212890625\n",
      "Epoch [7/50], Batch 97/120, Train Loss: 216.6841\n",
      "20266.134826660156\n",
      "Epoch [7/50], Batch 98/120, Train Loss: 206.7166\n",
      "20486.076080322266\n",
      "Epoch [7/50], Batch 99/120, Train Loss: 219.9413\n",
      "20695.365325927734\n",
      "Epoch [7/50], Batch 100/120, Train Loss: 209.2892\n",
      "20861.293228149414\n",
      "Epoch [7/50], Batch 101/120, Train Loss: 165.9279\n",
      "21041.710983276367\n",
      "Epoch [7/50], Batch 102/120, Train Loss: 180.4178\n",
      "21218.560165405273\n",
      "Epoch [7/50], Batch 103/120, Train Loss: 176.8492\n",
      "21452.179733276367\n",
      "Epoch [7/50], Batch 104/120, Train Loss: 233.6196\n",
      "21631.39469909668\n",
      "Epoch [7/50], Batch 105/120, Train Loss: 179.2150\n",
      "21818.057907104492\n",
      "Epoch [7/50], Batch 106/120, Train Loss: 186.6632\n",
      "22003.128341674805\n",
      "Epoch [7/50], Batch 107/120, Train Loss: 185.0704\n",
      "22201.813858032227\n",
      "Epoch [7/50], Batch 108/120, Train Loss: 198.6855\n",
      "22419.434280395508\n",
      "Epoch [7/50], Batch 109/120, Train Loss: 217.6204\n",
      "22614.40675354004\n",
      "Epoch [7/50], Batch 110/120, Train Loss: 194.9725\n",
      "22834.443389892578\n",
      "Epoch [7/50], Batch 111/120, Train Loss: 220.0366\n",
      "23005.889282226562\n",
      "Epoch [7/50], Batch 112/120, Train Loss: 171.4459\n",
      "23174.26629638672\n",
      "Epoch [7/50], Batch 113/120, Train Loss: 168.3770\n",
      "23332.03517150879\n",
      "Epoch [7/50], Batch 114/120, Train Loss: 157.7689\n",
      "23521.168823242188\n",
      "Epoch [7/50], Batch 115/120, Train Loss: 189.1337\n",
      "23744.130752563477\n",
      "Epoch [7/50], Batch 116/120, Train Loss: 222.9619\n",
      "23926.759155273438\n",
      "Epoch [7/50], Batch 117/120, Train Loss: 182.6284\n",
      "24084.5691986084\n",
      "Epoch [7/50], Batch 118/120, Train Loss: 157.8100\n",
      "24302.6199798584\n",
      "Epoch [7/50], Batch 119/120, Train Loss: 218.0508\n",
      "24516.319046020508\n",
      "Epoch [7/50], Batch 120/120, Train Loss: 213.6991\n",
      "Epoch [7/50], Train Loss: 204.3027, Validation Loss: 197.6845\n",
      "194.512939453125\n",
      "Epoch [8/50], Batch 1/120, Train Loss: 194.5129\n",
      "360.74078369140625\n",
      "Epoch [8/50], Batch 2/120, Train Loss: 166.2278\n",
      "579.76025390625\n",
      "Epoch [8/50], Batch 3/120, Train Loss: 219.0195\n",
      "759.4824829101562\n",
      "Epoch [8/50], Batch 4/120, Train Loss: 179.7222\n",
      "939.7894134521484\n",
      "Epoch [8/50], Batch 5/120, Train Loss: 180.3069\n",
      "1123.7129821777344\n",
      "Epoch [8/50], Batch 6/120, Train Loss: 183.9236\n",
      "1309.8949584960938\n",
      "Epoch [8/50], Batch 7/120, Train Loss: 186.1820\n",
      "1502.3432922363281\n",
      "Epoch [8/50], Batch 8/120, Train Loss: 192.4483\n",
      "1696.2641143798828\n",
      "Epoch [8/50], Batch 9/120, Train Loss: 193.9208\n",
      "1916.7136688232422\n",
      "Epoch [8/50], Batch 10/120, Train Loss: 220.4496\n",
      "2097.8348541259766\n",
      "Epoch [8/50], Batch 11/120, Train Loss: 181.1212\n",
      "2324.311294555664\n",
      "Epoch [8/50], Batch 12/120, Train Loss: 226.4764\n",
      "2518.1710357666016\n",
      "Epoch [8/50], Batch 13/120, Train Loss: 193.8597\n",
      "2723.2071990966797\n",
      "Epoch [8/50], Batch 14/120, Train Loss: 205.0362\n",
      "2967.827651977539\n",
      "Epoch [8/50], Batch 15/120, Train Loss: 244.6205\n",
      "3181.9249420166016\n",
      "Epoch [8/50], Batch 16/120, Train Loss: 214.0973\n",
      "3404.7477264404297\n",
      "Epoch [8/50], Batch 17/120, Train Loss: 222.8228\n",
      "3644.348648071289\n",
      "Epoch [8/50], Batch 18/120, Train Loss: 239.6009\n",
      "3854.6786346435547\n",
      "Epoch [8/50], Batch 19/120, Train Loss: 210.3300\n",
      "4059.040985107422\n",
      "Epoch [8/50], Batch 20/120, Train Loss: 204.3624\n",
      "4256.001312255859\n",
      "Epoch [8/50], Batch 21/120, Train Loss: 196.9603\n",
      "4443.635772705078\n",
      "Epoch [8/50], Batch 22/120, Train Loss: 187.6345\n",
      "4647.107864379883\n",
      "Epoch [8/50], Batch 23/120, Train Loss: 203.4721\n",
      "4839.988510131836\n",
      "Epoch [8/50], Batch 24/120, Train Loss: 192.8806\n",
      "5033.653381347656\n",
      "Epoch [8/50], Batch 25/120, Train Loss: 193.6649\n",
      "5215.517486572266\n",
      "Epoch [8/50], Batch 26/120, Train Loss: 181.8641\n",
      "5433.275680541992\n",
      "Epoch [8/50], Batch 27/120, Train Loss: 217.7582\n",
      "5622.487762451172\n",
      "Epoch [8/50], Batch 28/120, Train Loss: 189.2121\n",
      "5794.354309082031\n",
      "Epoch [8/50], Batch 29/120, Train Loss: 171.8665\n",
      "5970.716903686523\n",
      "Epoch [8/50], Batch 30/120, Train Loss: 176.3626\n",
      "6133.271636962891\n",
      "Epoch [8/50], Batch 31/120, Train Loss: 162.5547\n",
      "6274.062316894531\n",
      "Epoch [8/50], Batch 32/120, Train Loss: 140.7907\n",
      "6457.49040222168\n",
      "Epoch [8/50], Batch 33/120, Train Loss: 183.4281\n",
      "6649.017929077148\n",
      "Epoch [8/50], Batch 34/120, Train Loss: 191.5275\n",
      "6841.93864440918\n",
      "Epoch [8/50], Batch 35/120, Train Loss: 192.9207\n",
      "7049.868026733398\n",
      "Epoch [8/50], Batch 36/120, Train Loss: 207.9294\n",
      "7242.427200317383\n",
      "Epoch [8/50], Batch 37/120, Train Loss: 192.5592\n",
      "7398.727813720703\n",
      "Epoch [8/50], Batch 38/120, Train Loss: 156.3006\n",
      "7624.958389282227\n",
      "Epoch [8/50], Batch 39/120, Train Loss: 226.2306\n",
      "7785.740692138672\n",
      "Epoch [8/50], Batch 40/120, Train Loss: 160.7823\n",
      "8003.723815917969\n",
      "Epoch [8/50], Batch 41/120, Train Loss: 217.9831\n",
      "8173.319610595703\n",
      "Epoch [8/50], Batch 42/120, Train Loss: 169.5958\n",
      "8373.697509765625\n",
      "Epoch [8/50], Batch 43/120, Train Loss: 200.3779\n",
      "8541.256454467773\n",
      "Epoch [8/50], Batch 44/120, Train Loss: 167.5589\n",
      "8709.355239868164\n",
      "Epoch [8/50], Batch 45/120, Train Loss: 168.0988\n",
      "8874.10580444336\n",
      "Epoch [8/50], Batch 46/120, Train Loss: 164.7506\n",
      "9057.650833129883\n",
      "Epoch [8/50], Batch 47/120, Train Loss: 183.5450\n",
      "9251.912994384766\n",
      "Epoch [8/50], Batch 48/120, Train Loss: 194.2622\n",
      "9448.65982055664\n",
      "Epoch [8/50], Batch 49/120, Train Loss: 196.7468\n",
      "9670.768600463867\n",
      "Epoch [8/50], Batch 50/120, Train Loss: 222.1088\n",
      "9873.240341186523\n",
      "Epoch [8/50], Batch 51/120, Train Loss: 202.4717\n",
      "10054.231842041016\n",
      "Epoch [8/50], Batch 52/120, Train Loss: 180.9915\n",
      "10246.817260742188\n",
      "Epoch [8/50], Batch 53/120, Train Loss: 192.5854\n",
      "10430.237365722656\n",
      "Epoch [8/50], Batch 54/120, Train Loss: 183.4201\n",
      "10646.518630981445\n",
      "Epoch [8/50], Batch 55/120, Train Loss: 216.2813\n",
      "10835.761260986328\n",
      "Epoch [8/50], Batch 56/120, Train Loss: 189.2426\n",
      "11041.744873046875\n",
      "Epoch [8/50], Batch 57/120, Train Loss: 205.9836\n",
      "11197.150497436523\n",
      "Epoch [8/50], Batch 58/120, Train Loss: 155.4056\n",
      "11357.031555175781\n",
      "Epoch [8/50], Batch 59/120, Train Loss: 159.8811\n",
      "11517.496597290039\n",
      "Epoch [8/50], Batch 60/120, Train Loss: 160.4650\n",
      "11688.784042358398\n",
      "Epoch [8/50], Batch 61/120, Train Loss: 171.2874\n",
      "11905.658599853516\n",
      "Epoch [8/50], Batch 62/120, Train Loss: 216.8746\n",
      "12074.011688232422\n",
      "Epoch [8/50], Batch 63/120, Train Loss: 168.3531\n",
      "12243.369171142578\n",
      "Epoch [8/50], Batch 64/120, Train Loss: 169.3575\n",
      "12424.034301757812\n",
      "Epoch [8/50], Batch 65/120, Train Loss: 180.6651\n",
      "12582.739151000977\n",
      "Epoch [8/50], Batch 66/120, Train Loss: 158.7048\n",
      "12774.070068359375\n",
      "Epoch [8/50], Batch 67/120, Train Loss: 191.3309\n",
      "12947.515197753906\n",
      "Epoch [8/50], Batch 68/120, Train Loss: 173.4451\n",
      "13177.824493408203\n",
      "Epoch [8/50], Batch 69/120, Train Loss: 230.3093\n",
      "13332.124755859375\n",
      "Epoch [8/50], Batch 70/120, Train Loss: 154.3003\n",
      "13517.328369140625\n",
      "Epoch [8/50], Batch 71/120, Train Loss: 185.2036\n",
      "13711.20736694336\n",
      "Epoch [8/50], Batch 72/120, Train Loss: 193.8790\n",
      "13906.204406738281\n",
      "Epoch [8/50], Batch 73/120, Train Loss: 194.9970\n",
      "14071.665817260742\n",
      "Epoch [8/50], Batch 74/120, Train Loss: 165.4614\n",
      "14271.846252441406\n",
      "Epoch [8/50], Batch 75/120, Train Loss: 200.1804\n",
      "14452.96224975586\n",
      "Epoch [8/50], Batch 76/120, Train Loss: 181.1160\n",
      "14666.757537841797\n",
      "Epoch [8/50], Batch 77/120, Train Loss: 213.7953\n",
      "14820.363372802734\n",
      "Epoch [8/50], Batch 78/120, Train Loss: 153.6058\n",
      "15002.723220825195\n",
      "Epoch [8/50], Batch 79/120, Train Loss: 182.3598\n",
      "15185.789108276367\n",
      "Epoch [8/50], Batch 80/120, Train Loss: 183.0659\n",
      "15344.529098510742\n",
      "Epoch [8/50], Batch 81/120, Train Loss: 158.7400\n",
      "15547.546844482422\n",
      "Epoch [8/50], Batch 82/120, Train Loss: 203.0177\n",
      "15715.565673828125\n",
      "Epoch [8/50], Batch 83/120, Train Loss: 168.0188\n",
      "15894.104202270508\n",
      "Epoch [8/50], Batch 84/120, Train Loss: 178.5385\n",
      "16061.465408325195\n",
      "Epoch [8/50], Batch 85/120, Train Loss: 167.3612\n",
      "16263.724472045898\n",
      "Epoch [8/50], Batch 86/120, Train Loss: 202.2591\n",
      "16490.500289916992\n",
      "Epoch [8/50], Batch 87/120, Train Loss: 226.7758\n",
      "16676.55809020996\n",
      "Epoch [8/50], Batch 88/120, Train Loss: 186.0578\n",
      "16835.977432250977\n",
      "Epoch [8/50], Batch 89/120, Train Loss: 159.4193\n",
      "16999.923614501953\n",
      "Epoch [8/50], Batch 90/120, Train Loss: 163.9462\n",
      "17192.949188232422\n",
      "Epoch [8/50], Batch 91/120, Train Loss: 193.0256\n",
      "17399.48468017578\n",
      "Epoch [8/50], Batch 92/120, Train Loss: 206.5355\n",
      "17596.425872802734\n",
      "Epoch [8/50], Batch 93/120, Train Loss: 196.9412\n",
      "17763.019439697266\n",
      "Epoch [8/50], Batch 94/120, Train Loss: 166.5936\n",
      "17970.443939208984\n",
      "Epoch [8/50], Batch 95/120, Train Loss: 207.4245\n",
      "18144.13491821289\n",
      "Epoch [8/50], Batch 96/120, Train Loss: 173.6910\n",
      "18335.79313659668\n",
      "Epoch [8/50], Batch 97/120, Train Loss: 191.6582\n",
      "18491.567825317383\n",
      "Epoch [8/50], Batch 98/120, Train Loss: 155.7747\n",
      "18668.0352935791\n",
      "Epoch [8/50], Batch 99/120, Train Loss: 176.4675\n",
      "18881.60272216797\n",
      "Epoch [8/50], Batch 100/120, Train Loss: 213.5674\n",
      "19035.85662841797\n",
      "Epoch [8/50], Batch 101/120, Train Loss: 154.2539\n",
      "19244.64926147461\n",
      "Epoch [8/50], Batch 102/120, Train Loss: 208.7926\n",
      "19436.716888427734\n",
      "Epoch [8/50], Batch 103/120, Train Loss: 192.0676\n",
      "19620.684692382812\n",
      "Epoch [8/50], Batch 104/120, Train Loss: 183.9678\n",
      "19835.97817993164\n",
      "Epoch [8/50], Batch 105/120, Train Loss: 215.2935\n",
      "19993.749389648438\n",
      "Epoch [8/50], Batch 106/120, Train Loss: 157.7712\n",
      "20214.230194091797\n",
      "Epoch [8/50], Batch 107/120, Train Loss: 220.4808\n",
      "20401.46206665039\n",
      "Epoch [8/50], Batch 108/120, Train Loss: 187.2319\n",
      "20554.94807434082\n",
      "Epoch [8/50], Batch 109/120, Train Loss: 153.4860\n",
      "20722.809600830078\n",
      "Epoch [8/50], Batch 110/120, Train Loss: 167.8615\n",
      "20947.551727294922\n",
      "Epoch [8/50], Batch 111/120, Train Loss: 224.7421\n",
      "21140.33172607422\n",
      "Epoch [8/50], Batch 112/120, Train Loss: 192.7800\n",
      "21326.680938720703\n",
      "Epoch [8/50], Batch 113/120, Train Loss: 186.3492\n",
      "21522.37030029297\n",
      "Epoch [8/50], Batch 114/120, Train Loss: 195.6894\n",
      "21700.603103637695\n",
      "Epoch [8/50], Batch 115/120, Train Loss: 178.2328\n",
      "21838.986892700195\n",
      "Epoch [8/50], Batch 116/120, Train Loss: 138.3838\n",
      "22027.749923706055\n",
      "Epoch [8/50], Batch 117/120, Train Loss: 188.7630\n",
      "22213.326080322266\n",
      "Epoch [8/50], Batch 118/120, Train Loss: 185.5762\n",
      "22368.42074584961\n",
      "Epoch [8/50], Batch 119/120, Train Loss: 155.0947\n",
      "22540.298095703125\n",
      "Epoch [8/50], Batch 120/120, Train Loss: 171.8773\n",
      "Epoch [8/50], Train Loss: 187.8358, Validation Loss: 181.5086\n",
      "238.18699645996094\n",
      "Epoch [9/50], Batch 1/120, Train Loss: 238.1870\n",
      "404.73023986816406\n",
      "Epoch [9/50], Batch 2/120, Train Loss: 166.5432\n",
      "618.5807342529297\n",
      "Epoch [9/50], Batch 3/120, Train Loss: 213.8505\n",
      "794.0919494628906\n",
      "Epoch [9/50], Batch 4/120, Train Loss: 175.5112\n",
      "956.1304626464844\n",
      "Epoch [9/50], Batch 5/120, Train Loss: 162.0385\n",
      "1150.2875061035156\n",
      "Epoch [9/50], Batch 6/120, Train Loss: 194.1570\n",
      "1300.9526062011719\n",
      "Epoch [9/50], Batch 7/120, Train Loss: 150.6651\n",
      "1491.4934844970703\n",
      "Epoch [9/50], Batch 8/120, Train Loss: 190.5409\n",
      "1702.179672241211\n",
      "Epoch [9/50], Batch 9/120, Train Loss: 210.6862\n",
      "1868.7987060546875\n",
      "Epoch [9/50], Batch 10/120, Train Loss: 166.6190\n",
      "2046.847915649414\n",
      "Epoch [9/50], Batch 11/120, Train Loss: 178.0492\n",
      "2210.020263671875\n",
      "Epoch [9/50], Batch 12/120, Train Loss: 163.1723\n",
      "2426.28173828125\n",
      "Epoch [9/50], Batch 13/120, Train Loss: 216.2615\n",
      "2590.8485412597656\n",
      "Epoch [9/50], Batch 14/120, Train Loss: 164.5668\n",
      "2763.153549194336\n",
      "Epoch [9/50], Batch 15/120, Train Loss: 172.3050\n",
      "2906.440414428711\n",
      "Epoch [9/50], Batch 16/120, Train Loss: 143.2869\n",
      "3090.0526580810547\n",
      "Epoch [9/50], Batch 17/120, Train Loss: 183.6122\n",
      "3294.747299194336\n",
      "Epoch [9/50], Batch 18/120, Train Loss: 204.6946\n",
      "3457.7725830078125\n",
      "Epoch [9/50], Batch 19/120, Train Loss: 163.0253\n",
      "3647.795379638672\n",
      "Epoch [9/50], Batch 20/120, Train Loss: 190.0228\n",
      "3826.1887969970703\n",
      "Epoch [9/50], Batch 21/120, Train Loss: 178.3934\n",
      "3999.9495697021484\n",
      "Epoch [9/50], Batch 22/120, Train Loss: 173.7608\n",
      "4164.256088256836\n",
      "Epoch [9/50], Batch 23/120, Train Loss: 164.3065\n",
      "4341.984603881836\n",
      "Epoch [9/50], Batch 24/120, Train Loss: 177.7285\n",
      "4531.422088623047\n",
      "Epoch [9/50], Batch 25/120, Train Loss: 189.4375\n",
      "4742.244842529297\n",
      "Epoch [9/50], Batch 26/120, Train Loss: 210.8228\n",
      "4919.791290283203\n",
      "Epoch [9/50], Batch 27/120, Train Loss: 177.5464\n",
      "5057.327407836914\n",
      "Epoch [9/50], Batch 28/120, Train Loss: 137.5361\n",
      "5209.460342407227\n",
      "Epoch [9/50], Batch 29/120, Train Loss: 152.1329\n",
      "5392.478561401367\n",
      "Epoch [9/50], Batch 30/120, Train Loss: 183.0182\n",
      "5552.911361694336\n",
      "Epoch [9/50], Batch 31/120, Train Loss: 160.4328\n",
      "5692.279220581055\n",
      "Epoch [9/50], Batch 32/120, Train Loss: 139.3679\n",
      "5826.074203491211\n",
      "Epoch [9/50], Batch 33/120, Train Loss: 133.7950\n",
      "5950.22038269043\n",
      "Epoch [9/50], Batch 34/120, Train Loss: 124.1462\n",
      "6097.638046264648\n",
      "Epoch [9/50], Batch 35/120, Train Loss: 147.4177\n",
      "6251.077041625977\n",
      "Epoch [9/50], Batch 36/120, Train Loss: 153.4390\n",
      "6435.614929199219\n",
      "Epoch [9/50], Batch 37/120, Train Loss: 184.5379\n",
      "6613.577972412109\n",
      "Epoch [9/50], Batch 38/120, Train Loss: 177.9630\n",
      "6793.7977294921875\n",
      "Epoch [9/50], Batch 39/120, Train Loss: 180.2198\n",
      "6994.193695068359\n",
      "Epoch [9/50], Batch 40/120, Train Loss: 200.3960\n",
      "7184.069000244141\n",
      "Epoch [9/50], Batch 41/120, Train Loss: 189.8753\n",
      "7389.952560424805\n",
      "Epoch [9/50], Batch 42/120, Train Loss: 205.8836\n",
      "7577.30012512207\n",
      "Epoch [9/50], Batch 43/120, Train Loss: 187.3476\n",
      "7742.58561706543\n",
      "Epoch [9/50], Batch 44/120, Train Loss: 165.2855\n",
      "7897.680328369141\n",
      "Epoch [9/50], Batch 45/120, Train Loss: 155.0947\n",
      "8065.923141479492\n",
      "Epoch [9/50], Batch 46/120, Train Loss: 168.2428\n",
      "8266.10595703125\n",
      "Epoch [9/50], Batch 47/120, Train Loss: 200.1828\n",
      "8449.56787109375\n",
      "Epoch [9/50], Batch 48/120, Train Loss: 183.4619\n",
      "8638.272415161133\n",
      "Epoch [9/50], Batch 49/120, Train Loss: 188.7045\n",
      "8838.155563354492\n",
      "Epoch [9/50], Batch 50/120, Train Loss: 199.8831\n",
      "8997.71939086914\n",
      "Epoch [9/50], Batch 51/120, Train Loss: 159.5638\n",
      "9155.582717895508\n",
      "Epoch [9/50], Batch 52/120, Train Loss: 157.8633\n",
      "9275.937683105469\n",
      "Epoch [9/50], Batch 53/120, Train Loss: 120.3550\n",
      "9486.613159179688\n",
      "Epoch [9/50], Batch 54/120, Train Loss: 210.6755\n",
      "9660.565017700195\n",
      "Epoch [9/50], Batch 55/120, Train Loss: 173.9519\n",
      "9846.049514770508\n",
      "Epoch [9/50], Batch 56/120, Train Loss: 185.4845\n",
      "9987.857666015625\n",
      "Epoch [9/50], Batch 57/120, Train Loss: 141.8082\n",
      "10153.674026489258\n",
      "Epoch [9/50], Batch 58/120, Train Loss: 165.8164\n",
      "10303.313385009766\n",
      "Epoch [9/50], Batch 59/120, Train Loss: 149.6394\n",
      "10470.65251159668\n",
      "Epoch [9/50], Batch 60/120, Train Loss: 167.3391\n",
      "10633.542739868164\n",
      "Epoch [9/50], Batch 61/120, Train Loss: 162.8902\n",
      "10793.114776611328\n",
      "Epoch [9/50], Batch 62/120, Train Loss: 159.5720\n",
      "10952.092987060547\n",
      "Epoch [9/50], Batch 63/120, Train Loss: 158.9782\n",
      "11132.317581176758\n",
      "Epoch [9/50], Batch 64/120, Train Loss: 180.2246\n",
      "11273.141799926758\n",
      "Epoch [9/50], Batch 65/120, Train Loss: 140.8242\n",
      "11441.607437133789\n",
      "Epoch [9/50], Batch 66/120, Train Loss: 168.4656\n",
      "11585.346954345703\n",
      "Epoch [9/50], Batch 67/120, Train Loss: 143.7395\n",
      "11738.063720703125\n",
      "Epoch [9/50], Batch 68/120, Train Loss: 152.7168\n",
      "11954.85710144043\n",
      "Epoch [9/50], Batch 69/120, Train Loss: 216.7934\n",
      "12133.981918334961\n",
      "Epoch [9/50], Batch 70/120, Train Loss: 179.1248\n",
      "12295.84782409668\n",
      "Epoch [9/50], Batch 71/120, Train Loss: 161.8659\n",
      "12497.996810913086\n",
      "Epoch [9/50], Batch 72/120, Train Loss: 202.1490\n",
      "12676.737533569336\n",
      "Epoch [9/50], Batch 73/120, Train Loss: 178.7407\n",
      "12853.85546875\n",
      "Epoch [9/50], Batch 74/120, Train Loss: 177.1179\n",
      "12998.002563476562\n",
      "Epoch [9/50], Batch 75/120, Train Loss: 144.1471\n",
      "13192.085906982422\n",
      "Epoch [9/50], Batch 76/120, Train Loss: 194.0833\n",
      "13379.510864257812\n",
      "Epoch [9/50], Batch 77/120, Train Loss: 187.4250\n",
      "13548.326354980469\n",
      "Epoch [9/50], Batch 78/120, Train Loss: 168.8155\n",
      "13728.025344848633\n",
      "Epoch [9/50], Batch 79/120, Train Loss: 179.6990\n",
      "13909.766815185547\n",
      "Epoch [9/50], Batch 80/120, Train Loss: 181.7415\n",
      "14086.09375\n",
      "Epoch [9/50], Batch 81/120, Train Loss: 176.3269\n",
      "14233.362518310547\n",
      "Epoch [9/50], Batch 82/120, Train Loss: 147.2688\n",
      "14427.432983398438\n",
      "Epoch [9/50], Batch 83/120, Train Loss: 194.0705\n",
      "14610.37043762207\n",
      "Epoch [9/50], Batch 84/120, Train Loss: 182.9375\n",
      "14783.590957641602\n",
      "Epoch [9/50], Batch 85/120, Train Loss: 173.2205\n",
      "14974.657760620117\n",
      "Epoch [9/50], Batch 86/120, Train Loss: 191.0668\n",
      "15144.768569946289\n",
      "Epoch [9/50], Batch 87/120, Train Loss: 170.1108\n",
      "15299.08366394043\n",
      "Epoch [9/50], Batch 88/120, Train Loss: 154.3151\n",
      "15452.613998413086\n",
      "Epoch [9/50], Batch 89/120, Train Loss: 153.5303\n",
      "15613.693862915039\n",
      "Epoch [9/50], Batch 90/120, Train Loss: 161.0799\n",
      "15775.82975769043\n",
      "Epoch [9/50], Batch 91/120, Train Loss: 162.1359\n",
      "15945.377944946289\n",
      "Epoch [9/50], Batch 92/120, Train Loss: 169.5482\n",
      "16116.456817626953\n",
      "Epoch [9/50], Batch 93/120, Train Loss: 171.0789\n",
      "16270.423599243164\n",
      "Epoch [9/50], Batch 94/120, Train Loss: 153.9668\n",
      "16436.58659362793\n",
      "Epoch [9/50], Batch 95/120, Train Loss: 166.1630\n",
      "16586.035583496094\n",
      "Epoch [9/50], Batch 96/120, Train Loss: 149.4490\n",
      "16743.50146484375\n",
      "Epoch [9/50], Batch 97/120, Train Loss: 157.4659\n",
      "16911.119354248047\n",
      "Epoch [9/50], Batch 98/120, Train Loss: 167.6179\n",
      "17091.837020874023\n",
      "Epoch [9/50], Batch 99/120, Train Loss: 180.7177\n",
      "17243.848754882812\n",
      "Epoch [9/50], Batch 100/120, Train Loss: 152.0117\n",
      "17408.873596191406\n",
      "Epoch [9/50], Batch 101/120, Train Loss: 165.0248\n",
      "17595.16146850586\n",
      "Epoch [9/50], Batch 102/120, Train Loss: 186.2879\n",
      "17768.91877746582\n",
      "Epoch [9/50], Batch 103/120, Train Loss: 173.7573\n",
      "17919.6092376709\n",
      "Epoch [9/50], Batch 104/120, Train Loss: 150.6905\n",
      "18090.40200805664\n",
      "Epoch [9/50], Batch 105/120, Train Loss: 170.7928\n",
      "18278.585876464844\n",
      "Epoch [9/50], Batch 106/120, Train Loss: 188.1839\n",
      "18429.7265625\n",
      "Epoch [9/50], Batch 107/120, Train Loss: 151.1407\n",
      "18570.751419067383\n",
      "Epoch [9/50], Batch 108/120, Train Loss: 141.0249\n",
      "18711.579147338867\n",
      "Epoch [9/50], Batch 109/120, Train Loss: 140.8277\n",
      "18866.304260253906\n",
      "Epoch [9/50], Batch 110/120, Train Loss: 154.7251\n",
      "19078.09376525879\n",
      "Epoch [9/50], Batch 111/120, Train Loss: 211.7895\n",
      "19234.125442504883\n",
      "Epoch [9/50], Batch 112/120, Train Loss: 156.0317\n",
      "19395.318923950195\n",
      "Epoch [9/50], Batch 113/120, Train Loss: 161.1935\n",
      "19575.81105041504\n",
      "Epoch [9/50], Batch 114/120, Train Loss: 180.4921\n",
      "19743.157943725586\n",
      "Epoch [9/50], Batch 115/120, Train Loss: 167.3469\n",
      "19911.923080444336\n",
      "Epoch [9/50], Batch 116/120, Train Loss: 168.7651\n",
      "20077.8175201416\n",
      "Epoch [9/50], Batch 117/120, Train Loss: 165.8944\n",
      "20235.792724609375\n",
      "Epoch [9/50], Batch 118/120, Train Loss: 157.9752\n",
      "20418.261474609375\n",
      "Epoch [9/50], Batch 119/120, Train Loss: 182.4688\n",
      "20618.992797851562\n",
      "Epoch [9/50], Batch 120/120, Train Loss: 200.7313\n",
      "Epoch [9/50], Train Loss: 171.8249, Validation Loss: 166.8935\n",
      "159.32379150390625\n",
      "Epoch [10/50], Batch 1/120, Train Loss: 159.3238\n",
      "304.32147216796875\n",
      "Epoch [10/50], Batch 2/120, Train Loss: 144.9977\n",
      "469.5795440673828\n",
      "Epoch [10/50], Batch 3/120, Train Loss: 165.2581\n",
      "649.0945892333984\n",
      "Epoch [10/50], Batch 4/120, Train Loss: 179.5150\n",
      "845.1385192871094\n",
      "Epoch [10/50], Batch 5/120, Train Loss: 196.0439\n",
      "1001.8675537109375\n",
      "Epoch [10/50], Batch 6/120, Train Loss: 156.7290\n",
      "1194.9299011230469\n",
      "Epoch [10/50], Batch 7/120, Train Loss: 193.0623\n",
      "1333.5208435058594\n",
      "Epoch [10/50], Batch 8/120, Train Loss: 138.5909\n",
      "1496.2486419677734\n",
      "Epoch [10/50], Batch 9/120, Train Loss: 162.7278\n",
      "1663.5313720703125\n",
      "Epoch [10/50], Batch 10/120, Train Loss: 167.2827\n",
      "1838.0877075195312\n",
      "Epoch [10/50], Batch 11/120, Train Loss: 174.5563\n",
      "1988.759262084961\n",
      "Epoch [10/50], Batch 12/120, Train Loss: 150.6716\n",
      "2144.1358032226562\n",
      "Epoch [10/50], Batch 13/120, Train Loss: 155.3765\n",
      "2271.5202255249023\n",
      "Epoch [10/50], Batch 14/120, Train Loss: 127.3844\n",
      "2466.4475326538086\n",
      "Epoch [10/50], Batch 15/120, Train Loss: 194.9273\n",
      "2608.678871154785\n",
      "Epoch [10/50], Batch 16/120, Train Loss: 142.2313\n",
      "2728.816719055176\n",
      "Epoch [10/50], Batch 17/120, Train Loss: 120.1378\n",
      "2869.986213684082\n",
      "Epoch [10/50], Batch 18/120, Train Loss: 141.1695\n",
      "3032.197639465332\n",
      "Epoch [10/50], Batch 19/120, Train Loss: 162.2114\n",
      "3197.7533950805664\n",
      "Epoch [10/50], Batch 20/120, Train Loss: 165.5558\n",
      "3336.509941101074\n",
      "Epoch [10/50], Batch 21/120, Train Loss: 138.7565\n",
      "3525.2255630493164\n",
      "Epoch [10/50], Batch 22/120, Train Loss: 188.7156\n",
      "3690.4240188598633\n",
      "Epoch [10/50], Batch 23/120, Train Loss: 165.1985\n",
      "3818.629814147949\n",
      "Epoch [10/50], Batch 24/120, Train Loss: 128.2058\n",
      "4046.860008239746\n",
      "Epoch [10/50], Batch 25/120, Train Loss: 228.2302\n",
      "4212.004554748535\n",
      "Epoch [10/50], Batch 26/120, Train Loss: 165.1445\n",
      "4370.953758239746\n",
      "Epoch [10/50], Batch 27/120, Train Loss: 158.9492\n",
      "4496.492317199707\n",
      "Epoch [10/50], Batch 28/120, Train Loss: 125.5386\n",
      "4667.531639099121\n",
      "Epoch [10/50], Batch 29/120, Train Loss: 171.0393\n",
      "4815.589469909668\n",
      "Epoch [10/50], Batch 30/120, Train Loss: 148.0578\n",
      "5017.261528015137\n",
      "Epoch [10/50], Batch 31/120, Train Loss: 201.6721\n",
      "5189.2871170043945\n",
      "Epoch [10/50], Batch 32/120, Train Loss: 172.0256\n",
      "5357.137260437012\n",
      "Epoch [10/50], Batch 33/120, Train Loss: 167.8501\n",
      "5523.42928314209\n",
      "Epoch [10/50], Batch 34/120, Train Loss: 166.2920\n",
      "5688.166206359863\n",
      "Epoch [10/50], Batch 35/120, Train Loss: 164.7369\n",
      "5862.332832336426\n",
      "Epoch [10/50], Batch 36/120, Train Loss: 174.1666\n",
      "6007.544868469238\n",
      "Epoch [10/50], Batch 37/120, Train Loss: 145.2120\n",
      "6184.457130432129\n",
      "Epoch [10/50], Batch 38/120, Train Loss: 176.9123\n",
      "6363.133613586426\n",
      "Epoch [10/50], Batch 39/120, Train Loss: 178.6765\n",
      "6485.214866638184\n",
      "Epoch [10/50], Batch 40/120, Train Loss: 122.0813\n",
      "6675.812950134277\n",
      "Epoch [10/50], Batch 41/120, Train Loss: 190.5981\n",
      "6841.985710144043\n",
      "Epoch [10/50], Batch 42/120, Train Loss: 166.1728\n",
      "7020.838356018066\n",
      "Epoch [10/50], Batch 43/120, Train Loss: 178.8526\n",
      "7197.6794509887695\n",
      "Epoch [10/50], Batch 44/120, Train Loss: 176.8411\n",
      "7383.597724914551\n",
      "Epoch [10/50], Batch 45/120, Train Loss: 185.9183\n",
      "7554.224143981934\n",
      "Epoch [10/50], Batch 46/120, Train Loss: 170.6264\n",
      "7716.221092224121\n",
      "Epoch [10/50], Batch 47/120, Train Loss: 161.9969\n",
      "7898.183296203613\n",
      "Epoch [10/50], Batch 48/120, Train Loss: 181.9622\n",
      "8098.247688293457\n",
      "Epoch [10/50], Batch 49/120, Train Loss: 200.0644\n",
      "8262.94213104248\n",
      "Epoch [10/50], Batch 50/120, Train Loss: 164.6944\n",
      "8414.39818572998\n",
      "Epoch [10/50], Batch 51/120, Train Loss: 151.4561\n",
      "8588.726356506348\n",
      "Epoch [10/50], Batch 52/120, Train Loss: 174.3282\n",
      "8742.01081085205\n",
      "Epoch [10/50], Batch 53/120, Train Loss: 153.2845\n",
      "8907.135200500488\n",
      "Epoch [10/50], Batch 54/120, Train Loss: 165.1244\n",
      "9074.864067077637\n",
      "Epoch [10/50], Batch 55/120, Train Loss: 167.7289\n",
      "9220.12068939209\n",
      "Epoch [10/50], Batch 56/120, Train Loss: 145.2566\n",
      "9382.994194030762\n",
      "Epoch [10/50], Batch 57/120, Train Loss: 162.8735\n",
      "9556.152671813965\n",
      "Epoch [10/50], Batch 58/120, Train Loss: 173.1585\n",
      "9725.339683532715\n",
      "Epoch [10/50], Batch 59/120, Train Loss: 169.1870\n",
      "9878.223320007324\n",
      "Epoch [10/50], Batch 60/120, Train Loss: 152.8836\n",
      "10023.272117614746\n",
      "Epoch [10/50], Batch 61/120, Train Loss: 145.0488\n",
      "10185.211814880371\n",
      "Epoch [10/50], Batch 62/120, Train Loss: 161.9397\n",
      "10354.084114074707\n",
      "Epoch [10/50], Batch 63/120, Train Loss: 168.8723\n",
      "10516.43659210205\n",
      "Epoch [10/50], Batch 64/120, Train Loss: 162.3525\n",
      "10679.541481018066\n",
      "Epoch [10/50], Batch 65/120, Train Loss: 163.1049\n",
      "10854.765510559082\n",
      "Epoch [10/50], Batch 66/120, Train Loss: 175.2240\n",
      "11030.402778625488\n",
      "Epoch [10/50], Batch 67/120, Train Loss: 175.6373\n",
      "11178.862800598145\n",
      "Epoch [10/50], Batch 68/120, Train Loss: 148.4600\n",
      "11328.46622467041\n",
      "Epoch [10/50], Batch 69/120, Train Loss: 149.6034\n",
      "11474.625541687012\n",
      "Epoch [10/50], Batch 70/120, Train Loss: 146.1593\n",
      "11633.896751403809\n",
      "Epoch [10/50], Batch 71/120, Train Loss: 159.2712\n",
      "11773.139259338379\n",
      "Epoch [10/50], Batch 72/120, Train Loss: 139.2425\n",
      "11940.17992401123\n",
      "Epoch [10/50], Batch 73/120, Train Loss: 167.0407\n",
      "12070.537055969238\n",
      "Epoch [10/50], Batch 74/120, Train Loss: 130.3571\n",
      "12225.01294708252\n",
      "Epoch [10/50], Batch 75/120, Train Loss: 154.4759\n",
      "12361.929695129395\n",
      "Epoch [10/50], Batch 76/120, Train Loss: 136.9167\n",
      "12534.970924377441\n",
      "Epoch [10/50], Batch 77/120, Train Loss: 173.0412\n",
      "12656.777542114258\n",
      "Epoch [10/50], Batch 78/120, Train Loss: 121.8066\n",
      "12777.878616333008\n",
      "Epoch [10/50], Batch 79/120, Train Loss: 121.1011\n",
      "12952.405883789062\n",
      "Epoch [10/50], Batch 80/120, Train Loss: 174.5273\n",
      "13104.37336730957\n",
      "Epoch [10/50], Batch 81/120, Train Loss: 151.9675\n",
      "13301.660110473633\n",
      "Epoch [10/50], Batch 82/120, Train Loss: 197.2867\n",
      "13449.169372558594\n",
      "Epoch [10/50], Batch 83/120, Train Loss: 147.5093\n",
      "13604.2607421875\n",
      "Epoch [10/50], Batch 84/120, Train Loss: 155.0914\n",
      "13735.601669311523\n",
      "Epoch [10/50], Batch 85/120, Train Loss: 131.3409\n",
      "13880.690841674805\n",
      "Epoch [10/50], Batch 86/120, Train Loss: 145.0892\n",
      "14040.383895874023\n",
      "Epoch [10/50], Batch 87/120, Train Loss: 159.6931\n",
      "14211.443618774414\n",
      "Epoch [10/50], Batch 88/120, Train Loss: 171.0597\n",
      "14396.826416015625\n",
      "Epoch [10/50], Batch 89/120, Train Loss: 185.3828\n",
      "14544.802215576172\n",
      "Epoch [10/50], Batch 90/120, Train Loss: 147.9758\n",
      "14723.533996582031\n",
      "Epoch [10/50], Batch 91/120, Train Loss: 178.7318\n",
      "14887.974517822266\n",
      "Epoch [10/50], Batch 92/120, Train Loss: 164.4405\n",
      "15043.232131958008\n",
      "Epoch [10/50], Batch 93/120, Train Loss: 155.2576\n",
      "15174.285446166992\n",
      "Epoch [10/50], Batch 94/120, Train Loss: 131.0533\n",
      "15350.638244628906\n",
      "Epoch [10/50], Batch 95/120, Train Loss: 176.3528\n",
      "15499.56753540039\n",
      "Epoch [10/50], Batch 96/120, Train Loss: 148.9293\n",
      "15673.531112670898\n",
      "Epoch [10/50], Batch 97/120, Train Loss: 173.9636\n",
      "15824.245590209961\n",
      "Epoch [10/50], Batch 98/120, Train Loss: 150.7145\n",
      "15981.74723815918\n",
      "Epoch [10/50], Batch 99/120, Train Loss: 157.5016\n",
      "16134.270858764648\n",
      "Epoch [10/50], Batch 100/120, Train Loss: 152.5236\n",
      "16300.112411499023\n",
      "Epoch [10/50], Batch 101/120, Train Loss: 165.8416\n",
      "16424.737426757812\n",
      "Epoch [10/50], Batch 102/120, Train Loss: 124.6250\n",
      "16550.527603149414\n",
      "Epoch [10/50], Batch 103/120, Train Loss: 125.7902\n",
      "16713.142181396484\n",
      "Epoch [10/50], Batch 104/120, Train Loss: 162.6146\n",
      "16837.822059631348\n",
      "Epoch [10/50], Batch 105/120, Train Loss: 124.6799\n",
      "16987.80182647705\n",
      "Epoch [10/50], Batch 106/120, Train Loss: 149.9798\n",
      "17146.89365386963\n",
      "Epoch [10/50], Batch 107/120, Train Loss: 159.0918\n",
      "17329.731147766113\n",
      "Epoch [10/50], Batch 108/120, Train Loss: 182.8375\n",
      "17445.27449798584\n",
      "Epoch [10/50], Batch 109/120, Train Loss: 115.5434\n",
      "17631.062980651855\n",
      "Epoch [10/50], Batch 110/120, Train Loss: 185.7885\n",
      "17777.797019958496\n",
      "Epoch [10/50], Batch 111/120, Train Loss: 146.7340\n",
      "17929.698066711426\n",
      "Epoch [10/50], Batch 112/120, Train Loss: 151.9010\n",
      "18073.876426696777\n",
      "Epoch [10/50], Batch 113/120, Train Loss: 144.1784\n",
      "18207.517417907715\n",
      "Epoch [10/50], Batch 114/120, Train Loss: 133.6410\n",
      "18324.913444519043\n",
      "Epoch [10/50], Batch 115/120, Train Loss: 117.3960\n",
      "18501.06406402588\n",
      "Epoch [10/50], Batch 116/120, Train Loss: 176.1506\n",
      "18668.460823059082\n",
      "Epoch [10/50], Batch 117/120, Train Loss: 167.3968\n",
      "18818.200233459473\n",
      "Epoch [10/50], Batch 118/120, Train Loss: 149.7394\n",
      "18954.82837677002\n",
      "Epoch [10/50], Batch 119/120, Train Loss: 136.6281\n",
      "19123.74599456787\n",
      "Epoch [10/50], Batch 120/120, Train Loss: 168.9176\n",
      "Epoch [10/50], Train Loss: 159.3645, Validation Loss: 156.0275\n",
      "145.4923095703125\n",
      "Epoch [11/50], Batch 1/120, Train Loss: 145.4923\n",
      "265.39334869384766\n",
      "Epoch [11/50], Batch 2/120, Train Loss: 119.9010\n",
      "417.6509475708008\n",
      "Epoch [11/50], Batch 3/120, Train Loss: 152.2576\n",
      "561.6203536987305\n",
      "Epoch [11/50], Batch 4/120, Train Loss: 143.9694\n",
      "694.2024917602539\n",
      "Epoch [11/50], Batch 5/120, Train Loss: 132.5821\n",
      "832.7858657836914\n",
      "Epoch [11/50], Batch 6/120, Train Loss: 138.5834\n",
      "963.8432998657227\n",
      "Epoch [11/50], Batch 7/120, Train Loss: 131.0574\n",
      "1127.514793395996\n",
      "Epoch [11/50], Batch 8/120, Train Loss: 163.6715\n",
      "1277.7242965698242\n",
      "Epoch [11/50], Batch 9/120, Train Loss: 150.2095\n",
      "1429.2797775268555\n",
      "Epoch [11/50], Batch 10/120, Train Loss: 151.5555\n",
      "1574.414436340332\n",
      "Epoch [11/50], Batch 11/120, Train Loss: 145.1347\n",
      "1724.2579727172852\n",
      "Epoch [11/50], Batch 12/120, Train Loss: 149.8435\n",
      "1868.4961624145508\n",
      "Epoch [11/50], Batch 13/120, Train Loss: 144.2382\n",
      "2032.755744934082\n",
      "Epoch [11/50], Batch 14/120, Train Loss: 164.2596\n",
      "2153.717887878418\n",
      "Epoch [11/50], Batch 15/120, Train Loss: 120.9621\n",
      "2281.394729614258\n",
      "Epoch [11/50], Batch 16/120, Train Loss: 127.6768\n",
      "2428.685317993164\n",
      "Epoch [11/50], Batch 17/120, Train Loss: 147.2906\n",
      "2596.845703125\n",
      "Epoch [11/50], Batch 18/120, Train Loss: 168.1604\n",
      "2736.3045501708984\n",
      "Epoch [11/50], Batch 19/120, Train Loss: 139.4588\n",
      "2902.3136444091797\n",
      "Epoch [11/50], Batch 20/120, Train Loss: 166.0091\n",
      "3037.7965545654297\n",
      "Epoch [11/50], Batch 21/120, Train Loss: 135.4829\n",
      "3191.5725860595703\n",
      "Epoch [11/50], Batch 22/120, Train Loss: 153.7760\n",
      "3328.112808227539\n",
      "Epoch [11/50], Batch 23/120, Train Loss: 136.5402\n",
      "3475.8135986328125\n",
      "Epoch [11/50], Batch 24/120, Train Loss: 147.7008\n",
      "3619.2713775634766\n",
      "Epoch [11/50], Batch 25/120, Train Loss: 143.4578\n",
      "3765.498336791992\n",
      "Epoch [11/50], Batch 26/120, Train Loss: 146.2270\n",
      "3907.134292602539\n",
      "Epoch [11/50], Batch 27/120, Train Loss: 141.6360\n",
      "4068.277084350586\n",
      "Epoch [11/50], Batch 28/120, Train Loss: 161.1428\n",
      "4182.4117431640625\n",
      "Epoch [11/50], Batch 29/120, Train Loss: 114.1347\n",
      "4318.188552856445\n",
      "Epoch [11/50], Batch 30/120, Train Loss: 135.7768\n",
      "4498.416061401367\n",
      "Epoch [11/50], Batch 31/120, Train Loss: 180.2275\n",
      "4629.547775268555\n",
      "Epoch [11/50], Batch 32/120, Train Loss: 131.1317\n",
      "4770.344543457031\n",
      "Epoch [11/50], Batch 33/120, Train Loss: 140.7968\n",
      "4909.797332763672\n",
      "Epoch [11/50], Batch 34/120, Train Loss: 139.4528\n",
      "5090.3157958984375\n",
      "Epoch [11/50], Batch 35/120, Train Loss: 180.5185\n",
      "5235.319763183594\n",
      "Epoch [11/50], Batch 36/120, Train Loss: 145.0040\n",
      "5423.47200012207\n",
      "Epoch [11/50], Batch 37/120, Train Loss: 188.1522\n",
      "5588.662582397461\n",
      "Epoch [11/50], Batch 38/120, Train Loss: 165.1906\n",
      "5729.099716186523\n",
      "Epoch [11/50], Batch 39/120, Train Loss: 140.4371\n",
      "5862.93962097168\n",
      "Epoch [11/50], Batch 40/120, Train Loss: 133.8399\n",
      "5987.202545166016\n",
      "Epoch [11/50], Batch 41/120, Train Loss: 124.2629\n",
      "6135.912490844727\n",
      "Epoch [11/50], Batch 42/120, Train Loss: 148.7099\n",
      "6297.31575012207\n",
      "Epoch [11/50], Batch 43/120, Train Loss: 161.4033\n",
      "6431.50862121582\n",
      "Epoch [11/50], Batch 44/120, Train Loss: 134.1929\n",
      "6567.416610717773\n",
      "Epoch [11/50], Batch 45/120, Train Loss: 135.9080\n",
      "6742.859420776367\n",
      "Epoch [11/50], Batch 46/120, Train Loss: 175.4428\n",
      "6907.187789916992\n",
      "Epoch [11/50], Batch 47/120, Train Loss: 164.3284\n",
      "7076.336410522461\n",
      "Epoch [11/50], Batch 48/120, Train Loss: 169.1486\n",
      "7256.976867675781\n",
      "Epoch [11/50], Batch 49/120, Train Loss: 180.6405\n",
      "7405.558685302734\n",
      "Epoch [11/50], Batch 50/120, Train Loss: 148.5818\n",
      "7522.958023071289\n",
      "Epoch [11/50], Batch 51/120, Train Loss: 117.3993\n",
      "7700.726791381836\n",
      "Epoch [11/50], Batch 52/120, Train Loss: 177.7688\n",
      "7859.928314208984\n",
      "Epoch [11/50], Batch 53/120, Train Loss: 159.2015\n",
      "7983.3227462768555\n",
      "Epoch [11/50], Batch 54/120, Train Loss: 123.3944\n",
      "8156.237083435059\n",
      "Epoch [11/50], Batch 55/120, Train Loss: 172.9143\n",
      "8302.205268859863\n",
      "Epoch [11/50], Batch 56/120, Train Loss: 145.9682\n",
      "8470.18970489502\n",
      "Epoch [11/50], Batch 57/120, Train Loss: 167.9844\n",
      "8640.981422424316\n",
      "Epoch [11/50], Batch 58/120, Train Loss: 170.7917\n",
      "8814.50788116455\n",
      "Epoch [11/50], Batch 59/120, Train Loss: 173.5265\n",
      "8967.168800354004\n",
      "Epoch [11/50], Batch 60/120, Train Loss: 152.6609\n",
      "9123.232124328613\n",
      "Epoch [11/50], Batch 61/120, Train Loss: 156.0633\n",
      "9309.769538879395\n",
      "Epoch [11/50], Batch 62/120, Train Loss: 186.5374\n",
      "9449.358787536621\n",
      "Epoch [11/50], Batch 63/120, Train Loss: 139.5892\n",
      "9599.828605651855\n",
      "Epoch [11/50], Batch 64/120, Train Loss: 150.4698\n",
      "9754.896156311035\n",
      "Epoch [11/50], Batch 65/120, Train Loss: 155.0676\n",
      "9875.87378692627\n",
      "Epoch [11/50], Batch 66/120, Train Loss: 120.9776\n",
      "10023.530433654785\n",
      "Epoch [11/50], Batch 67/120, Train Loss: 147.6566\n",
      "10190.2660446167\n",
      "Epoch [11/50], Batch 68/120, Train Loss: 166.7356\n",
      "10337.718849182129\n",
      "Epoch [11/50], Batch 69/120, Train Loss: 147.4528\n",
      "10494.665184020996\n",
      "Epoch [11/50], Batch 70/120, Train Loss: 156.9463\n",
      "10652.381065368652\n",
      "Epoch [11/50], Batch 71/120, Train Loss: 157.7159\n",
      "10793.531242370605\n",
      "Epoch [11/50], Batch 72/120, Train Loss: 141.1502\n",
      "10957.833686828613\n",
      "Epoch [11/50], Batch 73/120, Train Loss: 164.3024\n",
      "11082.234001159668\n",
      "Epoch [11/50], Batch 74/120, Train Loss: 124.4003\n",
      "11247.443870544434\n",
      "Epoch [11/50], Batch 75/120, Train Loss: 165.2099\n",
      "11378.281913757324\n",
      "Epoch [11/50], Batch 76/120, Train Loss: 130.8380\n",
      "11512.99373626709\n",
      "Epoch [11/50], Batch 77/120, Train Loss: 134.7118\n",
      "11658.377769470215\n",
      "Epoch [11/50], Batch 78/120, Train Loss: 145.3840\n",
      "11834.493629455566\n",
      "Epoch [11/50], Batch 79/120, Train Loss: 176.1159\n",
      "11976.210395812988\n",
      "Epoch [11/50], Batch 80/120, Train Loss: 141.7168\n",
      "12124.638160705566\n",
      "Epoch [11/50], Batch 81/120, Train Loss: 148.4278\n",
      "12288.036613464355\n",
      "Epoch [11/50], Batch 82/120, Train Loss: 163.3985\n",
      "12411.656860351562\n",
      "Epoch [11/50], Batch 83/120, Train Loss: 123.6202\n",
      "12563.309982299805\n",
      "Epoch [11/50], Batch 84/120, Train Loss: 151.6531\n",
      "12690.834732055664\n",
      "Epoch [11/50], Batch 85/120, Train Loss: 127.5247\n",
      "12822.1201171875\n",
      "Epoch [11/50], Batch 86/120, Train Loss: 131.2854\n",
      "13009.871643066406\n",
      "Epoch [11/50], Batch 87/120, Train Loss: 187.7515\n",
      "13120.513877868652\n",
      "Epoch [11/50], Batch 88/120, Train Loss: 110.6422\n",
      "13266.32738494873\n",
      "Epoch [11/50], Batch 89/120, Train Loss: 145.8135\n",
      "13383.706344604492\n",
      "Epoch [11/50], Batch 90/120, Train Loss: 117.3790\n",
      "13540.336380004883\n",
      "Epoch [11/50], Batch 91/120, Train Loss: 156.6300\n",
      "13688.603149414062\n",
      "Epoch [11/50], Batch 92/120, Train Loss: 148.2668\n",
      "13831.976745605469\n",
      "Epoch [11/50], Batch 93/120, Train Loss: 143.3736\n",
      "13985.929321289062\n",
      "Epoch [11/50], Batch 94/120, Train Loss: 153.9526\n",
      "14137.655868530273\n",
      "Epoch [11/50], Batch 95/120, Train Loss: 151.7265\n",
      "14286.330352783203\n",
      "Epoch [11/50], Batch 96/120, Train Loss: 148.6745\n",
      "14409.105522155762\n",
      "Epoch [11/50], Batch 97/120, Train Loss: 122.7752\n",
      "14544.727394104004\n",
      "Epoch [11/50], Batch 98/120, Train Loss: 135.6219\n",
      "14691.35083770752\n",
      "Epoch [11/50], Batch 99/120, Train Loss: 146.6234\n",
      "14809.139518737793\n",
      "Epoch [11/50], Batch 100/120, Train Loss: 117.7887\n",
      "14992.147468566895\n",
      "Epoch [11/50], Batch 101/120, Train Loss: 183.0079\n",
      "15134.071159362793\n",
      "Epoch [11/50], Batch 102/120, Train Loss: 141.9237\n",
      "15294.355094909668\n",
      "Epoch [11/50], Batch 103/120, Train Loss: 160.2839\n",
      "15454.022239685059\n",
      "Epoch [11/50], Batch 104/120, Train Loss: 159.6671\n",
      "15602.690284729004\n",
      "Epoch [11/50], Batch 105/120, Train Loss: 148.6680\n",
      "15731.209632873535\n",
      "Epoch [11/50], Batch 106/120, Train Loss: 128.5193\n",
      "15852.842468261719\n",
      "Epoch [11/50], Batch 107/120, Train Loss: 121.6328\n",
      "16003.766357421875\n",
      "Epoch [11/50], Batch 108/120, Train Loss: 150.9239\n",
      "16154.773620605469\n",
      "Epoch [11/50], Batch 109/120, Train Loss: 151.0073\n",
      "16291.248748779297\n",
      "Epoch [11/50], Batch 110/120, Train Loss: 136.4751\n",
      "16431.352966308594\n",
      "Epoch [11/50], Batch 111/120, Train Loss: 140.1042\n",
      "16558.69354248047\n",
      "Epoch [11/50], Batch 112/120, Train Loss: 127.3406\n",
      "16702.07373046875\n",
      "Epoch [11/50], Batch 113/120, Train Loss: 143.3802\n",
      "16846.37139892578\n",
      "Epoch [11/50], Batch 114/120, Train Loss: 144.2977\n",
      "16965.189895629883\n",
      "Epoch [11/50], Batch 115/120, Train Loss: 118.8185\n",
      "17120.142044067383\n",
      "Epoch [11/50], Batch 116/120, Train Loss: 154.9521\n",
      "17294.494338989258\n",
      "Epoch [11/50], Batch 117/120, Train Loss: 174.3523\n",
      "17436.14715576172\n",
      "Epoch [11/50], Batch 118/120, Train Loss: 141.6528\n",
      "17592.561614990234\n",
      "Epoch [11/50], Batch 119/120, Train Loss: 156.4145\n",
      "17716.88890838623\n",
      "Epoch [11/50], Batch 120/120, Train Loss: 124.3273\n",
      "Epoch [11/50], Train Loss: 147.6407, Validation Loss: 145.0788\n",
      "155.8912353515625\n",
      "Epoch [12/50], Batch 1/120, Train Loss: 155.8912\n",
      "316.4359130859375\n",
      "Epoch [12/50], Batch 2/120, Train Loss: 160.5447\n",
      "481.0207824707031\n",
      "Epoch [12/50], Batch 3/120, Train Loss: 164.5849\n",
      "658.8058471679688\n",
      "Epoch [12/50], Batch 4/120, Train Loss: 177.7851\n",
      "837.2148132324219\n",
      "Epoch [12/50], Batch 5/120, Train Loss: 178.4090\n",
      "942.4481887817383\n",
      "Epoch [12/50], Batch 6/120, Train Loss: 105.2334\n",
      "1077.886848449707\n",
      "Epoch [12/50], Batch 7/120, Train Loss: 135.4387\n",
      "1218.6470413208008\n",
      "Epoch [12/50], Batch 8/120, Train Loss: 140.7602\n",
      "1353.8390426635742\n",
      "Epoch [12/50], Batch 9/120, Train Loss: 135.1920\n",
      "1481.543357849121\n",
      "Epoch [12/50], Batch 10/120, Train Loss: 127.7043\n",
      "1624.0993423461914\n",
      "Epoch [12/50], Batch 11/120, Train Loss: 142.5560\n",
      "1767.5526962280273\n",
      "Epoch [12/50], Batch 12/120, Train Loss: 143.4534\n",
      "1906.0796737670898\n",
      "Epoch [12/50], Batch 13/120, Train Loss: 138.5270\n",
      "2053.031867980957\n",
      "Epoch [12/50], Batch 14/120, Train Loss: 146.9522\n",
      "2208.451972961426\n",
      "Epoch [12/50], Batch 15/120, Train Loss: 155.4201\n",
      "2343.02921295166\n",
      "Epoch [12/50], Batch 16/120, Train Loss: 134.5772\n",
      "2483.9939041137695\n",
      "Epoch [12/50], Batch 17/120, Train Loss: 140.9647\n",
      "2598.688148498535\n",
      "Epoch [12/50], Batch 18/120, Train Loss: 114.6942\n",
      "2759.7797927856445\n",
      "Epoch [12/50], Batch 19/120, Train Loss: 161.0916\n",
      "2910.0082473754883\n",
      "Epoch [12/50], Batch 20/120, Train Loss: 150.2285\n",
      "3014.76180267334\n",
      "Epoch [12/50], Batch 21/120, Train Loss: 104.7536\n",
      "3179.3066635131836\n",
      "Epoch [12/50], Batch 22/120, Train Loss: 164.5449\n",
      "3289.811065673828\n",
      "Epoch [12/50], Batch 23/120, Train Loss: 110.5044\n",
      "3407.477325439453\n",
      "Epoch [12/50], Batch 24/120, Train Loss: 117.6663\n",
      "3538.7722778320312\n",
      "Epoch [12/50], Batch 25/120, Train Loss: 131.2950\n",
      "3677.9507598876953\n",
      "Epoch [12/50], Batch 26/120, Train Loss: 139.1785\n",
      "3823.949264526367\n",
      "Epoch [12/50], Batch 27/120, Train Loss: 145.9985\n",
      "3974.9742279052734\n",
      "Epoch [12/50], Batch 28/120, Train Loss: 151.0250\n",
      "4105.016052246094\n",
      "Epoch [12/50], Batch 29/120, Train Loss: 130.0418\n",
      "4239.050109863281\n",
      "Epoch [12/50], Batch 30/120, Train Loss: 134.0341\n",
      "4374.833877563477\n",
      "Epoch [12/50], Batch 31/120, Train Loss: 135.7838\n",
      "4543.71842956543\n",
      "Epoch [12/50], Batch 32/120, Train Loss: 168.8846\n",
      "4677.884201049805\n",
      "Epoch [12/50], Batch 33/120, Train Loss: 134.1658\n",
      "4815.227691650391\n",
      "Epoch [12/50], Batch 34/120, Train Loss: 137.3435\n",
      "4912.151779174805\n",
      "Epoch [12/50], Batch 35/120, Train Loss: 96.9241\n",
      "5055.765609741211\n",
      "Epoch [12/50], Batch 36/120, Train Loss: 143.6138\n",
      "5213.8551025390625\n",
      "Epoch [12/50], Batch 37/120, Train Loss: 158.0895\n",
      "5346.923690795898\n",
      "Epoch [12/50], Batch 38/120, Train Loss: 133.0686\n",
      "5476.903030395508\n",
      "Epoch [12/50], Batch 39/120, Train Loss: 129.9793\n",
      "5605.885192871094\n",
      "Epoch [12/50], Batch 40/120, Train Loss: 128.9822\n",
      "5744.102020263672\n",
      "Epoch [12/50], Batch 41/120, Train Loss: 138.2168\n",
      "5889.519348144531\n",
      "Epoch [12/50], Batch 42/120, Train Loss: 145.4173\n",
      "6002.559410095215\n",
      "Epoch [12/50], Batch 43/120, Train Loss: 113.0401\n",
      "6130.330718994141\n",
      "Epoch [12/50], Batch 44/120, Train Loss: 127.7713\n",
      "6256.2729568481445\n",
      "Epoch [12/50], Batch 45/120, Train Loss: 125.9422\n",
      "6384.2649002075195\n",
      "Epoch [12/50], Batch 46/120, Train Loss: 127.9919\n",
      "6500.0190505981445\n",
      "Epoch [12/50], Batch 47/120, Train Loss: 115.7542\n",
      "6649.879615783691\n",
      "Epoch [12/50], Batch 48/120, Train Loss: 149.8606\n",
      "6772.285026550293\n",
      "Epoch [12/50], Batch 49/120, Train Loss: 122.4054\n",
      "6928.5859298706055\n",
      "Epoch [12/50], Batch 50/120, Train Loss: 156.3009\n",
      "7083.331123352051\n",
      "Epoch [12/50], Batch 51/120, Train Loss: 154.7452\n",
      "7246.017692565918\n",
      "Epoch [12/50], Batch 52/120, Train Loss: 162.6866\n",
      "7401.427513122559\n",
      "Epoch [12/50], Batch 53/120, Train Loss: 155.4098\n",
      "7566.472846984863\n",
      "Epoch [12/50], Batch 54/120, Train Loss: 165.0453\n",
      "7745.903846740723\n",
      "Epoch [12/50], Batch 55/120, Train Loss: 179.4310\n",
      "7888.957099914551\n",
      "Epoch [12/50], Batch 56/120, Train Loss: 143.0533\n",
      "8037.199195861816\n",
      "Epoch [12/50], Batch 57/120, Train Loss: 148.2421\n",
      "8202.881629943848\n",
      "Epoch [12/50], Batch 58/120, Train Loss: 165.6824\n",
      "8337.4556350708\n",
      "Epoch [12/50], Batch 59/120, Train Loss: 134.5740\n",
      "8483.623374938965\n",
      "Epoch [12/50], Batch 60/120, Train Loss: 146.1677\n",
      "8624.007316589355\n",
      "Epoch [12/50], Batch 61/120, Train Loss: 140.3839\n",
      "8743.683067321777\n",
      "Epoch [12/50], Batch 62/120, Train Loss: 119.6758\n",
      "8878.485862731934\n",
      "Epoch [12/50], Batch 63/120, Train Loss: 134.8028\n",
      "9027.65796661377\n",
      "Epoch [12/50], Batch 64/120, Train Loss: 149.1721\n",
      "9149.100730895996\n",
      "Epoch [12/50], Batch 65/120, Train Loss: 121.4428\n",
      "9271.048622131348\n",
      "Epoch [12/50], Batch 66/120, Train Loss: 121.9479\n",
      "9395.595375061035\n",
      "Epoch [12/50], Batch 67/120, Train Loss: 124.5468\n",
      "9482.173851013184\n",
      "Epoch [12/50], Batch 68/120, Train Loss: 86.5785\n",
      "9623.524681091309\n",
      "Epoch [12/50], Batch 69/120, Train Loss: 141.3508\n",
      "9764.629203796387\n",
      "Epoch [12/50], Batch 70/120, Train Loss: 141.1045\n",
      "9949.38762664795\n",
      "Epoch [12/50], Batch 71/120, Train Loss: 184.7584\n",
      "10085.539772033691\n",
      "Epoch [12/50], Batch 72/120, Train Loss: 136.1521\n",
      "10218.853889465332\n",
      "Epoch [12/50], Batch 73/120, Train Loss: 133.3141\n",
      "10338.134552001953\n",
      "Epoch [12/50], Batch 74/120, Train Loss: 119.2807\n",
      "10464.248657226562\n",
      "Epoch [12/50], Batch 75/120, Train Loss: 126.1141\n",
      "10629.977172851562\n",
      "Epoch [12/50], Batch 76/120, Train Loss: 165.7285\n",
      "10742.331817626953\n",
      "Epoch [12/50], Batch 77/120, Train Loss: 112.3546\n",
      "10898.538711547852\n",
      "Epoch [12/50], Batch 78/120, Train Loss: 156.2069\n",
      "11043.674209594727\n",
      "Epoch [12/50], Batch 79/120, Train Loss: 145.1355\n",
      "11167.885734558105\n",
      "Epoch [12/50], Batch 80/120, Train Loss: 124.2115\n",
      "11307.639060974121\n",
      "Epoch [12/50], Batch 81/120, Train Loss: 139.7533\n",
      "11439.517097473145\n",
      "Epoch [12/50], Batch 82/120, Train Loss: 131.8780\n",
      "11565.51773071289\n",
      "Epoch [12/50], Batch 83/120, Train Loss: 126.0006\n",
      "11706.009155273438\n",
      "Epoch [12/50], Batch 84/120, Train Loss: 140.4914\n",
      "11858.413925170898\n",
      "Epoch [12/50], Batch 85/120, Train Loss: 152.4048\n",
      "11990.991134643555\n",
      "Epoch [12/50], Batch 86/120, Train Loss: 132.5772\n",
      "12116.680366516113\n",
      "Epoch [12/50], Batch 87/120, Train Loss: 125.6892\n",
      "12259.446617126465\n",
      "Epoch [12/50], Batch 88/120, Train Loss: 142.7663\n",
      "12397.512306213379\n",
      "Epoch [12/50], Batch 89/120, Train Loss: 138.0657\n",
      "12556.488319396973\n",
      "Epoch [12/50], Batch 90/120, Train Loss: 158.9760\n",
      "12704.593223571777\n",
      "Epoch [12/50], Batch 91/120, Train Loss: 148.1049\n",
      "12837.799903869629\n",
      "Epoch [12/50], Batch 92/120, Train Loss: 133.2067\n",
      "12965.08080291748\n",
      "Epoch [12/50], Batch 93/120, Train Loss: 127.2809\n",
      "13094.657676696777\n",
      "Epoch [12/50], Batch 94/120, Train Loss: 129.5769\n",
      "13223.314567565918\n",
      "Epoch [12/50], Batch 95/120, Train Loss: 128.6569\n",
      "13349.404205322266\n",
      "Epoch [12/50], Batch 96/120, Train Loss: 126.0896\n",
      "13466.040802001953\n",
      "Epoch [12/50], Batch 97/120, Train Loss: 116.6366\n",
      "13589.491729736328\n",
      "Epoch [12/50], Batch 98/120, Train Loss: 123.4509\n",
      "13691.125122070312\n",
      "Epoch [12/50], Batch 99/120, Train Loss: 101.6334\n",
      "13826.478042602539\n",
      "Epoch [12/50], Batch 100/120, Train Loss: 135.3529\n",
      "13974.454788208008\n",
      "Epoch [12/50], Batch 101/120, Train Loss: 147.9767\n",
      "14104.839004516602\n",
      "Epoch [12/50], Batch 102/120, Train Loss: 130.3842\n",
      "14250.200653076172\n",
      "Epoch [12/50], Batch 103/120, Train Loss: 145.3616\n",
      "14374.992584228516\n",
      "Epoch [12/50], Batch 104/120, Train Loss: 124.7919\n",
      "14513.559814453125\n",
      "Epoch [12/50], Batch 105/120, Train Loss: 138.5672\n",
      "14620.179466247559\n",
      "Epoch [12/50], Batch 106/120, Train Loss: 106.6197\n",
      "14775.272758483887\n",
      "Epoch [12/50], Batch 107/120, Train Loss: 155.0933\n",
      "14896.600700378418\n",
      "Epoch [12/50], Batch 108/120, Train Loss: 121.3279\n",
      "15054.260414123535\n",
      "Epoch [12/50], Batch 109/120, Train Loss: 157.6597\n",
      "15202.529426574707\n",
      "Epoch [12/50], Batch 110/120, Train Loss: 148.2690\n",
      "15365.517585754395\n",
      "Epoch [12/50], Batch 111/120, Train Loss: 162.9882\n",
      "15472.590148925781\n",
      "Epoch [12/50], Batch 112/120, Train Loss: 107.0726\n",
      "15605.085754394531\n",
      "Epoch [12/50], Batch 113/120, Train Loss: 132.4956\n",
      "15741.467193603516\n",
      "Epoch [12/50], Batch 114/120, Train Loss: 136.3814\n",
      "15872.328125\n",
      "Epoch [12/50], Batch 115/120, Train Loss: 130.8609\n",
      "16022.73812866211\n",
      "Epoch [12/50], Batch 116/120, Train Loss: 150.4100\n",
      "16136.121948242188\n",
      "Epoch [12/50], Batch 117/120, Train Loss: 113.3838\n",
      "16281.643981933594\n",
      "Epoch [12/50], Batch 118/120, Train Loss: 145.5220\n",
      "16423.044494628906\n",
      "Epoch [12/50], Batch 119/120, Train Loss: 141.4005\n",
      "16548.238006591797\n",
      "Epoch [12/50], Batch 120/120, Train Loss: 125.1935\n",
      "Epoch [12/50], Train Loss: 137.9020, Validation Loss: 138.1866\n",
      "143.36099243164062\n",
      "Epoch [13/50], Batch 1/120, Train Loss: 143.3610\n",
      "252.56089782714844\n",
      "Epoch [13/50], Batch 2/120, Train Loss: 109.1999\n",
      "355.14683532714844\n",
      "Epoch [13/50], Batch 3/120, Train Loss: 102.5859\n",
      "493.62376403808594\n",
      "Epoch [13/50], Batch 4/120, Train Loss: 138.4769\n",
      "608.2875061035156\n",
      "Epoch [13/50], Batch 5/120, Train Loss: 114.6637\n",
      "726.9780883789062\n",
      "Epoch [13/50], Batch 6/120, Train Loss: 118.6906\n",
      "838.6491775512695\n",
      "Epoch [13/50], Batch 7/120, Train Loss: 111.6711\n",
      "944.174674987793\n",
      "Epoch [13/50], Batch 8/120, Train Loss: 105.5255\n",
      "1064.1988143920898\n",
      "Epoch [13/50], Batch 9/120, Train Loss: 120.0241\n",
      "1190.7178268432617\n",
      "Epoch [13/50], Batch 10/120, Train Loss: 126.5190\n",
      "1336.9987411499023\n",
      "Epoch [13/50], Batch 11/120, Train Loss: 146.2809\n",
      "1477.5858993530273\n",
      "Epoch [13/50], Batch 12/120, Train Loss: 140.5872\n",
      "1623.019676208496\n",
      "Epoch [13/50], Batch 13/120, Train Loss: 145.4338\n",
      "1783.2478408813477\n",
      "Epoch [13/50], Batch 14/120, Train Loss: 160.2282\n",
      "1918.2846145629883\n",
      "Epoch [13/50], Batch 15/120, Train Loss: 135.0368\n",
      "2061.8520431518555\n",
      "Epoch [13/50], Batch 16/120, Train Loss: 143.5674\n",
      "2236.390693664551\n",
      "Epoch [13/50], Batch 17/120, Train Loss: 174.5387\n",
      "2373.5922622680664\n",
      "Epoch [13/50], Batch 18/120, Train Loss: 137.2016\n",
      "2490.688865661621\n",
      "Epoch [13/50], Batch 19/120, Train Loss: 117.0966\n",
      "2608.543014526367\n",
      "Epoch [13/50], Batch 20/120, Train Loss: 117.8541\n",
      "2730.520347595215\n",
      "Epoch [13/50], Batch 21/120, Train Loss: 121.9773\n",
      "2847.634162902832\n",
      "Epoch [13/50], Batch 22/120, Train Loss: 117.1138\n",
      "2992.130439758301\n",
      "Epoch [13/50], Batch 23/120, Train Loss: 144.4963\n",
      "3092.7863235473633\n",
      "Epoch [13/50], Batch 24/120, Train Loss: 100.6559\n",
      "3219.0849227905273\n",
      "Epoch [13/50], Batch 25/120, Train Loss: 126.2986\n",
      "3365.1323165893555\n",
      "Epoch [13/50], Batch 26/120, Train Loss: 146.0474\n",
      "3524.792411804199\n",
      "Epoch [13/50], Batch 27/120, Train Loss: 159.6601\n",
      "3641.4530868530273\n",
      "Epoch [13/50], Batch 28/120, Train Loss: 116.6607\n",
      "3771.192283630371\n",
      "Epoch [13/50], Batch 29/120, Train Loss: 129.7392\n",
      "3879.319648742676\n",
      "Epoch [13/50], Batch 30/120, Train Loss: 108.1274\n",
      "4039.528694152832\n",
      "Epoch [13/50], Batch 31/120, Train Loss: 160.2090\n",
      "4129.180351257324\n",
      "Epoch [13/50], Batch 32/120, Train Loss: 89.6517\n",
      "4248.14973449707\n",
      "Epoch [13/50], Batch 33/120, Train Loss: 118.9694\n",
      "4392.839279174805\n",
      "Epoch [13/50], Batch 34/120, Train Loss: 144.6895\n",
      "4534.04231262207\n",
      "Epoch [13/50], Batch 35/120, Train Loss: 141.2030\n",
      "4662.9630126953125\n",
      "Epoch [13/50], Batch 36/120, Train Loss: 128.9207\n",
      "4783.84521484375\n",
      "Epoch [13/50], Batch 37/120, Train Loss: 120.8822\n",
      "4936.275634765625\n",
      "Epoch [13/50], Batch 38/120, Train Loss: 152.4304\n",
      "5076.797393798828\n",
      "Epoch [13/50], Batch 39/120, Train Loss: 140.5218\n",
      "5202.341171264648\n",
      "Epoch [13/50], Batch 40/120, Train Loss: 125.5438\n",
      "5347.85270690918\n",
      "Epoch [13/50], Batch 41/120, Train Loss: 145.5115\n",
      "5484.481063842773\n",
      "Epoch [13/50], Batch 42/120, Train Loss: 136.6284\n",
      "5628.971160888672\n",
      "Epoch [13/50], Batch 43/120, Train Loss: 144.4901\n",
      "5754.926803588867\n",
      "Epoch [13/50], Batch 44/120, Train Loss: 125.9556\n",
      "5895.385818481445\n",
      "Epoch [13/50], Batch 45/120, Train Loss: 140.4590\n",
      "6038.955795288086\n",
      "Epoch [13/50], Batch 46/120, Train Loss: 143.5700\n",
      "6169.063018798828\n",
      "Epoch [13/50], Batch 47/120, Train Loss: 130.1072\n",
      "6297.923980712891\n",
      "Epoch [13/50], Batch 48/120, Train Loss: 128.8610\n",
      "6437.945831298828\n",
      "Epoch [13/50], Batch 49/120, Train Loss: 140.0219\n",
      "6587.766876220703\n",
      "Epoch [13/50], Batch 50/120, Train Loss: 149.8210\n",
      "6722.584747314453\n",
      "Epoch [13/50], Batch 51/120, Train Loss: 134.8179\n",
      "6890.109146118164\n",
      "Epoch [13/50], Batch 52/120, Train Loss: 167.5244\n",
      "7023.777633666992\n",
      "Epoch [13/50], Batch 53/120, Train Loss: 133.6685\n",
      "7140.341773986816\n",
      "Epoch [13/50], Batch 54/120, Train Loss: 116.5641\n",
      "7262.544258117676\n",
      "Epoch [13/50], Batch 55/120, Train Loss: 122.2025\n",
      "7386.232566833496\n",
      "Epoch [13/50], Batch 56/120, Train Loss: 123.6883\n",
      "7518.800361633301\n",
      "Epoch [13/50], Batch 57/120, Train Loss: 132.5678\n",
      "7660.32218170166\n",
      "Epoch [13/50], Batch 58/120, Train Loss: 141.5218\n",
      "7797.8547439575195\n",
      "Epoch [13/50], Batch 59/120, Train Loss: 137.5326\n",
      "7929.512306213379\n",
      "Epoch [13/50], Batch 60/120, Train Loss: 131.6576\n",
      "8052.326286315918\n",
      "Epoch [13/50], Batch 61/120, Train Loss: 122.8140\n",
      "8199.426292419434\n",
      "Epoch [13/50], Batch 62/120, Train Loss: 147.1000\n",
      "8319.718055725098\n",
      "Epoch [13/50], Batch 63/120, Train Loss: 120.2918\n",
      "8449.764045715332\n",
      "Epoch [13/50], Batch 64/120, Train Loss: 130.0460\n",
      "8544.290046691895\n",
      "Epoch [13/50], Batch 65/120, Train Loss: 94.5260\n",
      "8683.17603302002\n",
      "Epoch [13/50], Batch 66/120, Train Loss: 138.8860\n",
      "8823.190406799316\n",
      "Epoch [13/50], Batch 67/120, Train Loss: 140.0144\n",
      "8925.33316040039\n",
      "Epoch [13/50], Batch 68/120, Train Loss: 102.1428\n",
      "9064.83706665039\n",
      "Epoch [13/50], Batch 69/120, Train Loss: 139.5039\n",
      "9198.036926269531\n",
      "Epoch [13/50], Batch 70/120, Train Loss: 133.1999\n",
      "9327.647094726562\n",
      "Epoch [13/50], Batch 71/120, Train Loss: 129.6102\n",
      "9473.601165771484\n",
      "Epoch [13/50], Batch 72/120, Train Loss: 145.9541\n",
      "9597.741432189941\n",
      "Epoch [13/50], Batch 73/120, Train Loss: 124.1403\n",
      "9746.435768127441\n",
      "Epoch [13/50], Batch 74/120, Train Loss: 148.6943\n",
      "9886.481056213379\n",
      "Epoch [13/50], Batch 75/120, Train Loss: 140.0453\n",
      "9999.402893066406\n",
      "Epoch [13/50], Batch 76/120, Train Loss: 112.9218\n",
      "10146.439178466797\n",
      "Epoch [13/50], Batch 77/120, Train Loss: 147.0363\n",
      "10259.671821594238\n",
      "Epoch [13/50], Batch 78/120, Train Loss: 113.2326\n",
      "10377.162612915039\n",
      "Epoch [13/50], Batch 79/120, Train Loss: 117.4908\n",
      "10486.249366760254\n",
      "Epoch [13/50], Batch 80/120, Train Loss: 109.0868\n",
      "10622.042808532715\n",
      "Epoch [13/50], Batch 81/120, Train Loss: 135.7934\n",
      "10710.319389343262\n",
      "Epoch [13/50], Batch 82/120, Train Loss: 88.2766\n",
      "10829.056884765625\n",
      "Epoch [13/50], Batch 83/120, Train Loss: 118.7375\n",
      "10943.087341308594\n",
      "Epoch [13/50], Batch 84/120, Train Loss: 114.0305\n",
      "11085.639587402344\n",
      "Epoch [13/50], Batch 85/120, Train Loss: 142.5522\n",
      "11210.251693725586\n",
      "Epoch [13/50], Batch 86/120, Train Loss: 124.6121\n",
      "11328.208084106445\n",
      "Epoch [13/50], Batch 87/120, Train Loss: 117.9564\n",
      "11468.03108215332\n",
      "Epoch [13/50], Batch 88/120, Train Loss: 139.8230\n",
      "11613.642013549805\n",
      "Epoch [13/50], Batch 89/120, Train Loss: 145.6109\n",
      "11732.488731384277\n",
      "Epoch [13/50], Batch 90/120, Train Loss: 118.8467\n",
      "11882.614250183105\n",
      "Epoch [13/50], Batch 91/120, Train Loss: 150.1255\n",
      "12007.79133605957\n",
      "Epoch [13/50], Batch 92/120, Train Loss: 125.1771\n",
      "12118.277725219727\n",
      "Epoch [13/50], Batch 93/120, Train Loss: 110.4864\n",
      "12302.69937133789\n",
      "Epoch [13/50], Batch 94/120, Train Loss: 184.4216\n",
      "12432.864181518555\n",
      "Epoch [13/50], Batch 95/120, Train Loss: 130.1648\n",
      "12574.322738647461\n",
      "Epoch [13/50], Batch 96/120, Train Loss: 141.4586\n",
      "12699.174835205078\n",
      "Epoch [13/50], Batch 97/120, Train Loss: 124.8521\n",
      "12827.445755004883\n",
      "Epoch [13/50], Batch 98/120, Train Loss: 128.2709\n",
      "12951.301773071289\n",
      "Epoch [13/50], Batch 99/120, Train Loss: 123.8560\n",
      "13062.85122680664\n",
      "Epoch [13/50], Batch 100/120, Train Loss: 111.5495\n",
      "13181.788696289062\n",
      "Epoch [13/50], Batch 101/120, Train Loss: 118.9375\n",
      "13309.51528930664\n",
      "Epoch [13/50], Batch 102/120, Train Loss: 127.7266\n",
      "13404.769134521484\n",
      "Epoch [13/50], Batch 103/120, Train Loss: 95.2538\n",
      "13507.31290435791\n",
      "Epoch [13/50], Batch 104/120, Train Loss: 102.5438\n",
      "13634.373756408691\n",
      "Epoch [13/50], Batch 105/120, Train Loss: 127.0609\n",
      "13780.724586486816\n",
      "Epoch [13/50], Batch 106/120, Train Loss: 146.3508\n",
      "13904.368644714355\n",
      "Epoch [13/50], Batch 107/120, Train Loss: 123.6441\n",
      "14019.931884765625\n",
      "Epoch [13/50], Batch 108/120, Train Loss: 115.5632\n",
      "14133.212158203125\n",
      "Epoch [13/50], Batch 109/120, Train Loss: 113.2803\n",
      "14265.403839111328\n",
      "Epoch [13/50], Batch 110/120, Train Loss: 132.1917\n",
      "14401.381439208984\n",
      "Epoch [13/50], Batch 111/120, Train Loss: 135.9776\n",
      "14522.86238861084\n",
      "Epoch [13/50], Batch 112/120, Train Loss: 121.4809\n",
      "14661.093849182129\n",
      "Epoch [13/50], Batch 113/120, Train Loss: 138.2315\n",
      "14785.414283752441\n",
      "Epoch [13/50], Batch 114/120, Train Loss: 124.3204\n",
      "14882.758934020996\n",
      "Epoch [13/50], Batch 115/120, Train Loss: 97.3447\n",
      "14991.276237487793\n",
      "Epoch [13/50], Batch 116/120, Train Loss: 108.5173\n",
      "15144.526847839355\n",
      "Epoch [13/50], Batch 117/120, Train Loss: 153.2506\n",
      "15281.532402038574\n",
      "Epoch [13/50], Batch 118/120, Train Loss: 137.0056\n",
      "15404.028343200684\n",
      "Epoch [13/50], Batch 119/120, Train Loss: 122.4959\n",
      "15558.315452575684\n",
      "Epoch [13/50], Batch 120/120, Train Loss: 154.2871\n",
      "Epoch [13/50], Train Loss: 129.6526, Validation Loss: 131.8953\n",
      "126.3907470703125\n",
      "Epoch [14/50], Batch 1/120, Train Loss: 126.3907\n",
      "279.5020751953125\n",
      "Epoch [14/50], Batch 2/120, Train Loss: 153.1113\n",
      "448.9678039550781\n",
      "Epoch [14/50], Batch 3/120, Train Loss: 169.4657\n",
      "558.8801116943359\n",
      "Epoch [14/50], Batch 4/120, Train Loss: 109.9123\n",
      "676.2385940551758\n",
      "Epoch [14/50], Batch 5/120, Train Loss: 117.3585\n",
      "788.3672714233398\n",
      "Epoch [14/50], Batch 6/120, Train Loss: 112.1287\n",
      "923.343132019043\n",
      "Epoch [14/50], Batch 7/120, Train Loss: 134.9759\n",
      "1031.1371536254883\n",
      "Epoch [14/50], Batch 8/120, Train Loss: 107.7940\n",
      "1135.9195022583008\n",
      "Epoch [14/50], Batch 9/120, Train Loss: 104.7823\n",
      "1263.9913711547852\n",
      "Epoch [14/50], Batch 10/120, Train Loss: 128.0719\n",
      "1369.3079986572266\n",
      "Epoch [14/50], Batch 11/120, Train Loss: 105.3166\n",
      "1500.9207763671875\n",
      "Epoch [14/50], Batch 12/120, Train Loss: 131.6128\n",
      "1616.9979553222656\n",
      "Epoch [14/50], Batch 13/120, Train Loss: 116.0772\n",
      "1741.7255096435547\n",
      "Epoch [14/50], Batch 14/120, Train Loss: 124.7276\n",
      "1903.9700317382812\n",
      "Epoch [14/50], Batch 15/120, Train Loss: 162.2445\n",
      "2018.2377471923828\n",
      "Epoch [14/50], Batch 16/120, Train Loss: 114.2677\n",
      "2149.309585571289\n",
      "Epoch [14/50], Batch 17/120, Train Loss: 131.0718\n",
      "2257.9878692626953\n",
      "Epoch [14/50], Batch 18/120, Train Loss: 108.6783\n",
      "2383.781913757324\n",
      "Epoch [14/50], Batch 19/120, Train Loss: 125.7940\n",
      "2498.1291732788086\n",
      "Epoch [14/50], Batch 20/120, Train Loss: 114.3473\n",
      "2626.2263107299805\n",
      "Epoch [14/50], Batch 21/120, Train Loss: 128.0971\n",
      "2775.306083679199\n",
      "Epoch [14/50], Batch 22/120, Train Loss: 149.0798\n",
      "2889.1133575439453\n",
      "Epoch [14/50], Batch 23/120, Train Loss: 113.8073\n",
      "3004.486862182617\n",
      "Epoch [14/50], Batch 24/120, Train Loss: 115.3735\n",
      "3127.893798828125\n",
      "Epoch [14/50], Batch 25/120, Train Loss: 123.4069\n",
      "3272.409194946289\n",
      "Epoch [14/50], Batch 26/120, Train Loss: 144.5154\n",
      "3403.1534881591797\n",
      "Epoch [14/50], Batch 27/120, Train Loss: 130.7443\n",
      "3547.455322265625\n",
      "Epoch [14/50], Batch 28/120, Train Loss: 144.3018\n",
      "3631.482246398926\n",
      "Epoch [14/50], Batch 29/120, Train Loss: 84.0269\n",
      "3753.9155883789062\n",
      "Epoch [14/50], Batch 30/120, Train Loss: 122.4333\n",
      "3910.264373779297\n",
      "Epoch [14/50], Batch 31/120, Train Loss: 156.3488\n",
      "4016.5707931518555\n",
      "Epoch [14/50], Batch 32/120, Train Loss: 106.3064\n",
      "4155.972297668457\n",
      "Epoch [14/50], Batch 33/120, Train Loss: 139.4015\n",
      "4273.778167724609\n",
      "Epoch [14/50], Batch 34/120, Train Loss: 117.8059\n",
      "4384.672576904297\n",
      "Epoch [14/50], Batch 35/120, Train Loss: 110.8944\n",
      "4505.072830200195\n",
      "Epoch [14/50], Batch 36/120, Train Loss: 120.4003\n",
      "4629.321968078613\n",
      "Epoch [14/50], Batch 37/120, Train Loss: 124.2491\n",
      "4741.113822937012\n",
      "Epoch [14/50], Batch 38/120, Train Loss: 111.7919\n",
      "4849.402671813965\n",
      "Epoch [14/50], Batch 39/120, Train Loss: 108.2888\n",
      "4984.506187438965\n",
      "Epoch [14/50], Batch 40/120, Train Loss: 135.1035\n",
      "5105.5004959106445\n",
      "Epoch [14/50], Batch 41/120, Train Loss: 120.9943\n",
      "5229.453384399414\n",
      "Epoch [14/50], Batch 42/120, Train Loss: 123.9529\n",
      "5366.83576965332\n",
      "Epoch [14/50], Batch 43/120, Train Loss: 137.3824\n",
      "5490.866119384766\n",
      "Epoch [14/50], Batch 44/120, Train Loss: 124.0303\n",
      "5613.917572021484\n",
      "Epoch [14/50], Batch 45/120, Train Loss: 123.0515\n",
      "5748.414581298828\n",
      "Epoch [14/50], Batch 46/120, Train Loss: 134.4970\n",
      "5860.903701782227\n",
      "Epoch [14/50], Batch 47/120, Train Loss: 112.4891\n",
      "5957.327529907227\n",
      "Epoch [14/50], Batch 48/120, Train Loss: 96.4238\n",
      "6076.472808837891\n",
      "Epoch [14/50], Batch 49/120, Train Loss: 119.1453\n",
      "6187.973220825195\n",
      "Epoch [14/50], Batch 50/120, Train Loss: 111.5004\n",
      "6308.288757324219\n",
      "Epoch [14/50], Batch 51/120, Train Loss: 120.3155\n",
      "6430.463836669922\n",
      "Epoch [14/50], Batch 52/120, Train Loss: 122.1751\n",
      "6572.814239501953\n",
      "Epoch [14/50], Batch 53/120, Train Loss: 142.3504\n",
      "6669.469085693359\n",
      "Epoch [14/50], Batch 54/120, Train Loss: 96.6548\n",
      "6815.75537109375\n",
      "Epoch [14/50], Batch 55/120, Train Loss: 146.2863\n",
      "6925.908493041992\n",
      "Epoch [14/50], Batch 56/120, Train Loss: 110.1531\n",
      "7057.910415649414\n",
      "Epoch [14/50], Batch 57/120, Train Loss: 132.0019\n",
      "7173.813194274902\n",
      "Epoch [14/50], Batch 58/120, Train Loss: 115.9028\n",
      "7303.3893966674805\n",
      "Epoch [14/50], Batch 59/120, Train Loss: 129.5762\n",
      "7413.484191894531\n",
      "Epoch [14/50], Batch 60/120, Train Loss: 110.0948\n",
      "7500.432067871094\n",
      "Epoch [14/50], Batch 61/120, Train Loss: 86.9479\n",
      "7625.072082519531\n",
      "Epoch [14/50], Batch 62/120, Train Loss: 124.6400\n",
      "7751.596603393555\n",
      "Epoch [14/50], Batch 63/120, Train Loss: 126.5245\n",
      "7860.179794311523\n",
      "Epoch [14/50], Batch 64/120, Train Loss: 108.5832\n",
      "7994.068511962891\n",
      "Epoch [14/50], Batch 65/120, Train Loss: 133.8887\n",
      "8143.029235839844\n",
      "Epoch [14/50], Batch 66/120, Train Loss: 148.9607\n",
      "8264.642951965332\n",
      "Epoch [14/50], Batch 67/120, Train Loss: 121.6137\n",
      "8399.776268005371\n",
      "Epoch [14/50], Batch 68/120, Train Loss: 135.1333\n",
      "8523.338882446289\n",
      "Epoch [14/50], Batch 69/120, Train Loss: 123.5626\n",
      "8655.817672729492\n",
      "Epoch [14/50], Batch 70/120, Train Loss: 132.4788\n",
      "8816.156234741211\n",
      "Epoch [14/50], Batch 71/120, Train Loss: 160.3386\n",
      "8957.095779418945\n",
      "Epoch [14/50], Batch 72/120, Train Loss: 140.9395\n",
      "9119.39486694336\n",
      "Epoch [14/50], Batch 73/120, Train Loss: 162.2991\n",
      "9258.89761352539\n",
      "Epoch [14/50], Batch 74/120, Train Loss: 139.5027\n",
      "9369.860038757324\n",
      "Epoch [14/50], Batch 75/120, Train Loss: 110.9624\n",
      "9495.843994140625\n",
      "Epoch [14/50], Batch 76/120, Train Loss: 125.9840\n",
      "9621.450309753418\n",
      "Epoch [14/50], Batch 77/120, Train Loss: 125.6063\n",
      "9699.732200622559\n",
      "Epoch [14/50], Batch 78/120, Train Loss: 78.2819\n",
      "9835.702415466309\n",
      "Epoch [14/50], Batch 79/120, Train Loss: 135.9702\n",
      "9932.138710021973\n",
      "Epoch [14/50], Batch 80/120, Train Loss: 96.4363\n",
      "10039.714645385742\n",
      "Epoch [14/50], Batch 81/120, Train Loss: 107.5759\n",
      "10146.052993774414\n",
      "Epoch [14/50], Batch 82/120, Train Loss: 106.3383\n",
      "10281.342666625977\n",
      "Epoch [14/50], Batch 83/120, Train Loss: 135.2897\n",
      "10407.798904418945\n",
      "Epoch [14/50], Batch 84/120, Train Loss: 126.4562\n",
      "10544.451263427734\n",
      "Epoch [14/50], Batch 85/120, Train Loss: 136.6524\n",
      "10659.192916870117\n",
      "Epoch [14/50], Batch 86/120, Train Loss: 114.7417\n",
      "10799.747650146484\n",
      "Epoch [14/50], Batch 87/120, Train Loss: 140.5547\n",
      "10954.039276123047\n",
      "Epoch [14/50], Batch 88/120, Train Loss: 154.2916\n",
      "11076.38451385498\n",
      "Epoch [14/50], Batch 89/120, Train Loss: 122.3452\n",
      "11202.28988647461\n",
      "Epoch [14/50], Batch 90/120, Train Loss: 125.9054\n",
      "11342.029647827148\n",
      "Epoch [14/50], Batch 91/120, Train Loss: 139.7398\n",
      "11455.1953125\n",
      "Epoch [14/50], Batch 92/120, Train Loss: 113.1657\n",
      "11569.314666748047\n",
      "Epoch [14/50], Batch 93/120, Train Loss: 114.1194\n",
      "11701.70573425293\n",
      "Epoch [14/50], Batch 94/120, Train Loss: 132.3911\n",
      "11796.34538269043\n",
      "Epoch [14/50], Batch 95/120, Train Loss: 94.6396\n",
      "11920.930892944336\n",
      "Epoch [14/50], Batch 96/120, Train Loss: 124.5855\n",
      "12042.771392822266\n",
      "Epoch [14/50], Batch 97/120, Train Loss: 121.8405\n",
      "12162.858856201172\n",
      "Epoch [14/50], Batch 98/120, Train Loss: 120.0875\n",
      "12295.279006958008\n",
      "Epoch [14/50], Batch 99/120, Train Loss: 132.4202\n",
      "12422.155044555664\n",
      "Epoch [14/50], Batch 100/120, Train Loss: 126.8760\n",
      "12558.998825073242\n",
      "Epoch [14/50], Batch 101/120, Train Loss: 136.8438\n",
      "12685.686065673828\n",
      "Epoch [14/50], Batch 102/120, Train Loss: 126.6872\n",
      "12790.742057800293\n",
      "Epoch [14/50], Batch 103/120, Train Loss: 105.0560\n",
      "12906.142639160156\n",
      "Epoch [14/50], Batch 104/120, Train Loss: 115.4006\n",
      "13040.732635498047\n",
      "Epoch [14/50], Batch 105/120, Train Loss: 134.5900\n",
      "13189.009384155273\n",
      "Epoch [14/50], Batch 106/120, Train Loss: 148.2767\n",
      "13259.722595214844\n",
      "Epoch [14/50], Batch 107/120, Train Loss: 70.7132\n",
      "13387.348236083984\n",
      "Epoch [14/50], Batch 108/120, Train Loss: 127.6256\n",
      "13519.19271850586\n",
      "Epoch [14/50], Batch 109/120, Train Loss: 131.8445\n",
      "13619.005424499512\n",
      "Epoch [14/50], Batch 110/120, Train Loss: 99.8127\n",
      "13749.724723815918\n",
      "Epoch [14/50], Batch 111/120, Train Loss: 130.7193\n",
      "13876.13582611084\n",
      "Epoch [14/50], Batch 112/120, Train Loss: 126.4111\n",
      "13981.505531311035\n",
      "Epoch [14/50], Batch 113/120, Train Loss: 105.3697\n",
      "14074.28645324707\n",
      "Epoch [14/50], Batch 114/120, Train Loss: 92.7809\n",
      "14222.710494995117\n",
      "Epoch [14/50], Batch 115/120, Train Loss: 148.4240\n",
      "14324.152305603027\n",
      "Epoch [14/50], Batch 116/120, Train Loss: 101.4418\n",
      "14438.088569641113\n",
      "Epoch [14/50], Batch 117/120, Train Loss: 113.9363\n",
      "14558.520896911621\n",
      "Epoch [14/50], Batch 118/120, Train Loss: 120.4323\n",
      "14678.388160705566\n",
      "Epoch [14/50], Batch 119/120, Train Loss: 119.8673\n",
      "14761.19709777832\n",
      "Epoch [14/50], Batch 120/120, Train Loss: 82.8089\n",
      "Epoch [14/50], Train Loss: 123.0100, Validation Loss: 127.6708\n",
      "111.87954711914062\n",
      "Epoch [15/50], Batch 1/120, Train Loss: 111.8795\n",
      "236.73069763183594\n",
      "Epoch [15/50], Batch 2/120, Train Loss: 124.8512\n",
      "341.1919860839844\n",
      "Epoch [15/50], Batch 3/120, Train Loss: 104.4613\n",
      "483.5507354736328\n",
      "Epoch [15/50], Batch 4/120, Train Loss: 142.3587\n",
      "608.9491729736328\n",
      "Epoch [15/50], Batch 5/120, Train Loss: 125.3984\n",
      "742.8909454345703\n",
      "Epoch [15/50], Batch 6/120, Train Loss: 133.9418\n",
      "873.3883056640625\n",
      "Epoch [15/50], Batch 7/120, Train Loss: 130.4974\n",
      "1007.6728515625\n",
      "Epoch [15/50], Batch 8/120, Train Loss: 134.2845\n",
      "1095.3064422607422\n",
      "Epoch [15/50], Batch 9/120, Train Loss: 87.6336\n",
      "1209.5376358032227\n",
      "Epoch [15/50], Batch 10/120, Train Loss: 114.2312\n",
      "1320.8440551757812\n",
      "Epoch [15/50], Batch 11/120, Train Loss: 111.3064\n",
      "1435.0265350341797\n",
      "Epoch [15/50], Batch 12/120, Train Loss: 114.1825\n",
      "1561.4546356201172\n",
      "Epoch [15/50], Batch 13/120, Train Loss: 126.4281\n",
      "1692.357925415039\n",
      "Epoch [15/50], Batch 14/120, Train Loss: 130.9033\n",
      "1801.631690979004\n",
      "Epoch [15/50], Batch 15/120, Train Loss: 109.2738\n",
      "1933.7805557250977\n",
      "Epoch [15/50], Batch 16/120, Train Loss: 132.1489\n",
      "2084.1974563598633\n",
      "Epoch [15/50], Batch 17/120, Train Loss: 150.4169\n",
      "2192.31160736084\n",
      "Epoch [15/50], Batch 18/120, Train Loss: 108.1142\n",
      "2318.0129623413086\n",
      "Epoch [15/50], Batch 19/120, Train Loss: 125.7014\n",
      "2421.4453125\n",
      "Epoch [15/50], Batch 20/120, Train Loss: 103.4324\n",
      "2548.9741287231445\n",
      "Epoch [15/50], Batch 21/120, Train Loss: 127.5288\n",
      "2677.7881240844727\n",
      "Epoch [15/50], Batch 22/120, Train Loss: 128.8140\n",
      "2776.734275817871\n",
      "Epoch [15/50], Batch 23/120, Train Loss: 98.9462\n",
      "2901.4883880615234\n",
      "Epoch [15/50], Batch 24/120, Train Loss: 124.7541\n",
      "3024.002342224121\n",
      "Epoch [15/50], Batch 25/120, Train Loss: 122.5140\n",
      "3128.1577072143555\n",
      "Epoch [15/50], Batch 26/120, Train Loss: 104.1554\n",
      "3245.3584213256836\n",
      "Epoch [15/50], Batch 27/120, Train Loss: 117.2007\n",
      "3352.651512145996\n",
      "Epoch [15/50], Batch 28/120, Train Loss: 107.2931\n",
      "3498.97420501709\n",
      "Epoch [15/50], Batch 29/120, Train Loss: 146.3227\n",
      "3632.703727722168\n",
      "Epoch [15/50], Batch 30/120, Train Loss: 133.7295\n",
      "3741.785301208496\n",
      "Epoch [15/50], Batch 31/120, Train Loss: 109.0816\n",
      "3882.664390563965\n",
      "Epoch [15/50], Batch 32/120, Train Loss: 140.8791\n",
      "4001.464179992676\n",
      "Epoch [15/50], Batch 33/120, Train Loss: 118.7998\n",
      "4111.377990722656\n",
      "Epoch [15/50], Batch 34/120, Train Loss: 109.9138\n",
      "4239.857376098633\n",
      "Epoch [15/50], Batch 35/120, Train Loss: 128.4794\n",
      "4354.027374267578\n",
      "Epoch [15/50], Batch 36/120, Train Loss: 114.1700\n",
      "4488.023468017578\n",
      "Epoch [15/50], Batch 37/120, Train Loss: 133.9961\n",
      "4614.165298461914\n",
      "Epoch [15/50], Batch 38/120, Train Loss: 126.1418\n",
      "4763.552291870117\n",
      "Epoch [15/50], Batch 39/120, Train Loss: 149.3870\n",
      "4887.2202072143555\n",
      "Epoch [15/50], Batch 40/120, Train Loss: 123.6679\n",
      "5011.550163269043\n",
      "Epoch [15/50], Batch 41/120, Train Loss: 124.3300\n",
      "5109.0295486450195\n",
      "Epoch [15/50], Batch 42/120, Train Loss: 97.4794\n",
      "5224.9289627075195\n",
      "Epoch [15/50], Batch 43/120, Train Loss: 115.8994\n",
      "5360.062843322754\n",
      "Epoch [15/50], Batch 44/120, Train Loss: 135.1339\n",
      "5488.43839263916\n",
      "Epoch [15/50], Batch 45/120, Train Loss: 128.3755\n",
      "5625.831275939941\n",
      "Epoch [15/50], Batch 46/120, Train Loss: 137.3929\n",
      "5724.654716491699\n",
      "Epoch [15/50], Batch 47/120, Train Loss: 98.8234\n",
      "5836.27384185791\n",
      "Epoch [15/50], Batch 48/120, Train Loss: 111.6191\n",
      "5940.899482727051\n",
      "Epoch [15/50], Batch 49/120, Train Loss: 104.6256\n",
      "6063.917930603027\n",
      "Epoch [15/50], Batch 50/120, Train Loss: 123.0184\n",
      "6169.464920043945\n",
      "Epoch [15/50], Batch 51/120, Train Loss: 105.5470\n",
      "6307.568069458008\n",
      "Epoch [15/50], Batch 52/120, Train Loss: 138.1031\n",
      "6431.7058181762695\n",
      "Epoch [15/50], Batch 53/120, Train Loss: 124.1377\n",
      "6538.774208068848\n",
      "Epoch [15/50], Batch 54/120, Train Loss: 107.0684\n",
      "6664.15641784668\n",
      "Epoch [15/50], Batch 55/120, Train Loss: 125.3822\n",
      "6778.235969543457\n",
      "Epoch [15/50], Batch 56/120, Train Loss: 114.0796\n",
      "6892.709190368652\n",
      "Epoch [15/50], Batch 57/120, Train Loss: 114.4732\n",
      "6983.088470458984\n",
      "Epoch [15/50], Batch 58/120, Train Loss: 90.3793\n",
      "7091.921607971191\n",
      "Epoch [15/50], Batch 59/120, Train Loss: 108.8331\n",
      "7184.522727966309\n",
      "Epoch [15/50], Batch 60/120, Train Loss: 92.6011\n",
      "7323.547492980957\n",
      "Epoch [15/50], Batch 61/120, Train Loss: 139.0248\n",
      "7446.915916442871\n",
      "Epoch [15/50], Batch 62/120, Train Loss: 123.3684\n",
      "7566.803245544434\n",
      "Epoch [15/50], Batch 63/120, Train Loss: 119.8873\n",
      "7691.500770568848\n",
      "Epoch [15/50], Batch 64/120, Train Loss: 124.6975\n",
      "7804.51212310791\n",
      "Epoch [15/50], Batch 65/120, Train Loss: 113.0114\n",
      "7915.491630554199\n",
      "Epoch [15/50], Batch 66/120, Train Loss: 110.9795\n",
      "8057.261360168457\n",
      "Epoch [15/50], Batch 67/120, Train Loss: 141.7697\n",
      "8182.628303527832\n",
      "Epoch [15/50], Batch 68/120, Train Loss: 125.3669\n",
      "8298.158279418945\n",
      "Epoch [15/50], Batch 69/120, Train Loss: 115.5300\n",
      "8446.30451965332\n",
      "Epoch [15/50], Batch 70/120, Train Loss: 148.1462\n",
      "8592.711685180664\n",
      "Epoch [15/50], Batch 71/120, Train Loss: 146.4072\n",
      "8694.854553222656\n",
      "Epoch [15/50], Batch 72/120, Train Loss: 102.1429\n",
      "8798.292510986328\n",
      "Epoch [15/50], Batch 73/120, Train Loss: 103.4380\n",
      "8901.030364990234\n",
      "Epoch [15/50], Batch 74/120, Train Loss: 102.7379\n",
      "9038.311218261719\n",
      "Epoch [15/50], Batch 75/120, Train Loss: 137.2809\n",
      "9170.3251953125\n",
      "Epoch [15/50], Batch 76/120, Train Loss: 132.0140\n",
      "9280.916015625\n",
      "Epoch [15/50], Batch 77/120, Train Loss: 110.5908\n",
      "9374.192764282227\n",
      "Epoch [15/50], Batch 78/120, Train Loss: 93.2767\n",
      "9477.715255737305\n",
      "Epoch [15/50], Batch 79/120, Train Loss: 103.5225\n",
      "9580.981399536133\n",
      "Epoch [15/50], Batch 80/120, Train Loss: 103.2661\n",
      "9703.791137695312\n",
      "Epoch [15/50], Batch 81/120, Train Loss: 122.8097\n",
      "9803.579940795898\n",
      "Epoch [15/50], Batch 82/120, Train Loss: 99.7888\n",
      "9914.1099319458\n",
      "Epoch [15/50], Batch 83/120, Train Loss: 110.5300\n",
      "10045.96996307373\n",
      "Epoch [15/50], Batch 84/120, Train Loss: 131.8600\n",
      "10145.25269317627\n",
      "Epoch [15/50], Batch 85/120, Train Loss: 99.2827\n",
      "10264.945579528809\n",
      "Epoch [15/50], Batch 86/120, Train Loss: 119.6929\n",
      "10364.869804382324\n",
      "Epoch [15/50], Batch 87/120, Train Loss: 99.9242\n",
      "10465.995246887207\n",
      "Epoch [15/50], Batch 88/120, Train Loss: 101.1254\n",
      "10569.110694885254\n",
      "Epoch [15/50], Batch 89/120, Train Loss: 103.1154\n",
      "10704.432929992676\n",
      "Epoch [15/50], Batch 90/120, Train Loss: 135.3222\n",
      "10815.538673400879\n",
      "Epoch [15/50], Batch 91/120, Train Loss: 111.1057\n",
      "10938.250755310059\n",
      "Epoch [15/50], Batch 92/120, Train Loss: 122.7121\n",
      "11059.296073913574\n",
      "Epoch [15/50], Batch 93/120, Train Loss: 121.0453\n",
      "11191.283073425293\n",
      "Epoch [15/50], Batch 94/120, Train Loss: 131.9870\n",
      "11308.481185913086\n",
      "Epoch [15/50], Batch 95/120, Train Loss: 117.1981\n",
      "11414.830932617188\n",
      "Epoch [15/50], Batch 96/120, Train Loss: 106.3497\n",
      "11527.13899230957\n",
      "Epoch [15/50], Batch 97/120, Train Loss: 112.3081\n",
      "11655.490127563477\n",
      "Epoch [15/50], Batch 98/120, Train Loss: 128.3511\n",
      "11786.17887878418\n",
      "Epoch [15/50], Batch 99/120, Train Loss: 130.6888\n",
      "11894.642059326172\n",
      "Epoch [15/50], Batch 100/120, Train Loss: 108.4632\n",
      "12022.46646118164\n",
      "Epoch [15/50], Batch 101/120, Train Loss: 127.8244\n",
      "12149.762176513672\n",
      "Epoch [15/50], Batch 102/120, Train Loss: 127.2957\n",
      "12275.1781539917\n",
      "Epoch [15/50], Batch 103/120, Train Loss: 125.4160\n",
      "12411.169151306152\n",
      "Epoch [15/50], Batch 104/120, Train Loss: 135.9910\n",
      "12528.493934631348\n",
      "Epoch [15/50], Batch 105/120, Train Loss: 117.3248\n",
      "12642.428634643555\n",
      "Epoch [15/50], Batch 106/120, Train Loss: 113.9347\n",
      "12760.557510375977\n",
      "Epoch [15/50], Batch 107/120, Train Loss: 118.1289\n",
      "12885.568649291992\n",
      "Epoch [15/50], Batch 108/120, Train Loss: 125.0111\n",
      "13005.186470031738\n",
      "Epoch [15/50], Batch 109/120, Train Loss: 119.6178\n",
      "13126.895561218262\n",
      "Epoch [15/50], Batch 110/120, Train Loss: 121.7091\n",
      "13226.420997619629\n",
      "Epoch [15/50], Batch 111/120, Train Loss: 99.5254\n",
      "13324.880104064941\n",
      "Epoch [15/50], Batch 112/120, Train Loss: 98.4591\n",
      "13428.32479095459\n",
      "Epoch [15/50], Batch 113/120, Train Loss: 103.4447\n",
      "13544.073554992676\n",
      "Epoch [15/50], Batch 114/120, Train Loss: 115.7488\n",
      "13667.80142211914\n",
      "Epoch [15/50], Batch 115/120, Train Loss: 123.7279\n",
      "13802.016387939453\n",
      "Epoch [15/50], Batch 116/120, Train Loss: 134.2150\n",
      "13913.413215637207\n",
      "Epoch [15/50], Batch 117/120, Train Loss: 111.3968\n",
      "14021.64446258545\n",
      "Epoch [15/50], Batch 118/120, Train Loss: 108.2312\n",
      "14156.097007751465\n",
      "Epoch [15/50], Batch 119/120, Train Loss: 134.4525\n",
      "14266.024673461914\n",
      "Epoch [15/50], Batch 120/120, Train Loss: 109.9277\n",
      "Epoch [15/50], Train Loss: 118.8835, Validation Loss: 123.2213\n",
      "106.76460266113281\n",
      "Epoch [16/50], Batch 1/120, Train Loss: 106.7646\n",
      "217.96653747558594\n",
      "Epoch [16/50], Batch 2/120, Train Loss: 111.2019\n",
      "347.76927185058594\n",
      "Epoch [16/50], Batch 3/120, Train Loss: 129.8027\n",
      "482.9058074951172\n",
      "Epoch [16/50], Batch 4/120, Train Loss: 135.1365\n",
      "582.0193176269531\n",
      "Epoch [16/50], Batch 5/120, Train Loss: 99.1135\n",
      "706.9683685302734\n",
      "Epoch [16/50], Batch 6/120, Train Loss: 124.9491\n",
      "845.5703277587891\n",
      "Epoch [16/50], Batch 7/120, Train Loss: 138.6020\n",
      "991.1636962890625\n",
      "Epoch [16/50], Batch 8/120, Train Loss: 145.5934\n",
      "1115.1576232910156\n",
      "Epoch [16/50], Batch 9/120, Train Loss: 123.9939\n",
      "1228.0977325439453\n",
      "Epoch [16/50], Batch 10/120, Train Loss: 112.9401\n",
      "1344.3529586791992\n",
      "Epoch [16/50], Batch 11/120, Train Loss: 116.2552\n",
      "1446.382698059082\n",
      "Epoch [16/50], Batch 12/120, Train Loss: 102.0297\n",
      "1560.4656982421875\n",
      "Epoch [16/50], Batch 13/120, Train Loss: 114.0830\n",
      "1663.6048889160156\n",
      "Epoch [16/50], Batch 14/120, Train Loss: 103.1392\n",
      "1776.413558959961\n",
      "Epoch [16/50], Batch 15/120, Train Loss: 112.8087\n",
      "1895.2346954345703\n",
      "Epoch [16/50], Batch 16/120, Train Loss: 118.8211\n",
      "1989.3689193725586\n",
      "Epoch [16/50], Batch 17/120, Train Loss: 94.1342\n",
      "2080.862693786621\n",
      "Epoch [16/50], Batch 18/120, Train Loss: 91.4938\n",
      "2170.9283905029297\n",
      "Epoch [16/50], Batch 19/120, Train Loss: 90.0657\n",
      "2292.4184036254883\n",
      "Epoch [16/50], Batch 20/120, Train Loss: 121.4900\n",
      "2418.315757751465\n",
      "Epoch [16/50], Batch 21/120, Train Loss: 125.8974\n",
      "2536.6425247192383\n",
      "Epoch [16/50], Batch 22/120, Train Loss: 118.3268\n",
      "2678.0596237182617\n",
      "Epoch [16/50], Batch 23/120, Train Loss: 141.4171\n",
      "2793.0870819091797\n",
      "Epoch [16/50], Batch 24/120, Train Loss: 115.0275\n",
      "2896.4642181396484\n",
      "Epoch [16/50], Batch 25/120, Train Loss: 103.3771\n",
      "3020.730125427246\n",
      "Epoch [16/50], Batch 26/120, Train Loss: 124.2659\n",
      "3151.89688873291\n",
      "Epoch [16/50], Batch 27/120, Train Loss: 131.1668\n",
      "3254.6609420776367\n",
      "Epoch [16/50], Batch 28/120, Train Loss: 102.7641\n",
      "3372.7031326293945\n",
      "Epoch [16/50], Batch 29/120, Train Loss: 118.0422\n",
      "3482.760841369629\n",
      "Epoch [16/50], Batch 30/120, Train Loss: 110.0577\n",
      "3615.198890686035\n",
      "Epoch [16/50], Batch 31/120, Train Loss: 132.4380\n",
      "3737.653419494629\n",
      "Epoch [16/50], Batch 32/120, Train Loss: 122.4545\n",
      "3874.311897277832\n",
      "Epoch [16/50], Batch 33/120, Train Loss: 136.6585\n",
      "4001.492889404297\n",
      "Epoch [16/50], Batch 34/120, Train Loss: 127.1810\n",
      "4127.885116577148\n",
      "Epoch [16/50], Batch 35/120, Train Loss: 126.3922\n",
      "4252.458801269531\n",
      "Epoch [16/50], Batch 36/120, Train Loss: 124.5737\n",
      "4360.052307128906\n",
      "Epoch [16/50], Batch 37/120, Train Loss: 107.5935\n",
      "4482.14688873291\n",
      "Epoch [16/50], Batch 38/120, Train Loss: 122.0946\n",
      "4578.630905151367\n",
      "Epoch [16/50], Batch 39/120, Train Loss: 96.4840\n",
      "4686.827674865723\n",
      "Epoch [16/50], Batch 40/120, Train Loss: 108.1968\n",
      "4804.509185791016\n",
      "Epoch [16/50], Batch 41/120, Train Loss: 117.6815\n",
      "4923.850936889648\n",
      "Epoch [16/50], Batch 42/120, Train Loss: 119.3418\n",
      "5045.628761291504\n",
      "Epoch [16/50], Batch 43/120, Train Loss: 121.7778\n",
      "5151.990104675293\n",
      "Epoch [16/50], Batch 44/120, Train Loss: 106.3613\n",
      "5266.00244140625\n",
      "Epoch [16/50], Batch 45/120, Train Loss: 114.0123\n",
      "5386.872840881348\n",
      "Epoch [16/50], Batch 46/120, Train Loss: 120.8704\n",
      "5476.92276763916\n",
      "Epoch [16/50], Batch 47/120, Train Loss: 90.0499\n",
      "5586.228614807129\n",
      "Epoch [16/50], Batch 48/120, Train Loss: 109.3058\n",
      "5710.3640213012695\n",
      "Epoch [16/50], Batch 49/120, Train Loss: 124.1354\n",
      "5814.358749389648\n",
      "Epoch [16/50], Batch 50/120, Train Loss: 103.9947\n",
      "5921.896347045898\n",
      "Epoch [16/50], Batch 51/120, Train Loss: 107.5376\n",
      "6020.382293701172\n",
      "Epoch [16/50], Batch 52/120, Train Loss: 98.4859\n",
      "6105.66471862793\n",
      "Epoch [16/50], Batch 53/120, Train Loss: 85.2824\n",
      "6223.250450134277\n",
      "Epoch [16/50], Batch 54/120, Train Loss: 117.5857\n",
      "6346.965866088867\n",
      "Epoch [16/50], Batch 55/120, Train Loss: 123.7154\n",
      "6466.217300415039\n",
      "Epoch [16/50], Batch 56/120, Train Loss: 119.2514\n",
      "6571.071083068848\n",
      "Epoch [16/50], Batch 57/120, Train Loss: 104.8538\n",
      "6671.232719421387\n",
      "Epoch [16/50], Batch 58/120, Train Loss: 100.1616\n",
      "6797.80793762207\n",
      "Epoch [16/50], Batch 59/120, Train Loss: 126.5752\n",
      "6909.480712890625\n",
      "Epoch [16/50], Batch 60/120, Train Loss: 111.6728\n",
      "7011.352195739746\n",
      "Epoch [16/50], Batch 61/120, Train Loss: 101.8715\n",
      "7140.659065246582\n",
      "Epoch [16/50], Batch 62/120, Train Loss: 129.3069\n",
      "7276.401496887207\n",
      "Epoch [16/50], Batch 63/120, Train Loss: 135.7424\n",
      "7414.434211730957\n",
      "Epoch [16/50], Batch 64/120, Train Loss: 138.0327\n",
      "7523.01815032959\n",
      "Epoch [16/50], Batch 65/120, Train Loss: 108.5839\n",
      "7628.431869506836\n",
      "Epoch [16/50], Batch 66/120, Train Loss: 105.4137\n",
      "7757.833953857422\n",
      "Epoch [16/50], Batch 67/120, Train Loss: 129.4021\n",
      "7865.525054931641\n",
      "Epoch [16/50], Batch 68/120, Train Loss: 107.6911\n",
      "7993.482757568359\n",
      "Epoch [16/50], Batch 69/120, Train Loss: 127.9577\n",
      "8120.0629959106445\n",
      "Epoch [16/50], Batch 70/120, Train Loss: 126.5802\n",
      "8225.15813446045\n",
      "Epoch [16/50], Batch 71/120, Train Loss: 105.0951\n",
      "8342.034400939941\n",
      "Epoch [16/50], Batch 72/120, Train Loss: 116.8763\n",
      "8458.61873626709\n",
      "Epoch [16/50], Batch 73/120, Train Loss: 116.5843\n",
      "8556.71102142334\n",
      "Epoch [16/50], Batch 74/120, Train Loss: 98.0923\n",
      "8693.602317810059\n",
      "Epoch [16/50], Batch 75/120, Train Loss: 136.8913\n",
      "8804.57299041748\n",
      "Epoch [16/50], Batch 76/120, Train Loss: 110.9707\n",
      "8909.854637145996\n",
      "Epoch [16/50], Batch 77/120, Train Loss: 105.2816\n",
      "9013.47518157959\n",
      "Epoch [16/50], Batch 78/120, Train Loss: 103.6205\n",
      "9161.083610534668\n",
      "Epoch [16/50], Batch 79/120, Train Loss: 147.6084\n",
      "9305.17699432373\n",
      "Epoch [16/50], Batch 80/120, Train Loss: 144.0934\n",
      "9387.176956176758\n",
      "Epoch [16/50], Batch 81/120, Train Loss: 82.0000\n",
      "9517.7119140625\n",
      "Epoch [16/50], Batch 82/120, Train Loss: 130.5350\n",
      "9617.956176757812\n",
      "Epoch [16/50], Batch 83/120, Train Loss: 100.2443\n",
      "9732.897163391113\n",
      "Epoch [16/50], Batch 84/120, Train Loss: 114.9410\n",
      "9842.1109085083\n",
      "Epoch [16/50], Batch 85/120, Train Loss: 109.2137\n",
      "9966.612464904785\n",
      "Epoch [16/50], Batch 86/120, Train Loss: 124.5016\n",
      "10087.242622375488\n",
      "Epoch [16/50], Batch 87/120, Train Loss: 120.6302\n",
      "10182.771942138672\n",
      "Epoch [16/50], Batch 88/120, Train Loss: 95.5293\n",
      "10310.34895324707\n",
      "Epoch [16/50], Batch 89/120, Train Loss: 127.5770\n",
      "10425.789413452148\n",
      "Epoch [16/50], Batch 90/120, Train Loss: 115.4405\n",
      "10538.952247619629\n",
      "Epoch [16/50], Batch 91/120, Train Loss: 113.1628\n",
      "10643.259140014648\n",
      "Epoch [16/50], Batch 92/120, Train Loss: 104.3069\n",
      "10761.573211669922\n",
      "Epoch [16/50], Batch 93/120, Train Loss: 118.3141\n",
      "10866.393814086914\n",
      "Epoch [16/50], Batch 94/120, Train Loss: 104.8206\n",
      "11004.180160522461\n",
      "Epoch [16/50], Batch 95/120, Train Loss: 137.7863\n",
      "11111.190483093262\n",
      "Epoch [16/50], Batch 96/120, Train Loss: 107.0103\n",
      "11245.384315490723\n",
      "Epoch [16/50], Batch 97/120, Train Loss: 134.1938\n",
      "11354.146827697754\n",
      "Epoch [16/50], Batch 98/120, Train Loss: 108.7625\n",
      "11470.074851989746\n",
      "Epoch [16/50], Batch 99/120, Train Loss: 115.9280\n",
      "11586.413581848145\n",
      "Epoch [16/50], Batch 100/120, Train Loss: 116.3387\n",
      "11675.506546020508\n",
      "Epoch [16/50], Batch 101/120, Train Loss: 89.0930\n",
      "11772.883514404297\n",
      "Epoch [16/50], Batch 102/120, Train Loss: 97.3770\n",
      "11907.068298339844\n",
      "Epoch [16/50], Batch 103/120, Train Loss: 134.1848\n",
      "12025.448196411133\n",
      "Epoch [16/50], Batch 104/120, Train Loss: 118.3799\n",
      "12121.119277954102\n",
      "Epoch [16/50], Batch 105/120, Train Loss: 95.6711\n",
      "12210.116401672363\n",
      "Epoch [16/50], Batch 106/120, Train Loss: 88.9971\n",
      "12339.768180847168\n",
      "Epoch [16/50], Batch 107/120, Train Loss: 129.6518\n",
      "12446.732498168945\n",
      "Epoch [16/50], Batch 108/120, Train Loss: 106.9643\n",
      "12558.006866455078\n",
      "Epoch [16/50], Batch 109/120, Train Loss: 111.2744\n",
      "12673.323051452637\n",
      "Epoch [16/50], Batch 110/120, Train Loss: 115.3162\n",
      "12798.127555847168\n",
      "Epoch [16/50], Batch 111/120, Train Loss: 124.8045\n",
      "12918.007720947266\n",
      "Epoch [16/50], Batch 112/120, Train Loss: 119.8802\n",
      "13048.919006347656\n",
      "Epoch [16/50], Batch 113/120, Train Loss: 130.9113\n",
      "13190.075973510742\n",
      "Epoch [16/50], Batch 114/120, Train Loss: 141.1570\n",
      "13311.113906860352\n",
      "Epoch [16/50], Batch 115/120, Train Loss: 121.0379\n",
      "13425.038047790527\n",
      "Epoch [16/50], Batch 116/120, Train Loss: 113.9241\n",
      "13539.394775390625\n",
      "Epoch [16/50], Batch 117/120, Train Loss: 114.3567\n",
      "13639.437309265137\n",
      "Epoch [16/50], Batch 118/120, Train Loss: 100.0425\n",
      "13784.024085998535\n",
      "Epoch [16/50], Batch 119/120, Train Loss: 144.5868\n",
      "13892.530464172363\n",
      "Epoch [16/50], Batch 120/120, Train Loss: 108.5064\n",
      "Epoch [16/50], Train Loss: 115.7711, Validation Loss: 121.4624\n",
      "103.44268798828125\n",
      "Epoch [17/50], Batch 1/120, Train Loss: 103.4427\n",
      "208.2826690673828\n",
      "Epoch [17/50], Batch 2/120, Train Loss: 104.8400\n",
      "335.9374542236328\n",
      "Epoch [17/50], Batch 3/120, Train Loss: 127.6548\n",
      "454.74693298339844\n",
      "Epoch [17/50], Batch 4/120, Train Loss: 118.8095\n",
      "557.4396896362305\n",
      "Epoch [17/50], Batch 5/120, Train Loss: 102.6928\n",
      "676.5871810913086\n",
      "Epoch [17/50], Batch 6/120, Train Loss: 119.1475\n",
      "779.3577880859375\n",
      "Epoch [17/50], Batch 7/120, Train Loss: 102.7706\n",
      "880.0966644287109\n",
      "Epoch [17/50], Batch 8/120, Train Loss: 100.7389\n",
      "985.6460418701172\n",
      "Epoch [17/50], Batch 9/120, Train Loss: 105.5494\n",
      "1070.1315155029297\n",
      "Epoch [17/50], Batch 10/120, Train Loss: 84.4855\n",
      "1166.5841751098633\n",
      "Epoch [17/50], Batch 11/120, Train Loss: 96.4527\n",
      "1279.634895324707\n",
      "Epoch [17/50], Batch 12/120, Train Loss: 113.0507\n",
      "1402.7309036254883\n",
      "Epoch [17/50], Batch 13/120, Train Loss: 123.0960\n",
      "1512.8218307495117\n",
      "Epoch [17/50], Batch 14/120, Train Loss: 110.0909\n",
      "1619.9614028930664\n",
      "Epoch [17/50], Batch 15/120, Train Loss: 107.1396\n",
      "1739.3907852172852\n",
      "Epoch [17/50], Batch 16/120, Train Loss: 119.4294\n",
      "1851.4372940063477\n",
      "Epoch [17/50], Batch 17/120, Train Loss: 112.0465\n",
      "1979.7879104614258\n",
      "Epoch [17/50], Batch 18/120, Train Loss: 128.3506\n",
      "2094.1207122802734\n",
      "Epoch [17/50], Batch 19/120, Train Loss: 114.3328\n",
      "2205.000274658203\n",
      "Epoch [17/50], Batch 20/120, Train Loss: 110.8796\n",
      "2335.4544677734375\n",
      "Epoch [17/50], Batch 21/120, Train Loss: 130.4542\n",
      "2460.788299560547\n",
      "Epoch [17/50], Batch 22/120, Train Loss: 125.3338\n",
      "2582.418846130371\n",
      "Epoch [17/50], Batch 23/120, Train Loss: 121.6305\n",
      "2711.0412826538086\n",
      "Epoch [17/50], Batch 24/120, Train Loss: 128.6224\n",
      "2842.9810104370117\n",
      "Epoch [17/50], Batch 25/120, Train Loss: 131.9397\n",
      "2991.013023376465\n",
      "Epoch [17/50], Batch 26/120, Train Loss: 148.0320\n",
      "3090.716377258301\n",
      "Epoch [17/50], Batch 27/120, Train Loss: 99.7034\n",
      "3172.2888565063477\n",
      "Epoch [17/50], Batch 28/120, Train Loss: 81.5725\n",
      "3290.145477294922\n",
      "Epoch [17/50], Batch 29/120, Train Loss: 117.8566\n",
      "3381.982147216797\n",
      "Epoch [17/50], Batch 30/120, Train Loss: 91.8367\n",
      "3514.2173461914062\n",
      "Epoch [17/50], Batch 31/120, Train Loss: 132.2352\n",
      "3608.9633178710938\n",
      "Epoch [17/50], Batch 32/120, Train Loss: 94.7460\n",
      "3695.6669158935547\n",
      "Epoch [17/50], Batch 33/120, Train Loss: 86.7036\n",
      "3823.5748138427734\n",
      "Epoch [17/50], Batch 34/120, Train Loss: 127.9079\n",
      "3949.463119506836\n",
      "Epoch [17/50], Batch 35/120, Train Loss: 125.8883\n",
      "4083.504898071289\n",
      "Epoch [17/50], Batch 36/120, Train Loss: 134.0418\n",
      "4178.640068054199\n",
      "Epoch [17/50], Batch 37/120, Train Loss: 95.1352\n",
      "4298.553489685059\n",
      "Epoch [17/50], Batch 38/120, Train Loss: 119.9134\n",
      "4404.922058105469\n",
      "Epoch [17/50], Batch 39/120, Train Loss: 106.3686\n",
      "4521.257339477539\n",
      "Epoch [17/50], Batch 40/120, Train Loss: 116.3353\n",
      "4639.594665527344\n",
      "Epoch [17/50], Batch 41/120, Train Loss: 118.3373\n",
      "4737.155090332031\n",
      "Epoch [17/50], Batch 42/120, Train Loss: 97.5604\n",
      "4837.871292114258\n",
      "Epoch [17/50], Batch 43/120, Train Loss: 100.7162\n",
      "4943.704666137695\n",
      "Epoch [17/50], Batch 44/120, Train Loss: 105.8334\n",
      "5054.574554443359\n",
      "Epoch [17/50], Batch 45/120, Train Loss: 110.8699\n",
      "5161.820373535156\n",
      "Epoch [17/50], Batch 46/120, Train Loss: 107.2458\n",
      "5241.06494140625\n",
      "Epoch [17/50], Batch 47/120, Train Loss: 79.2446\n",
      "5370.893402099609\n",
      "Epoch [17/50], Batch 48/120, Train Loss: 129.8285\n",
      "5499.132080078125\n",
      "Epoch [17/50], Batch 49/120, Train Loss: 128.2387\n",
      "5619.979827880859\n",
      "Epoch [17/50], Batch 50/120, Train Loss: 120.8477\n",
      "5722.621299743652\n",
      "Epoch [17/50], Batch 51/120, Train Loss: 102.6415\n",
      "5843.234733581543\n",
      "Epoch [17/50], Batch 52/120, Train Loss: 120.6134\n",
      "5951.543807983398\n",
      "Epoch [17/50], Batch 53/120, Train Loss: 108.3091\n",
      "6041.103576660156\n",
      "Epoch [17/50], Batch 54/120, Train Loss: 89.5598\n",
      "6161.522499084473\n",
      "Epoch [17/50], Batch 55/120, Train Loss: 120.4189\n",
      "6265.081916809082\n",
      "Epoch [17/50], Batch 56/120, Train Loss: 103.5594\n",
      "6389.847923278809\n",
      "Epoch [17/50], Batch 57/120, Train Loss: 124.7660\n",
      "6523.047065734863\n",
      "Epoch [17/50], Batch 58/120, Train Loss: 133.1991\n",
      "6633.183631896973\n",
      "Epoch [17/50], Batch 59/120, Train Loss: 110.1366\n",
      "6769.832618713379\n",
      "Epoch [17/50], Batch 60/120, Train Loss: 136.6490\n",
      "6860.0606689453125\n",
      "Epoch [17/50], Batch 61/120, Train Loss: 90.2281\n",
      "6952.614242553711\n",
      "Epoch [17/50], Batch 62/120, Train Loss: 92.5536\n",
      "7067.670967102051\n",
      "Epoch [17/50], Batch 63/120, Train Loss: 115.0567\n",
      "7169.431953430176\n",
      "Epoch [17/50], Batch 64/120, Train Loss: 101.7610\n",
      "7284.937629699707\n",
      "Epoch [17/50], Batch 65/120, Train Loss: 115.5057\n",
      "7396.611518859863\n",
      "Epoch [17/50], Batch 66/120, Train Loss: 111.6739\n",
      "7509.474075317383\n",
      "Epoch [17/50], Batch 67/120, Train Loss: 112.8626\n",
      "7605.668022155762\n",
      "Epoch [17/50], Batch 68/120, Train Loss: 96.1939\n",
      "7707.255035400391\n",
      "Epoch [17/50], Batch 69/120, Train Loss: 101.5870\n",
      "7813.07958984375\n",
      "Epoch [17/50], Batch 70/120, Train Loss: 105.8246\n",
      "7931.063735961914\n",
      "Epoch [17/50], Batch 71/120, Train Loss: 117.9841\n",
      "8055.457000732422\n",
      "Epoch [17/50], Batch 72/120, Train Loss: 124.3933\n",
      "8143.563125610352\n",
      "Epoch [17/50], Batch 73/120, Train Loss: 88.1061\n",
      "8255.974227905273\n",
      "Epoch [17/50], Batch 74/120, Train Loss: 112.4111\n",
      "8357.795364379883\n",
      "Epoch [17/50], Batch 75/120, Train Loss: 101.8211\n",
      "8465.558898925781\n",
      "Epoch [17/50], Batch 76/120, Train Loss: 107.7635\n",
      "8579.84455871582\n",
      "Epoch [17/50], Batch 77/120, Train Loss: 114.2857\n",
      "8679.010925292969\n",
      "Epoch [17/50], Batch 78/120, Train Loss: 99.1664\n",
      "8778.51343536377\n",
      "Epoch [17/50], Batch 79/120, Train Loss: 99.5025\n",
      "8896.089218139648\n",
      "Epoch [17/50], Batch 80/120, Train Loss: 117.5758\n",
      "8997.234748840332\n",
      "Epoch [17/50], Batch 81/120, Train Loss: 101.1455\n",
      "9120.563842773438\n",
      "Epoch [17/50], Batch 82/120, Train Loss: 123.3291\n",
      "9244.270866394043\n",
      "Epoch [17/50], Batch 83/120, Train Loss: 123.7070\n",
      "9347.729972839355\n",
      "Epoch [17/50], Batch 84/120, Train Loss: 103.4591\n",
      "9441.331001281738\n",
      "Epoch [17/50], Batch 85/120, Train Loss: 93.6010\n",
      "9553.244117736816\n",
      "Epoch [17/50], Batch 86/120, Train Loss: 111.9131\n",
      "9664.207160949707\n",
      "Epoch [17/50], Batch 87/120, Train Loss: 110.9630\n",
      "9801.757682800293\n",
      "Epoch [17/50], Batch 88/120, Train Loss: 137.5505\n",
      "9926.042091369629\n",
      "Epoch [17/50], Batch 89/120, Train Loss: 124.2844\n",
      "10052.394477844238\n",
      "Epoch [17/50], Batch 90/120, Train Loss: 126.3524\n",
      "10171.225791931152\n",
      "Epoch [17/50], Batch 91/120, Train Loss: 118.8313\n",
      "10291.341484069824\n",
      "Epoch [17/50], Batch 92/120, Train Loss: 120.1157\n",
      "10398.036560058594\n",
      "Epoch [17/50], Batch 93/120, Train Loss: 106.6951\n",
      "10531.021087646484\n",
      "Epoch [17/50], Batch 94/120, Train Loss: 132.9845\n",
      "10648.852188110352\n",
      "Epoch [17/50], Batch 95/120, Train Loss: 117.8311\n",
      "10775.055572509766\n",
      "Epoch [17/50], Batch 96/120, Train Loss: 126.2034\n",
      "10889.46713256836\n",
      "Epoch [17/50], Batch 97/120, Train Loss: 114.4116\n",
      "11000.652297973633\n",
      "Epoch [17/50], Batch 98/120, Train Loss: 111.1852\n",
      "11131.805725097656\n",
      "Epoch [17/50], Batch 99/120, Train Loss: 131.1534\n",
      "11232.039390563965\n",
      "Epoch [17/50], Batch 100/120, Train Loss: 100.2337\n",
      "11346.423072814941\n",
      "Epoch [17/50], Batch 101/120, Train Loss: 114.3837\n",
      "11456.566772460938\n",
      "Epoch [17/50], Batch 102/120, Train Loss: 110.1437\n",
      "11548.744323730469\n",
      "Epoch [17/50], Batch 103/120, Train Loss: 92.1776\n",
      "11652.693008422852\n",
      "Epoch [17/50], Batch 104/120, Train Loss: 103.9487\n",
      "11767.820701599121\n",
      "Epoch [17/50], Batch 105/120, Train Loss: 115.1277\n",
      "11867.846557617188\n",
      "Epoch [17/50], Batch 106/120, Train Loss: 100.0259\n",
      "11983.344139099121\n",
      "Epoch [17/50], Batch 107/120, Train Loss: 115.4976\n",
      "12108.496002197266\n",
      "Epoch [17/50], Batch 108/120, Train Loss: 125.1519\n",
      "12195.806442260742\n",
      "Epoch [17/50], Batch 109/120, Train Loss: 87.3104\n",
      "12299.867202758789\n",
      "Epoch [17/50], Batch 110/120, Train Loss: 104.0608\n",
      "12382.771469116211\n",
      "Epoch [17/50], Batch 111/120, Train Loss: 82.9043\n",
      "12521.99821472168\n",
      "Epoch [17/50], Batch 112/120, Train Loss: 139.2267\n",
      "12641.885055541992\n",
      "Epoch [17/50], Batch 113/120, Train Loss: 119.8868\n",
      "12733.574020385742\n",
      "Epoch [17/50], Batch 114/120, Train Loss: 91.6890\n",
      "12865.088912963867\n",
      "Epoch [17/50], Batch 115/120, Train Loss: 131.5149\n",
      "12991.384773254395\n",
      "Epoch [17/50], Batch 116/120, Train Loss: 126.2959\n",
      "13088.470962524414\n",
      "Epoch [17/50], Batch 117/120, Train Loss: 97.0862\n",
      "13177.33757019043\n",
      "Epoch [17/50], Batch 118/120, Train Loss: 88.8666\n",
      "13286.711227416992\n",
      "Epoch [17/50], Batch 119/120, Train Loss: 109.3737\n",
      "13416.782150268555\n",
      "Epoch [17/50], Batch 120/120, Train Loss: 130.0709\n",
      "Epoch [17/50], Train Loss: 111.8065, Validation Loss: 118.8016\n",
      "105.94251251220703\n",
      "Epoch [18/50], Batch 1/120, Train Loss: 105.9425\n",
      "204.38895416259766\n",
      "Epoch [18/50], Batch 2/120, Train Loss: 98.4464\n",
      "339.09354400634766\n",
      "Epoch [18/50], Batch 3/120, Train Loss: 134.7046\n",
      "435.90943908691406\n",
      "Epoch [18/50], Batch 4/120, Train Loss: 96.8159\n",
      "537.5499267578125\n",
      "Epoch [18/50], Batch 5/120, Train Loss: 101.6405\n",
      "627.8425598144531\n",
      "Epoch [18/50], Batch 6/120, Train Loss: 90.2926\n",
      "752.1925048828125\n",
      "Epoch [18/50], Batch 7/120, Train Loss: 124.3499\n",
      "859.7254028320312\n",
      "Epoch [18/50], Batch 8/120, Train Loss: 107.5329\n",
      "965.5830841064453\n",
      "Epoch [18/50], Batch 9/120, Train Loss: 105.8577\n",
      "1060.3760681152344\n",
      "Epoch [18/50], Batch 10/120, Train Loss: 94.7930\n",
      "1186.2642517089844\n",
      "Epoch [18/50], Batch 11/120, Train Loss: 125.8882\n",
      "1289.4451522827148\n",
      "Epoch [18/50], Batch 12/120, Train Loss: 103.1809\n",
      "1397.901985168457\n",
      "Epoch [18/50], Batch 13/120, Train Loss: 108.4568\n",
      "1522.647216796875\n",
      "Epoch [18/50], Batch 14/120, Train Loss: 124.7452\n",
      "1638.0285339355469\n",
      "Epoch [18/50], Batch 15/120, Train Loss: 115.3813\n",
      "1752.3373260498047\n",
      "Epoch [18/50], Batch 16/120, Train Loss: 114.3088\n",
      "1884.6742095947266\n",
      "Epoch [18/50], Batch 17/120, Train Loss: 132.3369\n",
      "1996.3997344970703\n",
      "Epoch [18/50], Batch 18/120, Train Loss: 111.7255\n",
      "2096.037582397461\n",
      "Epoch [18/50], Batch 19/120, Train Loss: 99.6378\n",
      "2194.2733306884766\n",
      "Epoch [18/50], Batch 20/120, Train Loss: 98.2357\n",
      "2300.8225860595703\n",
      "Epoch [18/50], Batch 21/120, Train Loss: 106.5493\n",
      "2421.708839416504\n",
      "Epoch [18/50], Batch 22/120, Train Loss: 120.8863\n",
      "2526.1254959106445\n",
      "Epoch [18/50], Batch 23/120, Train Loss: 104.4167\n",
      "2654.1159133911133\n",
      "Epoch [18/50], Batch 24/120, Train Loss: 127.9904\n",
      "2743.9760971069336\n",
      "Epoch [18/50], Batch 25/120, Train Loss: 89.8602\n",
      "2853.2799224853516\n",
      "Epoch [18/50], Batch 26/120, Train Loss: 109.3038\n",
      "2967.809829711914\n",
      "Epoch [18/50], Batch 27/120, Train Loss: 114.5299\n",
      "3092.8446655273438\n",
      "Epoch [18/50], Batch 28/120, Train Loss: 125.0348\n",
      "3237.7254791259766\n",
      "Epoch [18/50], Batch 29/120, Train Loss: 144.8808\n",
      "3393.834243774414\n",
      "Epoch [18/50], Batch 30/120, Train Loss: 156.1088\n",
      "3484.984962463379\n",
      "Epoch [18/50], Batch 31/120, Train Loss: 91.1507\n",
      "3588.5981826782227\n",
      "Epoch [18/50], Batch 32/120, Train Loss: 103.6132\n",
      "3693.5932846069336\n",
      "Epoch [18/50], Batch 33/120, Train Loss: 104.9951\n",
      "3778.34627532959\n",
      "Epoch [18/50], Batch 34/120, Train Loss: 84.7530\n",
      "3899.7391815185547\n",
      "Epoch [18/50], Batch 35/120, Train Loss: 121.3929\n",
      "4018.5635833740234\n",
      "Epoch [18/50], Batch 36/120, Train Loss: 118.8244\n",
      "4115.277763366699\n",
      "Epoch [18/50], Batch 37/120, Train Loss: 96.7142\n",
      "4204.552543640137\n",
      "Epoch [18/50], Batch 38/120, Train Loss: 89.2748\n",
      "4308.8446044921875\n",
      "Epoch [18/50], Batch 39/120, Train Loss: 104.2921\n",
      "4417.094512939453\n",
      "Epoch [18/50], Batch 40/120, Train Loss: 108.2499\n",
      "4503.088188171387\n",
      "Epoch [18/50], Batch 41/120, Train Loss: 85.9937\n",
      "4597.2238693237305\n",
      "Epoch [18/50], Batch 42/120, Train Loss: 94.1357\n",
      "4722.690673828125\n",
      "Epoch [18/50], Batch 43/120, Train Loss: 125.4668\n",
      "4833.4560546875\n",
      "Epoch [18/50], Batch 44/120, Train Loss: 110.7654\n",
      "4930.8142166137695\n",
      "Epoch [18/50], Batch 45/120, Train Loss: 97.3582\n",
      "5065.532325744629\n",
      "Epoch [18/50], Batch 46/120, Train Loss: 134.7181\n",
      "5165.204856872559\n",
      "Epoch [18/50], Batch 47/120, Train Loss: 99.6725\n",
      "5305.823036193848\n",
      "Epoch [18/50], Batch 48/120, Train Loss: 140.6182\n",
      "5429.242988586426\n",
      "Epoch [18/50], Batch 49/120, Train Loss: 123.4200\n",
      "5575.4601974487305\n",
      "Epoch [18/50], Batch 50/120, Train Loss: 146.2172\n",
      "5681.128807067871\n",
      "Epoch [18/50], Batch 51/120, Train Loss: 105.6686\n",
      "5770.162948608398\n",
      "Epoch [18/50], Batch 52/120, Train Loss: 89.0341\n",
      "5873.504379272461\n",
      "Epoch [18/50], Batch 53/120, Train Loss: 103.3414\n",
      "5987.907569885254\n",
      "Epoch [18/50], Batch 54/120, Train Loss: 114.4032\n",
      "6113.016830444336\n",
      "Epoch [18/50], Batch 55/120, Train Loss: 125.1093\n",
      "6232.890396118164\n",
      "Epoch [18/50], Batch 56/120, Train Loss: 119.8736\n",
      "6370.6131591796875\n",
      "Epoch [18/50], Batch 57/120, Train Loss: 137.7228\n",
      "6454.418045043945\n",
      "Epoch [18/50], Batch 58/120, Train Loss: 83.8049\n",
      "6566.228698730469\n",
      "Epoch [18/50], Batch 59/120, Train Loss: 111.8107\n",
      "6659.268394470215\n",
      "Epoch [18/50], Batch 60/120, Train Loss: 93.0397\n",
      "6777.115966796875\n",
      "Epoch [18/50], Batch 61/120, Train Loss: 117.8476\n",
      "6895.883834838867\n",
      "Epoch [18/50], Batch 62/120, Train Loss: 118.7679\n",
      "6974.244110107422\n",
      "Epoch [18/50], Batch 63/120, Train Loss: 78.3603\n",
      "7081.065765380859\n",
      "Epoch [18/50], Batch 64/120, Train Loss: 106.8217\n",
      "7205.319664001465\n",
      "Epoch [18/50], Batch 65/120, Train Loss: 124.2539\n",
      "7297.52725982666\n",
      "Epoch [18/50], Batch 66/120, Train Loss: 92.2076\n",
      "7386.080589294434\n",
      "Epoch [18/50], Batch 67/120, Train Loss: 88.5533\n",
      "7505.255844116211\n",
      "Epoch [18/50], Batch 68/120, Train Loss: 119.1753\n",
      "7631.650840759277\n",
      "Epoch [18/50], Batch 69/120, Train Loss: 126.3950\n",
      "7737.1182861328125\n",
      "Epoch [18/50], Batch 70/120, Train Loss: 105.4674\n",
      "7862.826522827148\n",
      "Epoch [18/50], Batch 71/120, Train Loss: 125.7082\n",
      "7975.8896408081055\n",
      "Epoch [18/50], Batch 72/120, Train Loss: 113.0631\n",
      "8085.749794006348\n",
      "Epoch [18/50], Batch 73/120, Train Loss: 109.8602\n",
      "8198.49681854248\n",
      "Epoch [18/50], Batch 74/120, Train Loss: 112.7470\n",
      "8282.754539489746\n",
      "Epoch [18/50], Batch 75/120, Train Loss: 84.2577\n",
      "8365.075561523438\n",
      "Epoch [18/50], Batch 76/120, Train Loss: 82.3210\n",
      "8463.16259765625\n",
      "Epoch [18/50], Batch 77/120, Train Loss: 98.0870\n",
      "8599.460571289062\n",
      "Epoch [18/50], Batch 78/120, Train Loss: 136.2980\n",
      "8701.434394836426\n",
      "Epoch [18/50], Batch 79/120, Train Loss: 101.9738\n",
      "8838.318977355957\n",
      "Epoch [18/50], Batch 80/120, Train Loss: 136.8846\n",
      "8918.128463745117\n",
      "Epoch [18/50], Batch 81/120, Train Loss: 79.8095\n",
      "9032.917015075684\n",
      "Epoch [18/50], Batch 82/120, Train Loss: 114.7886\n",
      "9131.043113708496\n",
      "Epoch [18/50], Batch 83/120, Train Loss: 98.1261\n",
      "9240.200942993164\n",
      "Epoch [18/50], Batch 84/120, Train Loss: 109.1578\n",
      "9378.99868774414\n",
      "Epoch [18/50], Batch 85/120, Train Loss: 138.7977\n",
      "9503.731315612793\n",
      "Epoch [18/50], Batch 86/120, Train Loss: 124.7326\n",
      "9618.50560760498\n",
      "Epoch [18/50], Batch 87/120, Train Loss: 114.7743\n",
      "9755.381706237793\n",
      "Epoch [18/50], Batch 88/120, Train Loss: 136.8761\n",
      "9847.31842803955\n",
      "Epoch [18/50], Batch 89/120, Train Loss: 91.9367\n",
      "9932.031478881836\n",
      "Epoch [18/50], Batch 90/120, Train Loss: 84.7131\n",
      "10043.341186523438\n",
      "Epoch [18/50], Batch 91/120, Train Loss: 111.3097\n",
      "10139.401657104492\n",
      "Epoch [18/50], Batch 92/120, Train Loss: 96.0605\n",
      "10235.67115020752\n",
      "Epoch [18/50], Batch 93/120, Train Loss: 96.2695\n",
      "10351.512092590332\n",
      "Epoch [18/50], Batch 94/120, Train Loss: 115.8409\n",
      "10473.397361755371\n",
      "Epoch [18/50], Batch 95/120, Train Loss: 121.8853\n",
      "10556.299621582031\n",
      "Epoch [18/50], Batch 96/120, Train Loss: 82.9023\n",
      "10683.354866027832\n",
      "Epoch [18/50], Batch 97/120, Train Loss: 127.0552\n",
      "10787.228309631348\n",
      "Epoch [18/50], Batch 98/120, Train Loss: 103.8734\n",
      "10896.770835876465\n",
      "Epoch [18/50], Batch 99/120, Train Loss: 109.5425\n",
      "11004.369239807129\n",
      "Epoch [18/50], Batch 100/120, Train Loss: 107.5984\n",
      "11118.573318481445\n",
      "Epoch [18/50], Batch 101/120, Train Loss: 114.2041\n",
      "11235.831939697266\n",
      "Epoch [18/50], Batch 102/120, Train Loss: 117.2586\n",
      "11337.516998291016\n",
      "Epoch [18/50], Batch 103/120, Train Loss: 101.6851\n",
      "11454.296203613281\n",
      "Epoch [18/50], Batch 104/120, Train Loss: 116.7792\n",
      "11565.823654174805\n",
      "Epoch [18/50], Batch 105/120, Train Loss: 111.5275\n",
      "11675.403244018555\n",
      "Epoch [18/50], Batch 106/120, Train Loss: 109.5796\n",
      "11779.47346496582\n",
      "Epoch [18/50], Batch 107/120, Train Loss: 104.0702\n",
      "11911.859588623047\n",
      "Epoch [18/50], Batch 108/120, Train Loss: 132.3861\n",
      "11994.93408203125\n",
      "Epoch [18/50], Batch 109/120, Train Loss: 83.0745\n",
      "12101.858505249023\n",
      "Epoch [18/50], Batch 110/120, Train Loss: 106.9244\n",
      "12223.505462646484\n",
      "Epoch [18/50], Batch 111/120, Train Loss: 121.6470\n",
      "12342.44287109375\n",
      "Epoch [18/50], Batch 112/120, Train Loss: 118.9374\n",
      "12472.505340576172\n",
      "Epoch [18/50], Batch 113/120, Train Loss: 130.0625\n",
      "12595.146621704102\n",
      "Epoch [18/50], Batch 114/120, Train Loss: 122.6413\n",
      "12682.869667053223\n",
      "Epoch [18/50], Batch 115/120, Train Loss: 87.7230\n",
      "12793.305809020996\n",
      "Epoch [18/50], Batch 116/120, Train Loss: 110.4361\n",
      "12910.462112426758\n",
      "Epoch [18/50], Batch 117/120, Train Loss: 117.1563\n",
      "13030.112976074219\n",
      "Epoch [18/50], Batch 118/120, Train Loss: 119.6509\n",
      "13119.62467956543\n",
      "Epoch [18/50], Batch 119/120, Train Loss: 89.5117\n",
      "13243.732376098633\n",
      "Epoch [18/50], Batch 120/120, Train Loss: 124.1077\n",
      "Epoch [18/50], Train Loss: 110.3644, Validation Loss: 117.9864\n",
      "89.56321716308594\n",
      "Epoch [19/50], Batch 1/120, Train Loss: 89.5632\n",
      "221.35009765625\n",
      "Epoch [19/50], Batch 2/120, Train Loss: 131.7869\n",
      "338.66316986083984\n",
      "Epoch [19/50], Batch 3/120, Train Loss: 117.3131\n",
      "459.0740432739258\n",
      "Epoch [19/50], Batch 4/120, Train Loss: 120.4109\n",
      "573.4597396850586\n",
      "Epoch [19/50], Batch 5/120, Train Loss: 114.3857\n",
      "670.7742767333984\n",
      "Epoch [19/50], Batch 6/120, Train Loss: 97.3145\n",
      "773.7809524536133\n",
      "Epoch [19/50], Batch 7/120, Train Loss: 103.0067\n",
      "903.9362869262695\n",
      "Epoch [19/50], Batch 8/120, Train Loss: 130.1553\n",
      "1018.0560073852539\n",
      "Epoch [19/50], Batch 9/120, Train Loss: 114.1197\n",
      "1135.9016571044922\n",
      "Epoch [19/50], Batch 10/120, Train Loss: 117.8456\n",
      "1241.168228149414\n",
      "Epoch [19/50], Batch 11/120, Train Loss: 105.2666\n",
      "1340.982681274414\n",
      "Epoch [19/50], Batch 12/120, Train Loss: 99.8145\n",
      "1468.5181350708008\n",
      "Epoch [19/50], Batch 13/120, Train Loss: 127.5355\n",
      "1559.237808227539\n",
      "Epoch [19/50], Batch 14/120, Train Loss: 90.7197\n",
      "1653.8197555541992\n",
      "Epoch [19/50], Batch 15/120, Train Loss: 94.5819\n",
      "1737.3961334228516\n",
      "Epoch [19/50], Batch 16/120, Train Loss: 83.5764\n",
      "1844.3268737792969\n",
      "Epoch [19/50], Batch 17/120, Train Loss: 106.9307\n",
      "1934.2903518676758\n",
      "Epoch [19/50], Batch 18/120, Train Loss: 89.9635\n",
      "2039.9965057373047\n",
      "Epoch [19/50], Batch 19/120, Train Loss: 105.7062\n",
      "2152.551025390625\n",
      "Epoch [19/50], Batch 20/120, Train Loss: 112.5545\n",
      "2260.609588623047\n",
      "Epoch [19/50], Batch 21/120, Train Loss: 108.0586\n",
      "2360.771194458008\n",
      "Epoch [19/50], Batch 22/120, Train Loss: 100.1616\n",
      "2465.2933807373047\n",
      "Epoch [19/50], Batch 23/120, Train Loss: 104.5222\n",
      "2566.3944702148438\n",
      "Epoch [19/50], Batch 24/120, Train Loss: 101.1011\n",
      "2677.398422241211\n",
      "Epoch [19/50], Batch 25/120, Train Loss: 111.0040\n",
      "2790.819450378418\n",
      "Epoch [19/50], Batch 26/120, Train Loss: 113.4210\n",
      "2885.609718322754\n",
      "Epoch [19/50], Batch 27/120, Train Loss: 94.7903\n",
      "2972.6100997924805\n",
      "Epoch [19/50], Batch 28/120, Train Loss: 87.0004\n",
      "3089.336227416992\n",
      "Epoch [19/50], Batch 29/120, Train Loss: 116.7261\n",
      "3196.981170654297\n",
      "Epoch [19/50], Batch 30/120, Train Loss: 107.6449\n",
      "3326.2713928222656\n",
      "Epoch [19/50], Batch 31/120, Train Loss: 129.2902\n",
      "3442.015335083008\n",
      "Epoch [19/50], Batch 32/120, Train Loss: 115.7439\n",
      "3561.0868530273438\n",
      "Epoch [19/50], Batch 33/120, Train Loss: 119.0715\n",
      "3685.910598754883\n",
      "Epoch [19/50], Batch 34/120, Train Loss: 124.8237\n",
      "3769.9405059814453\n",
      "Epoch [19/50], Batch 35/120, Train Loss: 84.0299\n",
      "3872.4934310913086\n",
      "Epoch [19/50], Batch 36/120, Train Loss: 102.5529\n",
      "3978.385612487793\n",
      "Epoch [19/50], Batch 37/120, Train Loss: 105.8922\n",
      "4095.2627182006836\n",
      "Epoch [19/50], Batch 38/120, Train Loss: 116.8771\n",
      "4204.098320007324\n",
      "Epoch [19/50], Batch 39/120, Train Loss: 108.8356\n",
      "4318.489654541016\n",
      "Epoch [19/50], Batch 40/120, Train Loss: 114.3913\n",
      "4439.786270141602\n",
      "Epoch [19/50], Batch 41/120, Train Loss: 121.2966\n",
      "4572.490020751953\n",
      "Epoch [19/50], Batch 42/120, Train Loss: 132.7038\n",
      "4680.939170837402\n",
      "Epoch [19/50], Batch 43/120, Train Loss: 108.4492\n",
      "4772.842399597168\n",
      "Epoch [19/50], Batch 44/120, Train Loss: 91.9032\n",
      "4905.6066818237305\n",
      "Epoch [19/50], Batch 45/120, Train Loss: 132.7643\n",
      "5019.45304107666\n",
      "Epoch [19/50], Batch 46/120, Train Loss: 113.8464\n",
      "5124.365234375\n",
      "Epoch [19/50], Batch 47/120, Train Loss: 104.9122\n",
      "5228.124702453613\n",
      "Epoch [19/50], Batch 48/120, Train Loss: 103.7595\n",
      "5335.188179016113\n",
      "Epoch [19/50], Batch 49/120, Train Loss: 107.0635\n",
      "5448.997657775879\n",
      "Epoch [19/50], Batch 50/120, Train Loss: 113.8095\n",
      "5536.984230041504\n",
      "Epoch [19/50], Batch 51/120, Train Loss: 87.9866\n",
      "5639.882698059082\n",
      "Epoch [19/50], Batch 52/120, Train Loss: 102.8985\n",
      "5769.315940856934\n",
      "Epoch [19/50], Batch 53/120, Train Loss: 129.4332\n",
      "5895.38614654541\n",
      "Epoch [19/50], Batch 54/120, Train Loss: 126.0702\n",
      "5991.906227111816\n",
      "Epoch [19/50], Batch 55/120, Train Loss: 96.5201\n",
      "6111.432426452637\n",
      "Epoch [19/50], Batch 56/120, Train Loss: 119.5262\n",
      "6240.848442077637\n",
      "Epoch [19/50], Batch 57/120, Train Loss: 129.4160\n",
      "6325.8588790893555\n",
      "Epoch [19/50], Batch 58/120, Train Loss: 85.0104\n",
      "6448.088722229004\n",
      "Epoch [19/50], Batch 59/120, Train Loss: 122.2298\n",
      "6563.280418395996\n",
      "Epoch [19/50], Batch 60/120, Train Loss: 115.1917\n",
      "6664.185432434082\n",
      "Epoch [19/50], Batch 61/120, Train Loss: 100.9050\n",
      "6782.958694458008\n",
      "Epoch [19/50], Batch 62/120, Train Loss: 118.7733\n",
      "6902.071823120117\n",
      "Epoch [19/50], Batch 63/120, Train Loss: 119.1131\n",
      "6990.763320922852\n",
      "Epoch [19/50], Batch 64/120, Train Loss: 88.6915\n",
      "7100.281707763672\n",
      "Epoch [19/50], Batch 65/120, Train Loss: 109.5184\n",
      "7213.137962341309\n",
      "Epoch [19/50], Batch 66/120, Train Loss: 112.8563\n",
      "7306.992088317871\n",
      "Epoch [19/50], Batch 67/120, Train Loss: 93.8541\n",
      "7409.855979919434\n",
      "Epoch [19/50], Batch 68/120, Train Loss: 102.8639\n",
      "7513.970596313477\n",
      "Epoch [19/50], Batch 69/120, Train Loss: 104.1146\n",
      "7622.961349487305\n",
      "Epoch [19/50], Batch 70/120, Train Loss: 108.9908\n",
      "7736.188743591309\n",
      "Epoch [19/50], Batch 71/120, Train Loss: 113.2274\n",
      "7865.316062927246\n",
      "Epoch [19/50], Batch 72/120, Train Loss: 129.1273\n",
      "7960.982261657715\n",
      "Epoch [19/50], Batch 73/120, Train Loss: 95.6662\n",
      "8081.039848327637\n",
      "Epoch [19/50], Batch 74/120, Train Loss: 120.0576\n",
      "8184.085014343262\n",
      "Epoch [19/50], Batch 75/120, Train Loss: 103.0452\n",
      "8313.788871765137\n",
      "Epoch [19/50], Batch 76/120, Train Loss: 129.7039\n",
      "8452.793998718262\n",
      "Epoch [19/50], Batch 77/120, Train Loss: 139.0051\n",
      "8546.362663269043\n",
      "Epoch [19/50], Batch 78/120, Train Loss: 93.5687\n",
      "8652.061904907227\n",
      "Epoch [19/50], Batch 79/120, Train Loss: 105.6992\n",
      "8756.259490966797\n",
      "Epoch [19/50], Batch 80/120, Train Loss: 104.1976\n",
      "8848.18539428711\n",
      "Epoch [19/50], Batch 81/120, Train Loss: 91.9259\n",
      "8946.34156036377\n",
      "Epoch [19/50], Batch 82/120, Train Loss: 98.1562\n",
      "9052.23656463623\n",
      "Epoch [19/50], Batch 83/120, Train Loss: 105.8950\n",
      "9175.91136932373\n",
      "Epoch [19/50], Batch 84/120, Train Loss: 123.6748\n",
      "9274.689666748047\n",
      "Epoch [19/50], Batch 85/120, Train Loss: 98.7783\n",
      "9384.008567810059\n",
      "Epoch [19/50], Batch 86/120, Train Loss: 109.3189\n",
      "9504.558250427246\n",
      "Epoch [19/50], Batch 87/120, Train Loss: 120.5497\n",
      "9623.66788482666\n",
      "Epoch [19/50], Batch 88/120, Train Loss: 119.1096\n",
      "9707.380531311035\n",
      "Epoch [19/50], Batch 89/120, Train Loss: 83.7126\n",
      "9811.02465057373\n",
      "Epoch [19/50], Batch 90/120, Train Loss: 103.6441\n",
      "9909.679176330566\n",
      "Epoch [19/50], Batch 91/120, Train Loss: 98.6545\n",
      "10023.587425231934\n",
      "Epoch [19/50], Batch 92/120, Train Loss: 113.9082\n",
      "10121.687690734863\n",
      "Epoch [19/50], Batch 93/120, Train Loss: 98.1003\n",
      "10232.142234802246\n",
      "Epoch [19/50], Batch 94/120, Train Loss: 110.4545\n",
      "10337.582160949707\n",
      "Epoch [19/50], Batch 95/120, Train Loss: 105.4399\n",
      "10422.3265914917\n",
      "Epoch [19/50], Batch 96/120, Train Loss: 84.7444\n",
      "10535.646873474121\n",
      "Epoch [19/50], Batch 97/120, Train Loss: 113.3203\n",
      "10647.99853515625\n",
      "Epoch [19/50], Batch 98/120, Train Loss: 112.3517\n",
      "10751.414154052734\n",
      "Epoch [19/50], Batch 99/120, Train Loss: 103.4156\n",
      "10881.627166748047\n",
      "Epoch [19/50], Batch 100/120, Train Loss: 130.2130\n",
      "10983.041000366211\n",
      "Epoch [19/50], Batch 101/120, Train Loss: 101.4138\n",
      "11104.954895019531\n",
      "Epoch [19/50], Batch 102/120, Train Loss: 121.9139\n",
      "11206.465881347656\n",
      "Epoch [19/50], Batch 103/120, Train Loss: 101.5110\n",
      "11321.37574005127\n",
      "Epoch [19/50], Batch 104/120, Train Loss: 114.9099\n",
      "11425.011268615723\n",
      "Epoch [19/50], Batch 105/120, Train Loss: 103.6355\n",
      "11499.838562011719\n",
      "Epoch [19/50], Batch 106/120, Train Loss: 74.8273\n",
      "11604.892112731934\n",
      "Epoch [19/50], Batch 107/120, Train Loss: 105.0536\n",
      "11717.409156799316\n",
      "Epoch [19/50], Batch 108/120, Train Loss: 112.5170\n",
      "11827.20231628418\n",
      "Epoch [19/50], Batch 109/120, Train Loss: 109.7932\n",
      "11918.449645996094\n",
      "Epoch [19/50], Batch 110/120, Train Loss: 91.2473\n",
      "12028.98403930664\n",
      "Epoch [19/50], Batch 111/120, Train Loss: 110.5344\n",
      "12146.700897216797\n",
      "Epoch [19/50], Batch 112/120, Train Loss: 117.7169\n",
      "12248.256973266602\n",
      "Epoch [19/50], Batch 113/120, Train Loss: 101.5561\n",
      "12372.242614746094\n",
      "Epoch [19/50], Batch 114/120, Train Loss: 123.9856\n",
      "12507.255462646484\n",
      "Epoch [19/50], Batch 115/120, Train Loss: 135.0128\n",
      "12609.981689453125\n",
      "Epoch [19/50], Batch 116/120, Train Loss: 102.7262\n",
      "12719.937561035156\n",
      "Epoch [19/50], Batch 117/120, Train Loss: 109.9559\n",
      "12850.775360107422\n",
      "Epoch [19/50], Batch 118/120, Train Loss: 130.8378\n",
      "12968.363334655762\n",
      "Epoch [19/50], Batch 119/120, Train Loss: 117.5880\n",
      "13082.457290649414\n",
      "Epoch [19/50], Batch 120/120, Train Loss: 114.0940\n",
      "Epoch [19/50], Train Loss: 109.0205, Validation Loss: 117.0641\n",
      "114.29940032958984\n",
      "Epoch [20/50], Batch 1/120, Train Loss: 114.2994\n",
      "207.7442398071289\n",
      "Epoch [20/50], Batch 2/120, Train Loss: 93.4448\n",
      "328.1792221069336\n",
      "Epoch [20/50], Batch 3/120, Train Loss: 120.4350\n",
      "436.573486328125\n",
      "Epoch [20/50], Batch 4/120, Train Loss: 108.3943\n",
      "551.4469604492188\n",
      "Epoch [20/50], Batch 5/120, Train Loss: 114.8735\n",
      "671.7794036865234\n",
      "Epoch [20/50], Batch 6/120, Train Loss: 120.3324\n",
      "769.9578552246094\n",
      "Epoch [20/50], Batch 7/120, Train Loss: 98.1785\n",
      "880.3315200805664\n",
      "Epoch [20/50], Batch 8/120, Train Loss: 110.3737\n",
      "1006.2548522949219\n",
      "Epoch [20/50], Batch 9/120, Train Loss: 125.9233\n",
      "1119.2245712280273\n",
      "Epoch [20/50], Batch 10/120, Train Loss: 112.9697\n",
      "1237.563362121582\n",
      "Epoch [20/50], Batch 11/120, Train Loss: 118.3388\n",
      "1337.286994934082\n",
      "Epoch [20/50], Batch 12/120, Train Loss: 99.7236\n",
      "1445.672996520996\n",
      "Epoch [20/50], Batch 13/120, Train Loss: 108.3860\n",
      "1533.9988098144531\n",
      "Epoch [20/50], Batch 14/120, Train Loss: 88.3258\n",
      "1659.0464935302734\n",
      "Epoch [20/50], Batch 15/120, Train Loss: 125.0477\n",
      "1743.4082336425781\n",
      "Epoch [20/50], Batch 16/120, Train Loss: 84.3617\n",
      "1854.5872650146484\n",
      "Epoch [20/50], Batch 17/120, Train Loss: 111.1790\n",
      "1984.849380493164\n",
      "Epoch [20/50], Batch 18/120, Train Loss: 130.2621\n",
      "2093.5564880371094\n",
      "Epoch [20/50], Batch 19/120, Train Loss: 108.7071\n",
      "2223.2887573242188\n",
      "Epoch [20/50], Batch 20/120, Train Loss: 129.7323\n",
      "2331.019874572754\n",
      "Epoch [20/50], Batch 21/120, Train Loss: 107.7311\n",
      "2448.0128860473633\n",
      "Epoch [20/50], Batch 22/120, Train Loss: 116.9930\n",
      "2557.1724548339844\n",
      "Epoch [20/50], Batch 23/120, Train Loss: 109.1596\n",
      "2662.6606521606445\n",
      "Epoch [20/50], Batch 24/120, Train Loss: 105.4882\n",
      "2776.9201126098633\n",
      "Epoch [20/50], Batch 25/120, Train Loss: 114.2595\n",
      "2871.149238586426\n",
      "Epoch [20/50], Batch 26/120, Train Loss: 94.2291\n",
      "3003.6044692993164\n",
      "Epoch [20/50], Batch 27/120, Train Loss: 132.4552\n",
      "3120.7200241088867\n",
      "Epoch [20/50], Batch 28/120, Train Loss: 117.1156\n",
      "3219.564826965332\n",
      "Epoch [20/50], Batch 29/120, Train Loss: 98.8448\n",
      "3321.54093170166\n",
      "Epoch [20/50], Batch 30/120, Train Loss: 101.9761\n",
      "3404.9007568359375\n",
      "Epoch [20/50], Batch 31/120, Train Loss: 83.3598\n",
      "3538.1373596191406\n",
      "Epoch [20/50], Batch 32/120, Train Loss: 133.2366\n",
      "3646.6876373291016\n",
      "Epoch [20/50], Batch 33/120, Train Loss: 108.5503\n",
      "3749.804916381836\n",
      "Epoch [20/50], Batch 34/120, Train Loss: 103.1173\n",
      "3868.088592529297\n",
      "Epoch [20/50], Batch 35/120, Train Loss: 118.2837\n",
      "3978.9939346313477\n",
      "Epoch [20/50], Batch 36/120, Train Loss: 110.9053\n",
      "4112.355155944824\n",
      "Epoch [20/50], Batch 37/120, Train Loss: 133.3612\n",
      "4223.392051696777\n",
      "Epoch [20/50], Batch 38/120, Train Loss: 111.0369\n",
      "4332.7255783081055\n",
      "Epoch [20/50], Batch 39/120, Train Loss: 109.3335\n",
      "4425.296501159668\n",
      "Epoch [20/50], Batch 40/120, Train Loss: 92.5709\n",
      "4523.896690368652\n",
      "Epoch [20/50], Batch 41/120, Train Loss: 98.6002\n",
      "4611.608619689941\n",
      "Epoch [20/50], Batch 42/120, Train Loss: 87.7119\n",
      "4705.375778198242\n",
      "Epoch [20/50], Batch 43/120, Train Loss: 93.7672\n",
      "4815.805480957031\n",
      "Epoch [20/50], Batch 44/120, Train Loss: 110.4297\n",
      "4910.096099853516\n",
      "Epoch [20/50], Batch 45/120, Train Loss: 94.2906\n",
      "5008.558525085449\n",
      "Epoch [20/50], Batch 46/120, Train Loss: 98.4624\n",
      "5085.642822265625\n",
      "Epoch [20/50], Batch 47/120, Train Loss: 77.0843\n",
      "5181.512832641602\n",
      "Epoch [20/50], Batch 48/120, Train Loss: 95.8700\n",
      "5273.881736755371\n",
      "Epoch [20/50], Batch 49/120, Train Loss: 92.3689\n",
      "5382.767204284668\n",
      "Epoch [20/50], Batch 50/120, Train Loss: 108.8855\n",
      "5486.960624694824\n",
      "Epoch [20/50], Batch 51/120, Train Loss: 104.1934\n",
      "5594.927925109863\n",
      "Epoch [20/50], Batch 52/120, Train Loss: 107.9673\n",
      "5716.334732055664\n",
      "Epoch [20/50], Batch 53/120, Train Loss: 121.4068\n",
      "5823.768280029297\n",
      "Epoch [20/50], Batch 54/120, Train Loss: 107.4335\n",
      "5937.236511230469\n",
      "Epoch [20/50], Batch 55/120, Train Loss: 113.4682\n",
      "6057.936187744141\n",
      "Epoch [20/50], Batch 56/120, Train Loss: 120.6997\n",
      "6188.541595458984\n",
      "Epoch [20/50], Batch 57/120, Train Loss: 130.6054\n",
      "6291.571792602539\n",
      "Epoch [20/50], Batch 58/120, Train Loss: 103.0302\n",
      "6380.817565917969\n",
      "Epoch [20/50], Batch 59/120, Train Loss: 89.2458\n",
      "6484.878128051758\n",
      "Epoch [20/50], Batch 60/120, Train Loss: 104.0606\n",
      "6572.474395751953\n",
      "Epoch [20/50], Batch 61/120, Train Loss: 87.5963\n",
      "6695.884994506836\n",
      "Epoch [20/50], Batch 62/120, Train Loss: 123.4106\n",
      "6806.244247436523\n",
      "Epoch [20/50], Batch 63/120, Train Loss: 110.3593\n",
      "6909.508583068848\n",
      "Epoch [20/50], Batch 64/120, Train Loss: 103.2643\n",
      "6987.464050292969\n",
      "Epoch [20/50], Batch 65/120, Train Loss: 77.9555\n",
      "7080.577789306641\n",
      "Epoch [20/50], Batch 66/120, Train Loss: 93.1137\n",
      "7205.3115234375\n",
      "Epoch [20/50], Batch 67/120, Train Loss: 124.7337\n",
      "7306.929397583008\n",
      "Epoch [20/50], Batch 68/120, Train Loss: 101.6179\n",
      "7403.345855712891\n",
      "Epoch [20/50], Batch 69/120, Train Loss: 96.4165\n",
      "7512.2451171875\n",
      "Epoch [20/50], Batch 70/120, Train Loss: 108.8993\n",
      "7629.097686767578\n",
      "Epoch [20/50], Batch 71/120, Train Loss: 116.8526\n",
      "7734.649871826172\n",
      "Epoch [20/50], Batch 72/120, Train Loss: 105.5522\n",
      "7842.496231079102\n",
      "Epoch [20/50], Batch 73/120, Train Loss: 107.8464\n",
      "7978.136367797852\n",
      "Epoch [20/50], Batch 74/120, Train Loss: 135.6401\n",
      "8066.533554077148\n",
      "Epoch [20/50], Batch 75/120, Train Loss: 88.3972\n",
      "8190.510803222656\n",
      "Epoch [20/50], Batch 76/120, Train Loss: 123.9772\n",
      "8280.979682922363\n",
      "Epoch [20/50], Batch 77/120, Train Loss: 90.4689\n",
      "8383.579887390137\n",
      "Epoch [20/50], Batch 78/120, Train Loss: 102.6002\n",
      "8480.025451660156\n",
      "Epoch [20/50], Batch 79/120, Train Loss: 96.4456\n",
      "8593.271781921387\n",
      "Epoch [20/50], Batch 80/120, Train Loss: 113.2463\n",
      "8668.244491577148\n",
      "Epoch [20/50], Batch 81/120, Train Loss: 74.9727\n",
      "8757.544303894043\n",
      "Epoch [20/50], Batch 82/120, Train Loss: 89.2998\n",
      "8867.315254211426\n",
      "Epoch [20/50], Batch 83/120, Train Loss: 109.7710\n",
      "8958.321273803711\n",
      "Epoch [20/50], Batch 84/120, Train Loss: 91.0060\n",
      "9063.64291381836\n",
      "Epoch [20/50], Batch 85/120, Train Loss: 105.3216\n",
      "9185.881057739258\n",
      "Epoch [20/50], Batch 86/120, Train Loss: 122.2381\n",
      "9277.268798828125\n",
      "Epoch [20/50], Batch 87/120, Train Loss: 91.3877\n",
      "9386.016860961914\n",
      "Epoch [20/50], Batch 88/120, Train Loss: 108.7481\n",
      "9488.526039123535\n",
      "Epoch [20/50], Batch 89/120, Train Loss: 102.5092\n",
      "9587.344917297363\n",
      "Epoch [20/50], Batch 90/120, Train Loss: 98.8189\n",
      "9720.05069732666\n",
      "Epoch [20/50], Batch 91/120, Train Loss: 132.7058\n",
      "9827.743156433105\n",
      "Epoch [20/50], Batch 92/120, Train Loss: 107.6925\n",
      "9927.215614318848\n",
      "Epoch [20/50], Batch 93/120, Train Loss: 99.4725\n",
      "10036.088600158691\n",
      "Epoch [20/50], Batch 94/120, Train Loss: 108.8730\n",
      "10141.104057312012\n",
      "Epoch [20/50], Batch 95/120, Train Loss: 105.0155\n",
      "10262.835792541504\n",
      "Epoch [20/50], Batch 96/120, Train Loss: 121.7317\n",
      "10369.562507629395\n",
      "Epoch [20/50], Batch 97/120, Train Loss: 106.7267\n",
      "10498.151161193848\n",
      "Epoch [20/50], Batch 98/120, Train Loss: 128.5887\n",
      "10598.226364135742\n",
      "Epoch [20/50], Batch 99/120, Train Loss: 100.0752\n",
      "10703.556335449219\n",
      "Epoch [20/50], Batch 100/120, Train Loss: 105.3300\n",
      "10804.95817565918\n",
      "Epoch [20/50], Batch 101/120, Train Loss: 101.4018\n",
      "10912.141616821289\n",
      "Epoch [20/50], Batch 102/120, Train Loss: 107.1834\n",
      "11024.43179321289\n",
      "Epoch [20/50], Batch 103/120, Train Loss: 112.2902\n",
      "11121.741638183594\n",
      "Epoch [20/50], Batch 104/120, Train Loss: 97.3098\n",
      "11222.822769165039\n",
      "Epoch [20/50], Batch 105/120, Train Loss: 101.0811\n",
      "11337.351257324219\n",
      "Epoch [20/50], Batch 106/120, Train Loss: 114.5285\n",
      "11456.720626831055\n",
      "Epoch [20/50], Batch 107/120, Train Loss: 119.3694\n",
      "11579.696701049805\n",
      "Epoch [20/50], Batch 108/120, Train Loss: 122.9761\n",
      "11692.499053955078\n",
      "Epoch [20/50], Batch 109/120, Train Loss: 112.8024\n",
      "11798.302139282227\n",
      "Epoch [20/50], Batch 110/120, Train Loss: 105.8031\n",
      "11916.886581420898\n",
      "Epoch [20/50], Batch 111/120, Train Loss: 118.5844\n",
      "12032.02074432373\n",
      "Epoch [20/50], Batch 112/120, Train Loss: 115.1342\n",
      "12155.37491607666\n",
      "Epoch [20/50], Batch 113/120, Train Loss: 123.3542\n",
      "12263.594207763672\n",
      "Epoch [20/50], Batch 114/120, Train Loss: 108.2193\n",
      "12368.729446411133\n",
      "Epoch [20/50], Batch 115/120, Train Loss: 105.1352\n",
      "12490.620483398438\n",
      "Epoch [20/50], Batch 116/120, Train Loss: 121.8910\n",
      "12608.536994934082\n",
      "Epoch [20/50], Batch 117/120, Train Loss: 117.9165\n",
      "12743.566032409668\n",
      "Epoch [20/50], Batch 118/120, Train Loss: 135.0290\n",
      "12855.613441467285\n",
      "Epoch [20/50], Batch 119/120, Train Loss: 112.0474\n",
      "12947.917152404785\n",
      "Epoch [20/50], Batch 120/120, Train Loss: 92.3037\n",
      "Epoch [20/50], Train Loss: 107.8993, Validation Loss: 116.5154\n",
      "129.30682373046875\n",
      "Epoch [21/50], Batch 1/120, Train Loss: 129.3068\n",
      "213.83131408691406\n",
      "Epoch [21/50], Batch 2/120, Train Loss: 84.5245\n",
      "338.8162841796875\n",
      "Epoch [21/50], Batch 3/120, Train Loss: 124.9850\n",
      "455.7428970336914\n",
      "Epoch [21/50], Batch 4/120, Train Loss: 116.9266\n",
      "555.524299621582\n",
      "Epoch [21/50], Batch 5/120, Train Loss: 99.7814\n",
      "630.4940414428711\n",
      "Epoch [21/50], Batch 6/120, Train Loss: 74.9697\n",
      "732.6886749267578\n",
      "Epoch [21/50], Batch 7/120, Train Loss: 102.1946\n",
      "841.3270645141602\n",
      "Epoch [21/50], Batch 8/120, Train Loss: 108.6384\n",
      "972.6267623901367\n",
      "Epoch [21/50], Batch 9/120, Train Loss: 131.2997\n",
      "1091.5429382324219\n",
      "Epoch [21/50], Batch 10/120, Train Loss: 118.9162\n",
      "1183.5464935302734\n",
      "Epoch [21/50], Batch 11/120, Train Loss: 92.0036\n",
      "1285.5763702392578\n",
      "Epoch [21/50], Batch 12/120, Train Loss: 102.0299\n",
      "1393.0361785888672\n",
      "Epoch [21/50], Batch 13/120, Train Loss: 107.4598\n",
      "1492.7949523925781\n",
      "Epoch [21/50], Batch 14/120, Train Loss: 99.7588\n",
      "1628.0250091552734\n",
      "Epoch [21/50], Batch 15/120, Train Loss: 135.2301\n",
      "1722.730972290039\n",
      "Epoch [21/50], Batch 16/120, Train Loss: 94.7060\n",
      "1814.9196472167969\n",
      "Epoch [21/50], Batch 17/120, Train Loss: 92.1887\n",
      "1912.555778503418\n",
      "Epoch [21/50], Batch 18/120, Train Loss: 97.6361\n",
      "1995.5364837646484\n",
      "Epoch [21/50], Batch 19/120, Train Loss: 82.9807\n",
      "2085.7584533691406\n",
      "Epoch [21/50], Batch 20/120, Train Loss: 90.2220\n",
      "2198.085647583008\n",
      "Epoch [21/50], Batch 21/120, Train Loss: 112.3272\n",
      "2300.857467651367\n",
      "Epoch [21/50], Batch 22/120, Train Loss: 102.7718\n",
      "2396.5025024414062\n",
      "Epoch [21/50], Batch 23/120, Train Loss: 95.6450\n",
      "2498.3118591308594\n",
      "Epoch [21/50], Batch 24/120, Train Loss: 101.8094\n",
      "2581.6834106445312\n",
      "Epoch [21/50], Batch 25/120, Train Loss: 83.3716\n",
      "2710.2427368164062\n",
      "Epoch [21/50], Batch 26/120, Train Loss: 128.5593\n",
      "2811.613037109375\n",
      "Epoch [21/50], Batch 27/120, Train Loss: 101.3703\n",
      "2922.3495330810547\n",
      "Epoch [21/50], Batch 28/120, Train Loss: 110.7365\n",
      "3056.916961669922\n",
      "Epoch [21/50], Batch 29/120, Train Loss: 134.5674\n",
      "3181.684768676758\n",
      "Epoch [21/50], Batch 30/120, Train Loss: 124.7678\n",
      "3276.603988647461\n",
      "Epoch [21/50], Batch 31/120, Train Loss: 94.9192\n",
      "3357.411033630371\n",
      "Epoch [21/50], Batch 32/120, Train Loss: 80.8070\n",
      "3494.073829650879\n",
      "Epoch [21/50], Batch 33/120, Train Loss: 136.6628\n",
      "3602.3353729248047\n",
      "Epoch [21/50], Batch 34/120, Train Loss: 108.2615\n",
      "3714.3607025146484\n",
      "Epoch [21/50], Batch 35/120, Train Loss: 112.0253\n",
      "3811.6455459594727\n",
      "Epoch [21/50], Batch 36/120, Train Loss: 97.2848\n",
      "3909.4755630493164\n",
      "Epoch [21/50], Batch 37/120, Train Loss: 97.8300\n",
      "4011.324592590332\n",
      "Epoch [21/50], Batch 38/120, Train Loss: 101.8490\n",
      "4116.868232727051\n",
      "Epoch [21/50], Batch 39/120, Train Loss: 105.5436\n",
      "4234.580780029297\n",
      "Epoch [21/50], Batch 40/120, Train Loss: 117.7125\n",
      "4334.117034912109\n",
      "Epoch [21/50], Batch 41/120, Train Loss: 99.5363\n",
      "4445.010192871094\n",
      "Epoch [21/50], Batch 42/120, Train Loss: 110.8932\n",
      "4554.368347167969\n",
      "Epoch [21/50], Batch 43/120, Train Loss: 109.3582\n",
      "4627.463157653809\n",
      "Epoch [21/50], Batch 44/120, Train Loss: 73.0948\n",
      "4723.442169189453\n",
      "Epoch [21/50], Batch 45/120, Train Loss: 95.9790\n",
      "4860.259948730469\n",
      "Epoch [21/50], Batch 46/120, Train Loss: 136.8178\n",
      "4966.07275390625\n",
      "Epoch [21/50], Batch 47/120, Train Loss: 105.8128\n",
      "5083.881332397461\n",
      "Epoch [21/50], Batch 48/120, Train Loss: 117.8086\n",
      "5200.986831665039\n",
      "Epoch [21/50], Batch 49/120, Train Loss: 117.1055\n",
      "5312.761734008789\n",
      "Epoch [21/50], Batch 50/120, Train Loss: 111.7749\n",
      "5421.992851257324\n",
      "Epoch [21/50], Batch 51/120, Train Loss: 109.2311\n",
      "5528.888710021973\n",
      "Epoch [21/50], Batch 52/120, Train Loss: 106.8959\n",
      "5619.587715148926\n",
      "Epoch [21/50], Batch 53/120, Train Loss: 90.6990\n",
      "5694.90616607666\n",
      "Epoch [21/50], Batch 54/120, Train Loss: 75.3185\n",
      "5820.076629638672\n",
      "Epoch [21/50], Batch 55/120, Train Loss: 125.1705\n",
      "5921.68830871582\n",
      "Epoch [21/50], Batch 56/120, Train Loss: 101.6117\n",
      "6008.819732666016\n",
      "Epoch [21/50], Batch 57/120, Train Loss: 87.1314\n",
      "6139.85969543457\n",
      "Epoch [21/50], Batch 58/120, Train Loss: 131.0400\n",
      "6243.665786743164\n",
      "Epoch [21/50], Batch 59/120, Train Loss: 103.8061\n",
      "6362.292137145996\n",
      "Epoch [21/50], Batch 60/120, Train Loss: 118.6264\n",
      "6481.854057312012\n",
      "Epoch [21/50], Batch 61/120, Train Loss: 119.5619\n",
      "6613.411949157715\n",
      "Epoch [21/50], Batch 62/120, Train Loss: 131.5579\n",
      "6710.943321228027\n",
      "Epoch [21/50], Batch 63/120, Train Loss: 97.5314\n",
      "6807.268623352051\n",
      "Epoch [21/50], Batch 64/120, Train Loss: 96.3253\n",
      "6907.059791564941\n",
      "Epoch [21/50], Batch 65/120, Train Loss: 99.7912\n",
      "7016.588447570801\n",
      "Epoch [21/50], Batch 66/120, Train Loss: 109.5287\n",
      "7127.290153503418\n",
      "Epoch [21/50], Batch 67/120, Train Loss: 110.7017\n",
      "7244.829818725586\n",
      "Epoch [21/50], Batch 68/120, Train Loss: 117.5397\n",
      "7354.601516723633\n",
      "Epoch [21/50], Batch 69/120, Train Loss: 109.7717\n",
      "7453.888595581055\n",
      "Epoch [21/50], Batch 70/120, Train Loss: 99.2871\n",
      "7565.654998779297\n",
      "Epoch [21/50], Batch 71/120, Train Loss: 111.7664\n",
      "7703.021942138672\n",
      "Epoch [21/50], Batch 72/120, Train Loss: 137.3669\n",
      "7782.132621765137\n",
      "Epoch [21/50], Batch 73/120, Train Loss: 79.1107\n",
      "7880.93009185791\n",
      "Epoch [21/50], Batch 74/120, Train Loss: 98.7975\n",
      "8011.533790588379\n",
      "Epoch [21/50], Batch 75/120, Train Loss: 130.6037\n",
      "8129.527618408203\n",
      "Epoch [21/50], Batch 76/120, Train Loss: 117.9938\n",
      "8273.639739990234\n",
      "Epoch [21/50], Batch 77/120, Train Loss: 144.1121\n",
      "8379.406112670898\n",
      "Epoch [21/50], Batch 78/120, Train Loss: 105.7664\n",
      "8489.195999145508\n",
      "Epoch [21/50], Batch 79/120, Train Loss: 109.7899\n",
      "8583.357093811035\n",
      "Epoch [21/50], Batch 80/120, Train Loss: 94.1611\n",
      "8697.592277526855\n",
      "Epoch [21/50], Batch 81/120, Train Loss: 114.2352\n",
      "8796.923301696777\n",
      "Epoch [21/50], Batch 82/120, Train Loss: 99.3310\n",
      "8891.715126037598\n",
      "Epoch [21/50], Batch 83/120, Train Loss: 94.7918\n",
      "8983.807655334473\n",
      "Epoch [21/50], Batch 84/120, Train Loss: 92.0925\n",
      "9078.260108947754\n",
      "Epoch [21/50], Batch 85/120, Train Loss: 94.4525\n",
      "9185.354064941406\n",
      "Epoch [21/50], Batch 86/120, Train Loss: 107.0940\n",
      "9281.862091064453\n",
      "Epoch [21/50], Batch 87/120, Train Loss: 96.5080\n",
      "9392.86474609375\n",
      "Epoch [21/50], Batch 88/120, Train Loss: 111.0027\n",
      "9495.175178527832\n",
      "Epoch [21/50], Batch 89/120, Train Loss: 102.3104\n",
      "9571.619483947754\n",
      "Epoch [21/50], Batch 90/120, Train Loss: 76.4443\n",
      "9665.63729095459\n",
      "Epoch [21/50], Batch 91/120, Train Loss: 94.0178\n",
      "9746.395179748535\n",
      "Epoch [21/50], Batch 92/120, Train Loss: 80.7579\n",
      "9872.046607971191\n",
      "Epoch [21/50], Batch 93/120, Train Loss: 125.6514\n",
      "9970.026542663574\n",
      "Epoch [21/50], Batch 94/120, Train Loss: 97.9799\n",
      "10081.67416381836\n",
      "Epoch [21/50], Batch 95/120, Train Loss: 111.6476\n",
      "10194.878517150879\n",
      "Epoch [21/50], Batch 96/120, Train Loss: 113.2044\n",
      "10305.809837341309\n",
      "Epoch [21/50], Batch 97/120, Train Loss: 110.9313\n",
      "10400.768074035645\n",
      "Epoch [21/50], Batch 98/120, Train Loss: 94.9582\n",
      "10511.053436279297\n",
      "Epoch [21/50], Batch 99/120, Train Loss: 110.2854\n",
      "10616.100997924805\n",
      "Epoch [21/50], Batch 100/120, Train Loss: 105.0476\n",
      "10711.520462036133\n",
      "Epoch [21/50], Batch 101/120, Train Loss: 95.4195\n",
      "10826.928268432617\n",
      "Epoch [21/50], Batch 102/120, Train Loss: 115.4078\n",
      "10919.080108642578\n",
      "Epoch [21/50], Batch 103/120, Train Loss: 92.1518\n",
      "11018.714584350586\n",
      "Epoch [21/50], Batch 104/120, Train Loss: 99.6345\n",
      "11123.171737670898\n",
      "Epoch [21/50], Batch 105/120, Train Loss: 104.4572\n",
      "11220.746200561523\n",
      "Epoch [21/50], Batch 106/120, Train Loss: 97.5745\n",
      "11321.451950073242\n",
      "Epoch [21/50], Batch 107/120, Train Loss: 100.7057\n",
      "11416.237266540527\n",
      "Epoch [21/50], Batch 108/120, Train Loss: 94.7853\n",
      "11517.374656677246\n",
      "Epoch [21/50], Batch 109/120, Train Loss: 101.1374\n",
      "11639.773918151855\n",
      "Epoch [21/50], Batch 110/120, Train Loss: 122.3993\n",
      "11739.995002746582\n",
      "Epoch [21/50], Batch 111/120, Train Loss: 100.2211\n",
      "11854.077598571777\n",
      "Epoch [21/50], Batch 112/120, Train Loss: 114.0826\n",
      "11972.453887939453\n",
      "Epoch [21/50], Batch 113/120, Train Loss: 118.3763\n",
      "12102.592346191406\n",
      "Epoch [21/50], Batch 114/120, Train Loss: 130.1385\n",
      "12196.079132080078\n",
      "Epoch [21/50], Batch 115/120, Train Loss: 93.4868\n",
      "12328.498565673828\n",
      "Epoch [21/50], Batch 116/120, Train Loss: 132.4194\n",
      "12453.731643676758\n",
      "Epoch [21/50], Batch 117/120, Train Loss: 125.2331\n",
      "12535.245544433594\n",
      "Epoch [21/50], Batch 118/120, Train Loss: 81.5139\n",
      "12641.147232055664\n",
      "Epoch [21/50], Batch 119/120, Train Loss: 105.9017\n",
      "12766.142501831055\n",
      "Epoch [21/50], Batch 120/120, Train Loss: 124.9953\n",
      "Epoch [21/50], Train Loss: 106.3845, Validation Loss: 115.5289\n",
      "87.49156188964844\n",
      "Epoch [22/50], Batch 1/120, Train Loss: 87.4916\n",
      "173.9367446899414\n",
      "Epoch [22/50], Batch 2/120, Train Loss: 86.4452\n",
      "268.797607421875\n",
      "Epoch [22/50], Batch 3/120, Train Loss: 94.8609\n",
      "383.89671325683594\n",
      "Epoch [22/50], Batch 4/120, Train Loss: 115.0991\n",
      "503.5751495361328\n",
      "Epoch [22/50], Batch 5/120, Train Loss: 119.6784\n",
      "597.7550659179688\n",
      "Epoch [22/50], Batch 6/120, Train Loss: 94.1799\n",
      "689.6368865966797\n",
      "Epoch [22/50], Batch 7/120, Train Loss: 91.8818\n",
      "790.9644165039062\n",
      "Epoch [22/50], Batch 8/120, Train Loss: 101.3275\n",
      "927.8470764160156\n",
      "Epoch [22/50], Batch 9/120, Train Loss: 136.8827\n",
      "1023.1357116699219\n",
      "Epoch [22/50], Batch 10/120, Train Loss: 95.2886\n",
      "1122.4518508911133\n",
      "Epoch [22/50], Batch 11/120, Train Loss: 99.3161\n",
      "1224.1184463500977\n",
      "Epoch [22/50], Batch 12/120, Train Loss: 101.6666\n",
      "1328.1214065551758\n",
      "Epoch [22/50], Batch 13/120, Train Loss: 104.0030\n",
      "1405.7942276000977\n",
      "Epoch [22/50], Batch 14/120, Train Loss: 77.6728\n",
      "1481.6312789916992\n",
      "Epoch [22/50], Batch 15/120, Train Loss: 75.8371\n",
      "1590.5281982421875\n",
      "Epoch [22/50], Batch 16/120, Train Loss: 108.8969\n",
      "1719.9015808105469\n",
      "Epoch [22/50], Batch 17/120, Train Loss: 129.3734\n",
      "1831.586311340332\n",
      "Epoch [22/50], Batch 18/120, Train Loss: 111.6847\n",
      "1940.498176574707\n",
      "Epoch [22/50], Batch 19/120, Train Loss: 108.9119\n",
      "2050.504104614258\n",
      "Epoch [22/50], Batch 20/120, Train Loss: 110.0059\n",
      "2165.9348754882812\n",
      "Epoch [22/50], Batch 21/120, Train Loss: 115.4308\n",
      "2273.8735122680664\n",
      "Epoch [22/50], Batch 22/120, Train Loss: 107.9386\n",
      "2379.1542358398438\n",
      "Epoch [22/50], Batch 23/120, Train Loss: 105.2807\n",
      "2494.682098388672\n",
      "Epoch [22/50], Batch 24/120, Train Loss: 115.5279\n",
      "2604.669952392578\n",
      "Epoch [22/50], Batch 25/120, Train Loss: 109.9879\n",
      "2697.850082397461\n",
      "Epoch [22/50], Batch 26/120, Train Loss: 93.1801\n",
      "2785.6477279663086\n",
      "Epoch [22/50], Batch 27/120, Train Loss: 87.7976\n",
      "2870.8517990112305\n",
      "Epoch [22/50], Batch 28/120, Train Loss: 85.2041\n",
      "2957.8064727783203\n",
      "Epoch [22/50], Batch 29/120, Train Loss: 86.9547\n",
      "3062.130828857422\n",
      "Epoch [22/50], Batch 30/120, Train Loss: 104.3244\n",
      "3193.6917877197266\n",
      "Epoch [22/50], Batch 31/120, Train Loss: 131.5610\n",
      "3306.0584411621094\n",
      "Epoch [22/50], Batch 32/120, Train Loss: 112.3667\n",
      "3416.7344665527344\n",
      "Epoch [22/50], Batch 33/120, Train Loss: 110.6760\n",
      "3508.911880493164\n",
      "Epoch [22/50], Batch 34/120, Train Loss: 92.1774\n",
      "3619.783058166504\n",
      "Epoch [22/50], Batch 35/120, Train Loss: 110.8712\n",
      "3709.8669357299805\n",
      "Epoch [22/50], Batch 36/120, Train Loss: 90.0839\n",
      "3820.131172180176\n",
      "Epoch [22/50], Batch 37/120, Train Loss: 110.2642\n",
      "3890.631477355957\n",
      "Epoch [22/50], Batch 38/120, Train Loss: 70.5003\n",
      "3995.232246398926\n",
      "Epoch [22/50], Batch 39/120, Train Loss: 104.6008\n",
      "4094.2263565063477\n",
      "Epoch [22/50], Batch 40/120, Train Loss: 98.9941\n",
      "4199.1013259887695\n",
      "Epoch [22/50], Batch 41/120, Train Loss: 104.8750\n",
      "4322.198265075684\n",
      "Epoch [22/50], Batch 42/120, Train Loss: 123.0969\n",
      "4451.025932312012\n",
      "Epoch [22/50], Batch 43/120, Train Loss: 128.8277\n",
      "4573.947319030762\n",
      "Epoch [22/50], Batch 44/120, Train Loss: 122.9214\n",
      "4692.300483703613\n",
      "Epoch [22/50], Batch 45/120, Train Loss: 118.3532\n",
      "4800.470161437988\n",
      "Epoch [22/50], Batch 46/120, Train Loss: 108.1697\n",
      "4908.140830993652\n",
      "Epoch [22/50], Batch 47/120, Train Loss: 107.6707\n",
      "5021.56990814209\n",
      "Epoch [22/50], Batch 48/120, Train Loss: 113.4291\n",
      "5124.193550109863\n",
      "Epoch [22/50], Batch 49/120, Train Loss: 102.6236\n",
      "5220.52848815918\n",
      "Epoch [22/50], Batch 50/120, Train Loss: 96.3349\n",
      "5322.0635986328125\n",
      "Epoch [22/50], Batch 51/120, Train Loss: 101.5351\n",
      "5442.069137573242\n",
      "Epoch [22/50], Batch 52/120, Train Loss: 120.0055\n",
      "5540.023483276367\n",
      "Epoch [22/50], Batch 53/120, Train Loss: 97.9543\n",
      "5625.934959411621\n",
      "Epoch [22/50], Batch 54/120, Train Loss: 85.9115\n",
      "5725.224189758301\n",
      "Epoch [22/50], Batch 55/120, Train Loss: 99.2892\n",
      "5841.596565246582\n",
      "Epoch [22/50], Batch 56/120, Train Loss: 116.3724\n",
      "5932.913757324219\n",
      "Epoch [22/50], Batch 57/120, Train Loss: 91.3172\n",
      "6045.870933532715\n",
      "Epoch [22/50], Batch 58/120, Train Loss: 112.9572\n",
      "6146.636741638184\n",
      "Epoch [22/50], Batch 59/120, Train Loss: 100.7658\n",
      "6236.8068771362305\n",
      "Epoch [22/50], Batch 60/120, Train Loss: 90.1701\n",
      "6351.279739379883\n",
      "Epoch [22/50], Batch 61/120, Train Loss: 114.4729\n",
      "6462.648193359375\n",
      "Epoch [22/50], Batch 62/120, Train Loss: 111.3685\n",
      "6554.940963745117\n",
      "Epoch [22/50], Batch 63/120, Train Loss: 92.2928\n",
      "6639.519500732422\n",
      "Epoch [22/50], Batch 64/120, Train Loss: 84.5785\n",
      "6721.847229003906\n",
      "Epoch [22/50], Batch 65/120, Train Loss: 82.3277\n",
      "6857.241622924805\n",
      "Epoch [22/50], Batch 66/120, Train Loss: 135.3944\n",
      "6977.479263305664\n",
      "Epoch [22/50], Batch 67/120, Train Loss: 120.2376\n",
      "7076.66512298584\n",
      "Epoch [22/50], Batch 68/120, Train Loss: 99.1859\n",
      "7181.948432922363\n",
      "Epoch [22/50], Batch 69/120, Train Loss: 105.2833\n",
      "7282.09952545166\n",
      "Epoch [22/50], Batch 70/120, Train Loss: 100.1511\n",
      "7377.253494262695\n",
      "Epoch [22/50], Batch 71/120, Train Loss: 95.1540\n",
      "7499.072616577148\n",
      "Epoch [22/50], Batch 72/120, Train Loss: 121.8191\n",
      "7599.34415435791\n",
      "Epoch [22/50], Batch 73/120, Train Loss: 100.2715\n",
      "7698.121490478516\n",
      "Epoch [22/50], Batch 74/120, Train Loss: 98.7773\n",
      "7819.179420471191\n",
      "Epoch [22/50], Batch 75/120, Train Loss: 121.0579\n",
      "7942.325630187988\n",
      "Epoch [22/50], Batch 76/120, Train Loss: 123.1462\n",
      "8037.370994567871\n",
      "Epoch [22/50], Batch 77/120, Train Loss: 95.0454\n",
      "8156.658767700195\n",
      "Epoch [22/50], Batch 78/120, Train Loss: 119.2878\n",
      "8275.644706726074\n",
      "Epoch [22/50], Batch 79/120, Train Loss: 118.9859\n",
      "8389.58169555664\n",
      "Epoch [22/50], Batch 80/120, Train Loss: 113.9370\n",
      "8486.117080688477\n",
      "Epoch [22/50], Batch 81/120, Train Loss: 96.5354\n",
      "8585.643432617188\n",
      "Epoch [22/50], Batch 82/120, Train Loss: 99.5264\n",
      "8721.544158935547\n",
      "Epoch [22/50], Batch 83/120, Train Loss: 135.9007\n",
      "8813.563766479492\n",
      "Epoch [22/50], Batch 84/120, Train Loss: 92.0196\n",
      "8895.597412109375\n",
      "Epoch [22/50], Batch 85/120, Train Loss: 82.0336\n",
      "8998.130355834961\n",
      "Epoch [22/50], Batch 86/120, Train Loss: 102.5329\n",
      "9080.00178527832\n",
      "Epoch [22/50], Batch 87/120, Train Loss: 81.8714\n",
      "9187.472091674805\n",
      "Epoch [22/50], Batch 88/120, Train Loss: 107.4703\n",
      "9274.248313903809\n",
      "Epoch [22/50], Batch 89/120, Train Loss: 86.7762\n",
      "9367.260124206543\n",
      "Epoch [22/50], Batch 90/120, Train Loss: 93.0118\n",
      "9494.944137573242\n",
      "Epoch [22/50], Batch 91/120, Train Loss: 127.6840\n",
      "9601.994812011719\n",
      "Epoch [22/50], Batch 92/120, Train Loss: 107.0507\n",
      "9693.070289611816\n",
      "Epoch [22/50], Batch 93/120, Train Loss: 91.0755\n",
      "9771.109115600586\n",
      "Epoch [22/50], Batch 94/120, Train Loss: 78.0388\n",
      "9882.482917785645\n",
      "Epoch [22/50], Batch 95/120, Train Loss: 111.3738\n",
      "10002.467506408691\n",
      "Epoch [22/50], Batch 96/120, Train Loss: 119.9846\n",
      "10110.279029846191\n",
      "Epoch [22/50], Batch 97/120, Train Loss: 107.8115\n",
      "10204.604179382324\n",
      "Epoch [22/50], Batch 98/120, Train Loss: 94.3251\n",
      "10321.36164855957\n",
      "Epoch [22/50], Batch 99/120, Train Loss: 116.7575\n",
      "10423.91089630127\n",
      "Epoch [22/50], Batch 100/120, Train Loss: 102.5492\n",
      "10521.604637145996\n",
      "Epoch [22/50], Batch 101/120, Train Loss: 97.6937\n",
      "10630.410743713379\n",
      "Epoch [22/50], Batch 102/120, Train Loss: 108.8061\n",
      "10746.754676818848\n",
      "Epoch [22/50], Batch 103/120, Train Loss: 116.3439\n",
      "10852.527488708496\n",
      "Epoch [22/50], Batch 104/120, Train Loss: 105.7728\n",
      "10955.81127166748\n",
      "Epoch [22/50], Batch 105/120, Train Loss: 103.2838\n",
      "11041.745262145996\n",
      "Epoch [22/50], Batch 106/120, Train Loss: 85.9340\n",
      "11148.927917480469\n",
      "Epoch [22/50], Batch 107/120, Train Loss: 107.1827\n",
      "11255.963088989258\n",
      "Epoch [22/50], Batch 108/120, Train Loss: 107.0352\n",
      "11350.922286987305\n",
      "Epoch [22/50], Batch 109/120, Train Loss: 94.9592\n",
      "11468.743072509766\n",
      "Epoch [22/50], Batch 110/120, Train Loss: 117.8208\n",
      "11594.936851501465\n",
      "Epoch [22/50], Batch 111/120, Train Loss: 126.1938\n",
      "11700.928886413574\n",
      "Epoch [22/50], Batch 112/120, Train Loss: 105.9920\n",
      "11799.73363494873\n",
      "Epoch [22/50], Batch 113/120, Train Loss: 98.8047\n",
      "11884.372032165527\n",
      "Epoch [22/50], Batch 114/120, Train Loss: 84.6384\n",
      "11994.561195373535\n",
      "Epoch [22/50], Batch 115/120, Train Loss: 110.1892\n",
      "12112.297218322754\n",
      "Epoch [22/50], Batch 116/120, Train Loss: 117.7360\n",
      "12202.617454528809\n",
      "Epoch [22/50], Batch 117/120, Train Loss: 90.3202\n",
      "12309.175285339355\n",
      "Epoch [22/50], Batch 118/120, Train Loss: 106.5578\n",
      "12409.40325164795\n",
      "Epoch [22/50], Batch 119/120, Train Loss: 100.2280\n",
      "12517.769371032715\n",
      "Epoch [22/50], Batch 120/120, Train Loss: 108.3661\n",
      "Epoch [22/50], Train Loss: 104.3147, Validation Loss: 114.5699\n",
      "108.17172241210938\n",
      "Epoch [23/50], Batch 1/120, Train Loss: 108.1717\n",
      "219.99994659423828\n",
      "Epoch [23/50], Batch 2/120, Train Loss: 111.8282\n",
      "331.9223861694336\n",
      "Epoch [23/50], Batch 3/120, Train Loss: 111.9224\n",
      "435.3527603149414\n",
      "Epoch [23/50], Batch 4/120, Train Loss: 103.4304\n",
      "514.3422317504883\n",
      "Epoch [23/50], Batch 5/120, Train Loss: 78.9895\n",
      "605.4267120361328\n",
      "Epoch [23/50], Batch 6/120, Train Loss: 91.0845\n",
      "713.13427734375\n",
      "Epoch [23/50], Batch 7/120, Train Loss: 107.7076\n",
      "847.2462615966797\n",
      "Epoch [23/50], Batch 8/120, Train Loss: 134.1120\n",
      "960.2217254638672\n",
      "Epoch [23/50], Batch 9/120, Train Loss: 112.9755\n",
      "1067.1858978271484\n",
      "Epoch [23/50], Batch 10/120, Train Loss: 106.9642\n",
      "1166.537612915039\n",
      "Epoch [23/50], Batch 11/120, Train Loss: 99.3517\n",
      "1302.8816680908203\n",
      "Epoch [23/50], Batch 12/120, Train Loss: 136.3441\n",
      "1426.0087890625\n",
      "Epoch [23/50], Batch 13/120, Train Loss: 123.1271\n",
      "1517.2442245483398\n",
      "Epoch [23/50], Batch 14/120, Train Loss: 91.2354\n",
      "1597.971549987793\n",
      "Epoch [23/50], Batch 15/120, Train Loss: 80.7273\n",
      "1785.0578384399414\n",
      "Epoch [23/50], Batch 16/120, Train Loss: 187.0863\n",
      "1903.1057510375977\n",
      "Epoch [23/50], Batch 17/120, Train Loss: 118.0479\n",
      "2008.144775390625\n",
      "Epoch [23/50], Batch 18/120, Train Loss: 105.0390\n",
      "2133.7999877929688\n",
      "Epoch [23/50], Batch 19/120, Train Loss: 125.6552\n",
      "2237.9273986816406\n",
      "Epoch [23/50], Batch 20/120, Train Loss: 104.1274\n",
      "2327.0585327148438\n",
      "Epoch [23/50], Batch 21/120, Train Loss: 89.1311\n",
      "2446.1983337402344\n",
      "Epoch [23/50], Batch 22/120, Train Loss: 119.1398\n",
      "2532.0968017578125\n",
      "Epoch [23/50], Batch 23/120, Train Loss: 85.8985\n",
      "2626.5101470947266\n",
      "Epoch [23/50], Batch 24/120, Train Loss: 94.4133\n",
      "2743.8845825195312\n",
      "Epoch [23/50], Batch 25/120, Train Loss: 117.3744\n",
      "2841.2110137939453\n",
      "Epoch [23/50], Batch 26/120, Train Loss: 97.3264\n",
      "2980.7625122070312\n",
      "Epoch [23/50], Batch 27/120, Train Loss: 139.5515\n",
      "3093.346420288086\n",
      "Epoch [23/50], Batch 28/120, Train Loss: 112.5839\n",
      "3196.8836364746094\n",
      "Epoch [23/50], Batch 29/120, Train Loss: 103.5372\n",
      "3308.955810546875\n",
      "Epoch [23/50], Batch 30/120, Train Loss: 112.0722\n",
      "3410.750289916992\n",
      "Epoch [23/50], Batch 31/120, Train Loss: 101.7945\n",
      "3508.7401733398438\n",
      "Epoch [23/50], Batch 32/120, Train Loss: 97.9899\n",
      "3598.906005859375\n",
      "Epoch [23/50], Batch 33/120, Train Loss: 90.1658\n",
      "3689.0454711914062\n",
      "Epoch [23/50], Batch 34/120, Train Loss: 90.1395\n",
      "3781.004898071289\n",
      "Epoch [23/50], Batch 35/120, Train Loss: 91.9594\n",
      "3896.0572967529297\n",
      "Epoch [23/50], Batch 36/120, Train Loss: 115.0524\n",
      "3995.783432006836\n",
      "Epoch [23/50], Batch 37/120, Train Loss: 99.7261\n",
      "4091.033935546875\n",
      "Epoch [23/50], Batch 38/120, Train Loss: 95.2505\n",
      "4198.553237915039\n",
      "Epoch [23/50], Batch 39/120, Train Loss: 107.5193\n",
      "4303.6707763671875\n",
      "Epoch [23/50], Batch 40/120, Train Loss: 105.1175\n",
      "4410.04655456543\n",
      "Epoch [23/50], Batch 41/120, Train Loss: 106.3758\n",
      "4530.071342468262\n",
      "Epoch [23/50], Batch 42/120, Train Loss: 120.0248\n",
      "4639.295768737793\n",
      "Epoch [23/50], Batch 43/120, Train Loss: 109.2244\n",
      "4727.495872497559\n",
      "Epoch [23/50], Batch 44/120, Train Loss: 88.2001\n",
      "4850.1630935668945\n",
      "Epoch [23/50], Batch 45/120, Train Loss: 122.6672\n",
      "4958.253791809082\n",
      "Epoch [23/50], Batch 46/120, Train Loss: 108.0907\n",
      "5078.017539978027\n",
      "Epoch [23/50], Batch 47/120, Train Loss: 119.7637\n",
      "5185.1352615356445\n",
      "Epoch [23/50], Batch 48/120, Train Loss: 107.1177\n",
      "5309.45760345459\n",
      "Epoch [23/50], Batch 49/120, Train Loss: 124.3223\n",
      "5431.83772277832\n",
      "Epoch [23/50], Batch 50/120, Train Loss: 122.3801\n",
      "5513.779899597168\n",
      "Epoch [23/50], Batch 51/120, Train Loss: 81.9422\n",
      "5621.986907958984\n",
      "Epoch [23/50], Batch 52/120, Train Loss: 108.2070\n",
      "5721.93635559082\n",
      "Epoch [23/50], Batch 53/120, Train Loss: 99.9494\n",
      "5842.269821166992\n",
      "Epoch [23/50], Batch 54/120, Train Loss: 120.3335\n",
      "5959.133117675781\n",
      "Epoch [23/50], Batch 55/120, Train Loss: 116.8633\n",
      "6057.380432128906\n",
      "Epoch [23/50], Batch 56/120, Train Loss: 98.2473\n",
      "6165.868225097656\n",
      "Epoch [23/50], Batch 57/120, Train Loss: 108.4878\n",
      "6276.032783508301\n",
      "Epoch [23/50], Batch 58/120, Train Loss: 110.1646\n",
      "6388.840644836426\n",
      "Epoch [23/50], Batch 59/120, Train Loss: 112.8079\n",
      "6487.639823913574\n",
      "Epoch [23/50], Batch 60/120, Train Loss: 98.7992\n",
      "6615.81778717041\n",
      "Epoch [23/50], Batch 61/120, Train Loss: 128.1780\n",
      "6702.2841720581055\n",
      "Epoch [23/50], Batch 62/120, Train Loss: 86.4664\n",
      "6806.504669189453\n",
      "Epoch [23/50], Batch 63/120, Train Loss: 104.2205\n",
      "6912.949645996094\n",
      "Epoch [23/50], Batch 64/120, Train Loss: 106.4450\n",
      "7025.904296875\n",
      "Epoch [23/50], Batch 65/120, Train Loss: 112.9547\n",
      "7120.584526062012\n",
      "Epoch [23/50], Batch 66/120, Train Loss: 94.6802\n",
      "7217.327354431152\n",
      "Epoch [23/50], Batch 67/120, Train Loss: 96.7428\n",
      "7328.241607666016\n",
      "Epoch [23/50], Batch 68/120, Train Loss: 110.9143\n",
      "7429.093521118164\n",
      "Epoch [23/50], Batch 69/120, Train Loss: 100.8519\n",
      "7537.254913330078\n",
      "Epoch [23/50], Batch 70/120, Train Loss: 108.1614\n",
      "7658.161811828613\n",
      "Epoch [23/50], Batch 71/120, Train Loss: 120.9069\n",
      "7746.509452819824\n",
      "Epoch [23/50], Batch 72/120, Train Loss: 88.3476\n",
      "7839.76114654541\n",
      "Epoch [23/50], Batch 73/120, Train Loss: 93.2517\n",
      "7923.5268630981445\n",
      "Epoch [23/50], Batch 74/120, Train Loss: 83.7657\n",
      "8034.110954284668\n",
      "Epoch [23/50], Batch 75/120, Train Loss: 110.5841\n",
      "8157.35799407959\n",
      "Epoch [23/50], Batch 76/120, Train Loss: 123.2470\n",
      "8282.854843139648\n",
      "Epoch [23/50], Batch 77/120, Train Loss: 125.4968\n",
      "8393.84097290039\n",
      "Epoch [23/50], Batch 78/120, Train Loss: 110.9861\n",
      "8515.204475402832\n",
      "Epoch [23/50], Batch 79/120, Train Loss: 121.3635\n",
      "8628.676170349121\n",
      "Epoch [23/50], Batch 80/120, Train Loss: 113.4717\n",
      "8736.460006713867\n",
      "Epoch [23/50], Batch 81/120, Train Loss: 107.7838\n",
      "8849.575439453125\n",
      "Epoch [23/50], Batch 82/120, Train Loss: 113.1154\n",
      "8934.171844482422\n",
      "Epoch [23/50], Batch 83/120, Train Loss: 84.5964\n",
      "9051.291358947754\n",
      "Epoch [23/50], Batch 84/120, Train Loss: 117.1195\n",
      "9199.121269226074\n",
      "Epoch [23/50], Batch 85/120, Train Loss: 147.8299\n",
      "9300.621810913086\n",
      "Epoch [23/50], Batch 86/120, Train Loss: 101.5005\n",
      "9405.723037719727\n",
      "Epoch [23/50], Batch 87/120, Train Loss: 105.1012\n",
      "9490.803016662598\n",
      "Epoch [23/50], Batch 88/120, Train Loss: 85.0800\n",
      "9609.032508850098\n",
      "Epoch [23/50], Batch 89/120, Train Loss: 118.2295\n",
      "9698.944221496582\n",
      "Epoch [23/50], Batch 90/120, Train Loss: 89.9117\n",
      "9799.157501220703\n",
      "Epoch [23/50], Batch 91/120, Train Loss: 100.2133\n",
      "9909.977081298828\n",
      "Epoch [23/50], Batch 92/120, Train Loss: 110.8196\n",
      "10019.966552734375\n",
      "Epoch [23/50], Batch 93/120, Train Loss: 109.9895\n",
      "10122.81510925293\n",
      "Epoch [23/50], Batch 94/120, Train Loss: 102.8486\n",
      "10237.74649810791\n",
      "Epoch [23/50], Batch 95/120, Train Loss: 114.9314\n",
      "10338.281623840332\n",
      "Epoch [23/50], Batch 96/120, Train Loss: 100.5351\n",
      "10446.758399963379\n",
      "Epoch [23/50], Batch 97/120, Train Loss: 108.4768\n",
      "10557.001678466797\n",
      "Epoch [23/50], Batch 98/120, Train Loss: 110.2433\n",
      "10689.83120727539\n",
      "Epoch [23/50], Batch 99/120, Train Loss: 132.8295\n",
      "10792.411636352539\n",
      "Epoch [23/50], Batch 100/120, Train Loss: 102.5804\n",
      "10900.242904663086\n",
      "Epoch [23/50], Batch 101/120, Train Loss: 107.8313\n",
      "10989.619750976562\n",
      "Epoch [23/50], Batch 102/120, Train Loss: 89.3768\n",
      "11089.469436645508\n",
      "Epoch [23/50], Batch 103/120, Train Loss: 99.8497\n",
      "11184.5078125\n",
      "Epoch [23/50], Batch 104/120, Train Loss: 95.0384\n",
      "11285.064376831055\n",
      "Epoch [23/50], Batch 105/120, Train Loss: 100.5566\n",
      "11393.345993041992\n",
      "Epoch [23/50], Batch 106/120, Train Loss: 108.2816\n",
      "11485.394439697266\n",
      "Epoch [23/50], Batch 107/120, Train Loss: 92.0484\n",
      "11569.621467590332\n",
      "Epoch [23/50], Batch 108/120, Train Loss: 84.2270\n",
      "11680.226707458496\n",
      "Epoch [23/50], Batch 109/120, Train Loss: 110.6052\n",
      "11816.189933776855\n",
      "Epoch [23/50], Batch 110/120, Train Loss: 135.9632\n",
      "11925.605171203613\n",
      "Epoch [23/50], Batch 111/120, Train Loss: 109.4152\n",
      "12025.021751403809\n",
      "Epoch [23/50], Batch 112/120, Train Loss: 99.4166\n",
      "12149.609008789062\n",
      "Epoch [23/50], Batch 113/120, Train Loss: 124.5873\n",
      "12269.217880249023\n",
      "Epoch [23/50], Batch 114/120, Train Loss: 119.6089\n",
      "12376.064254760742\n",
      "Epoch [23/50], Batch 115/120, Train Loss: 106.8464\n",
      "12474.108428955078\n",
      "Epoch [23/50], Batch 116/120, Train Loss: 98.0442\n",
      "12568.906051635742\n",
      "Epoch [23/50], Batch 117/120, Train Loss: 94.7976\n",
      "12687.600318908691\n",
      "Epoch [23/50], Batch 118/120, Train Loss: 118.6943\n",
      "12779.159851074219\n",
      "Epoch [23/50], Batch 119/120, Train Loss: 91.5595\n",
      "12859.499229431152\n",
      "Epoch [23/50], Batch 120/120, Train Loss: 80.3394\n",
      "Epoch [23/50], Train Loss: 107.1625, Validation Loss: 117.9265\n",
      "81.88482666015625\n",
      "Epoch [24/50], Batch 1/120, Train Loss: 81.8848\n",
      "187.59323120117188\n",
      "Epoch [24/50], Batch 2/120, Train Loss: 105.7084\n",
      "321.0154113769531\n",
      "Epoch [24/50], Batch 3/120, Train Loss: 133.4222\n",
      "434.54080963134766\n",
      "Epoch [24/50], Batch 4/120, Train Loss: 113.5254\n",
      "543.2168655395508\n",
      "Epoch [24/50], Batch 5/120, Train Loss: 108.6761\n",
      "630.1369247436523\n",
      "Epoch [24/50], Batch 6/120, Train Loss: 86.9201\n",
      "738.7962417602539\n",
      "Epoch [24/50], Batch 7/120, Train Loss: 108.6593\n",
      "830.5630798339844\n",
      "Epoch [24/50], Batch 8/120, Train Loss: 91.7668\n",
      "936.2895050048828\n",
      "Epoch [24/50], Batch 9/120, Train Loss: 105.7264\n",
      "1036.0605850219727\n",
      "Epoch [24/50], Batch 10/120, Train Loss: 99.7711\n",
      "1125.2342224121094\n",
      "Epoch [24/50], Batch 11/120, Train Loss: 89.1736\n",
      "1252.5758819580078\n",
      "Epoch [24/50], Batch 12/120, Train Loss: 127.3417\n",
      "1369.3502655029297\n",
      "Epoch [24/50], Batch 13/120, Train Loss: 116.7744\n",
      "1470.4440002441406\n",
      "Epoch [24/50], Batch 14/120, Train Loss: 101.0937\n",
      "1593.321174621582\n",
      "Epoch [24/50], Batch 15/120, Train Loss: 122.8772\n",
      "1677.0476837158203\n",
      "Epoch [24/50], Batch 16/120, Train Loss: 83.7265\n",
      "1793.7564010620117\n",
      "Epoch [24/50], Batch 17/120, Train Loss: 116.7087\n",
      "1915.9066619873047\n",
      "Epoch [24/50], Batch 18/120, Train Loss: 122.1503\n",
      "2015.2853088378906\n",
      "Epoch [24/50], Batch 19/120, Train Loss: 99.3786\n",
      "2094.8504791259766\n",
      "Epoch [24/50], Batch 20/120, Train Loss: 79.5652\n",
      "2192.8195190429688\n",
      "Epoch [24/50], Batch 21/120, Train Loss: 97.9690\n",
      "2313.6354217529297\n",
      "Epoch [24/50], Batch 22/120, Train Loss: 120.8159\n",
      "2406.7784118652344\n",
      "Epoch [24/50], Batch 23/120, Train Loss: 93.1430\n",
      "2521.7873916625977\n",
      "Epoch [24/50], Batch 24/120, Train Loss: 115.0090\n",
      "2625.45938873291\n",
      "Epoch [24/50], Batch 25/120, Train Loss: 103.6720\n",
      "2740.991844177246\n",
      "Epoch [24/50], Batch 26/120, Train Loss: 115.5325\n",
      "2877.9494552612305\n",
      "Epoch [24/50], Batch 27/120, Train Loss: 136.9576\n",
      "2985.0307235717773\n",
      "Epoch [24/50], Batch 28/120, Train Loss: 107.0813\n",
      "3078.9246978759766\n",
      "Epoch [24/50], Batch 29/120, Train Loss: 93.8940\n",
      "3186.0045623779297\n",
      "Epoch [24/50], Batch 30/120, Train Loss: 107.0799\n",
      "3279.5560760498047\n",
      "Epoch [24/50], Batch 31/120, Train Loss: 93.5515\n",
      "3383.889533996582\n",
      "Epoch [24/50], Batch 32/120, Train Loss: 104.3335\n",
      "3513.546485900879\n",
      "Epoch [24/50], Batch 33/120, Train Loss: 129.6570\n",
      "3621.2504272460938\n",
      "Epoch [24/50], Batch 34/120, Train Loss: 107.7039\n",
      "3711.67879486084\n",
      "Epoch [24/50], Batch 35/120, Train Loss: 90.4284\n",
      "3830.479652404785\n",
      "Epoch [24/50], Batch 36/120, Train Loss: 118.8009\n",
      "3908.474411010742\n",
      "Epoch [24/50], Batch 37/120, Train Loss: 77.9948\n",
      "4023.3100814819336\n",
      "Epoch [24/50], Batch 38/120, Train Loss: 114.8357\n",
      "4143.973762512207\n",
      "Epoch [24/50], Batch 39/120, Train Loss: 120.6637\n",
      "4226.112823486328\n",
      "Epoch [24/50], Batch 40/120, Train Loss: 82.1391\n",
      "4328.655014038086\n",
      "Epoch [24/50], Batch 41/120, Train Loss: 102.5422\n",
      "4454.122619628906\n",
      "Epoch [24/50], Batch 42/120, Train Loss: 125.4676\n",
      "4576.56037902832\n",
      "Epoch [24/50], Batch 43/120, Train Loss: 122.4378\n",
      "4691.201187133789\n",
      "Epoch [24/50], Batch 44/120, Train Loss: 114.6408\n",
      "4795.988830566406\n",
      "Epoch [24/50], Batch 45/120, Train Loss: 104.7876\n",
      "4880.173377990723\n",
      "Epoch [24/50], Batch 46/120, Train Loss: 84.1845\n",
      "4982.4785079956055\n",
      "Epoch [24/50], Batch 47/120, Train Loss: 102.3051\n",
      "5100.719970703125\n",
      "Epoch [24/50], Batch 48/120, Train Loss: 118.2415\n",
      "5215.136459350586\n",
      "Epoch [24/50], Batch 49/120, Train Loss: 114.4165\n",
      "5317.836380004883\n",
      "Epoch [24/50], Batch 50/120, Train Loss: 102.6999\n",
      "5440.672134399414\n",
      "Epoch [24/50], Batch 51/120, Train Loss: 122.8358\n",
      "5552.201950073242\n",
      "Epoch [24/50], Batch 52/120, Train Loss: 111.5298\n",
      "5636.021728515625\n",
      "Epoch [24/50], Batch 53/120, Train Loss: 83.8198\n",
      "5741.877105712891\n",
      "Epoch [24/50], Batch 54/120, Train Loss: 105.8554\n",
      "5849.636291503906\n",
      "Epoch [24/50], Batch 55/120, Train Loss: 107.7592\n",
      "5948.971389770508\n",
      "Epoch [24/50], Batch 56/120, Train Loss: 99.3351\n",
      "6063.025634765625\n",
      "Epoch [24/50], Batch 57/120, Train Loss: 114.0542\n",
      "6164.069961547852\n",
      "Epoch [24/50], Batch 58/120, Train Loss: 101.0443\n",
      "6248.471786499023\n",
      "Epoch [24/50], Batch 59/120, Train Loss: 84.4018\n",
      "6358.246208190918\n",
      "Epoch [24/50], Batch 60/120, Train Loss: 109.7744\n",
      "6471.585258483887\n",
      "Epoch [24/50], Batch 61/120, Train Loss: 113.3391\n",
      "6589.262184143066\n",
      "Epoch [24/50], Batch 62/120, Train Loss: 117.6769\n",
      "6697.068809509277\n",
      "Epoch [24/50], Batch 63/120, Train Loss: 107.8066\n",
      "6811.768592834473\n",
      "Epoch [24/50], Batch 64/120, Train Loss: 114.6998\n",
      "6922.670066833496\n",
      "Epoch [24/50], Batch 65/120, Train Loss: 110.9015\n",
      "7026.704139709473\n",
      "Epoch [24/50], Batch 66/120, Train Loss: 104.0341\n",
      "7129.697326660156\n",
      "Epoch [24/50], Batch 67/120, Train Loss: 102.9932\n",
      "7256.677780151367\n",
      "Epoch [24/50], Batch 68/120, Train Loss: 126.9805\n",
      "7344.124694824219\n",
      "Epoch [24/50], Batch 69/120, Train Loss: 87.4469\n",
      "7431.55094909668\n",
      "Epoch [24/50], Batch 70/120, Train Loss: 87.4263\n",
      "7533.162841796875\n",
      "Epoch [24/50], Batch 71/120, Train Loss: 101.6119\n",
      "7666.3651123046875\n",
      "Epoch [24/50], Batch 72/120, Train Loss: 133.2023\n",
      "7770.679725646973\n",
      "Epoch [24/50], Batch 73/120, Train Loss: 104.3146\n",
      "7868.537330627441\n",
      "Epoch [24/50], Batch 74/120, Train Loss: 97.8576\n",
      "7975.592185974121\n",
      "Epoch [24/50], Batch 75/120, Train Loss: 107.0549\n",
      "8084.25528717041\n",
      "Epoch [24/50], Batch 76/120, Train Loss: 108.6631\n",
      "8196.97819519043\n",
      "Epoch [24/50], Batch 77/120, Train Loss: 112.7229\n",
      "8312.031463623047\n",
      "Epoch [24/50], Batch 78/120, Train Loss: 115.0533\n",
      "8431.563430786133\n",
      "Epoch [24/50], Batch 79/120, Train Loss: 119.5320\n",
      "8531.742538452148\n",
      "Epoch [24/50], Batch 80/120, Train Loss: 100.1791\n",
      "8630.301986694336\n",
      "Epoch [24/50], Batch 81/120, Train Loss: 98.5594\n",
      "8754.928833007812\n",
      "Epoch [24/50], Batch 82/120, Train Loss: 124.6268\n",
      "8846.978889465332\n",
      "Epoch [24/50], Batch 83/120, Train Loss: 92.0501\n",
      "8939.353622436523\n",
      "Epoch [24/50], Batch 84/120, Train Loss: 92.3747\n",
      "9032.8119430542\n",
      "Epoch [24/50], Batch 85/120, Train Loss: 93.4583\n",
      "9142.215881347656\n",
      "Epoch [24/50], Batch 86/120, Train Loss: 109.4039\n",
      "9231.098258972168\n",
      "Epoch [24/50], Batch 87/120, Train Loss: 88.8824\n",
      "9312.6928024292\n",
      "Epoch [24/50], Batch 88/120, Train Loss: 81.5945\n",
      "9415.991569519043\n",
      "Epoch [24/50], Batch 89/120, Train Loss: 103.2988\n",
      "9522.710678100586\n",
      "Epoch [24/50], Batch 90/120, Train Loss: 106.7191\n",
      "9630.868179321289\n",
      "Epoch [24/50], Batch 91/120, Train Loss: 108.1575\n",
      "9717.912773132324\n",
      "Epoch [24/50], Batch 92/120, Train Loss: 87.0446\n",
      "9829.113479614258\n",
      "Epoch [24/50], Batch 93/120, Train Loss: 111.2007\n",
      "9929.03776550293\n",
      "Epoch [24/50], Batch 94/120, Train Loss: 99.9243\n",
      "10021.363998413086\n",
      "Epoch [24/50], Batch 95/120, Train Loss: 92.3262\n",
      "10128.456092834473\n",
      "Epoch [24/50], Batch 96/120, Train Loss: 107.0921\n",
      "10242.372077941895\n",
      "Epoch [24/50], Batch 97/120, Train Loss: 113.9160\n",
      "10362.723571777344\n",
      "Epoch [24/50], Batch 98/120, Train Loss: 120.3515\n",
      "10488.720024108887\n",
      "Epoch [24/50], Batch 99/120, Train Loss: 125.9965\n",
      "10579.375160217285\n",
      "Epoch [24/50], Batch 100/120, Train Loss: 90.6551\n",
      "10699.283660888672\n",
      "Epoch [24/50], Batch 101/120, Train Loss: 119.9085\n",
      "10798.118179321289\n",
      "Epoch [24/50], Batch 102/120, Train Loss: 98.8345\n",
      "10930.366622924805\n",
      "Epoch [24/50], Batch 103/120, Train Loss: 132.2484\n",
      "11041.893272399902\n",
      "Epoch [24/50], Batch 104/120, Train Loss: 111.5266\n",
      "11142.520004272461\n",
      "Epoch [24/50], Batch 105/120, Train Loss: 100.6267\n",
      "11248.875244140625\n",
      "Epoch [24/50], Batch 106/120, Train Loss: 106.3552\n",
      "11364.570709228516\n",
      "Epoch [24/50], Batch 107/120, Train Loss: 115.6955\n",
      "11454.295501708984\n",
      "Epoch [24/50], Batch 108/120, Train Loss: 89.7248\n",
      "11574.153205871582\n",
      "Epoch [24/50], Batch 109/120, Train Loss: 119.8577\n",
      "11678.956443786621\n",
      "Epoch [24/50], Batch 110/120, Train Loss: 104.8032\n",
      "11796.97679901123\n",
      "Epoch [24/50], Batch 111/120, Train Loss: 118.0204\n",
      "11909.540603637695\n",
      "Epoch [24/50], Batch 112/120, Train Loss: 112.5638\n",
      "12032.304656982422\n",
      "Epoch [24/50], Batch 113/120, Train Loss: 122.7641\n",
      "12133.874282836914\n",
      "Epoch [24/50], Batch 114/120, Train Loss: 101.5696\n",
      "12233.916610717773\n",
      "Epoch [24/50], Batch 115/120, Train Loss: 100.0423\n",
      "12338.813957214355\n",
      "Epoch [24/50], Batch 116/120, Train Loss: 104.8973\n",
      "12439.202133178711\n",
      "Epoch [24/50], Batch 117/120, Train Loss: 100.3882\n",
      "12549.1978225708\n",
      "Epoch [24/50], Batch 118/120, Train Loss: 109.9957\n",
      "12655.310981750488\n",
      "Epoch [24/50], Batch 119/120, Train Loss: 106.1132\n",
      "12761.078086853027\n",
      "Epoch [24/50], Batch 120/120, Train Loss: 105.7671\n",
      "Epoch [24/50], Train Loss: 106.3423, Validation Loss: 117.1754\n",
      "131.70150756835938\n",
      "Epoch [25/50], Batch 1/120, Train Loss: 131.7015\n",
      "246.5275115966797\n",
      "Epoch [25/50], Batch 2/120, Train Loss: 114.8260\n",
      "341.19642639160156\n",
      "Epoch [25/50], Batch 3/120, Train Loss: 94.6689\n",
      "456.59857177734375\n",
      "Epoch [25/50], Batch 4/120, Train Loss: 115.4021\n",
      "578.8540191650391\n",
      "Epoch [25/50], Batch 5/120, Train Loss: 122.2554\n",
      "679.7299728393555\n",
      "Epoch [25/50], Batch 6/120, Train Loss: 100.8760\n",
      "785.392448425293\n",
      "Epoch [25/50], Batch 7/120, Train Loss: 105.6625\n",
      "883.1940231323242\n",
      "Epoch [25/50], Batch 8/120, Train Loss: 97.8016\n",
      "985.7889633178711\n",
      "Epoch [25/50], Batch 9/120, Train Loss: 102.5949\n",
      "1095.9121627807617\n",
      "Epoch [25/50], Batch 10/120, Train Loss: 110.1232\n",
      "1202.9023361206055\n",
      "Epoch [25/50], Batch 11/120, Train Loss: 106.9902\n",
      "1323.910659790039\n",
      "Epoch [25/50], Batch 12/120, Train Loss: 121.0083\n",
      "1412.8353729248047\n",
      "Epoch [25/50], Batch 13/120, Train Loss: 88.9247\n",
      "1509.4259338378906\n",
      "Epoch [25/50], Batch 14/120, Train Loss: 96.5906\n",
      "1597.3600540161133\n",
      "Epoch [25/50], Batch 15/120, Train Loss: 87.9341\n",
      "1679.107566833496\n",
      "Epoch [25/50], Batch 16/120, Train Loss: 81.7475\n",
      "1772.9034881591797\n",
      "Epoch [25/50], Batch 17/120, Train Loss: 93.7959\n",
      "1882.8754577636719\n",
      "Epoch [25/50], Batch 18/120, Train Loss: 109.9720\n",
      "1989.7083892822266\n",
      "Epoch [25/50], Batch 19/120, Train Loss: 106.8329\n",
      "2091.5428161621094\n",
      "Epoch [25/50], Batch 20/120, Train Loss: 101.8344\n",
      "2199.5402069091797\n",
      "Epoch [25/50], Batch 21/120, Train Loss: 107.9974\n",
      "2288.549690246582\n",
      "Epoch [25/50], Batch 22/120, Train Loss: 89.0095\n",
      "2400.407814025879\n",
      "Epoch [25/50], Batch 23/120, Train Loss: 111.8581\n",
      "2541.7446060180664\n",
      "Epoch [25/50], Batch 24/120, Train Loss: 141.3368\n",
      "2624.8136825561523\n",
      "Epoch [25/50], Batch 25/120, Train Loss: 83.0691\n",
      "2738.3900833129883\n",
      "Epoch [25/50], Batch 26/120, Train Loss: 113.5764\n",
      "2846.605140686035\n",
      "Epoch [25/50], Batch 27/120, Train Loss: 108.2151\n",
      "2946.333671569824\n",
      "Epoch [25/50], Batch 28/120, Train Loss: 99.7285\n",
      "3051.1414489746094\n",
      "Epoch [25/50], Batch 29/120, Train Loss: 104.8078\n",
      "3159.2064666748047\n",
      "Epoch [25/50], Batch 30/120, Train Loss: 108.0650\n",
      "3261.994094848633\n",
      "Epoch [25/50], Batch 31/120, Train Loss: 102.7876\n",
      "3371.538040161133\n",
      "Epoch [25/50], Batch 32/120, Train Loss: 109.5439\n",
      "3459.0373153686523\n",
      "Epoch [25/50], Batch 33/120, Train Loss: 87.4993\n",
      "3554.535484313965\n",
      "Epoch [25/50], Batch 34/120, Train Loss: 95.4982\n",
      "3639.6740341186523\n",
      "Epoch [25/50], Batch 35/120, Train Loss: 85.1385\n",
      "3749.8730697631836\n",
      "Epoch [25/50], Batch 36/120, Train Loss: 110.1990\n",
      "3838.505416870117\n",
      "Epoch [25/50], Batch 37/120, Train Loss: 88.6323\n",
      "3942.868453979492\n",
      "Epoch [25/50], Batch 38/120, Train Loss: 104.3630\n",
      "4075.548843383789\n",
      "Epoch [25/50], Batch 39/120, Train Loss: 132.6804\n",
      "4178.3786697387695\n",
      "Epoch [25/50], Batch 40/120, Train Loss: 102.8298\n",
      "4273.205192565918\n",
      "Epoch [25/50], Batch 41/120, Train Loss: 94.8265\n",
      "4387.362571716309\n",
      "Epoch [25/50], Batch 42/120, Train Loss: 114.1574\n",
      "4489.326988220215\n",
      "Epoch [25/50], Batch 43/120, Train Loss: 101.9644\n",
      "4582.697158813477\n",
      "Epoch [25/50], Batch 44/120, Train Loss: 93.3702\n",
      "4677.578079223633\n",
      "Epoch [25/50], Batch 45/120, Train Loss: 94.8809\n",
      "4778.438629150391\n",
      "Epoch [25/50], Batch 46/120, Train Loss: 100.8605\n",
      "4883.041854858398\n",
      "Epoch [25/50], Batch 47/120, Train Loss: 104.6032\n",
      "5019.100555419922\n",
      "Epoch [25/50], Batch 48/120, Train Loss: 136.0587\n",
      "5150.492156982422\n",
      "Epoch [25/50], Batch 49/120, Train Loss: 131.3916\n",
      "5247.710784912109\n",
      "Epoch [25/50], Batch 50/120, Train Loss: 97.2186\n",
      "5367.138702392578\n",
      "Epoch [25/50], Batch 51/120, Train Loss: 119.4279\n",
      "5450.961158752441\n",
      "Epoch [25/50], Batch 52/120, Train Loss: 83.8225\n",
      "5541.3928298950195\n",
      "Epoch [25/50], Batch 53/120, Train Loss: 90.4317\n",
      "5675.291801452637\n",
      "Epoch [25/50], Batch 54/120, Train Loss: 133.8990\n",
      "5785.945159912109\n",
      "Epoch [25/50], Batch 55/120, Train Loss: 110.6534\n",
      "5900.243202209473\n",
      "Epoch [25/50], Batch 56/120, Train Loss: 114.2980\n",
      "6007.193305969238\n",
      "Epoch [25/50], Batch 57/120, Train Loss: 106.9501\n",
      "6119.441619873047\n",
      "Epoch [25/50], Batch 58/120, Train Loss: 112.2483\n",
      "6244.696571350098\n",
      "Epoch [25/50], Batch 59/120, Train Loss: 125.2550\n",
      "6341.298149108887\n",
      "Epoch [25/50], Batch 60/120, Train Loss: 96.6016\n",
      "6448.6543045043945\n",
      "Epoch [25/50], Batch 61/120, Train Loss: 107.3562\n",
      "6562.655662536621\n",
      "Epoch [25/50], Batch 62/120, Train Loss: 114.0014\n",
      "6664.109962463379\n",
      "Epoch [25/50], Batch 63/120, Train Loss: 101.4543\n",
      "6747.137550354004\n",
      "Epoch [25/50], Batch 64/120, Train Loss: 83.0276\n",
      "6851.95719909668\n",
      "Epoch [25/50], Batch 65/120, Train Loss: 104.8196\n",
      "6932.497871398926\n",
      "Epoch [25/50], Batch 66/120, Train Loss: 80.5407\n",
      "7085.957618713379\n",
      "Epoch [25/50], Batch 67/120, Train Loss: 153.4597\n",
      "7188.877494812012\n",
      "Epoch [25/50], Batch 68/120, Train Loss: 102.9199\n",
      "7285.541679382324\n",
      "Epoch [25/50], Batch 69/120, Train Loss: 96.6642\n",
      "7385.319374084473\n",
      "Epoch [25/50], Batch 70/120, Train Loss: 99.7777\n",
      "7496.31477355957\n",
      "Epoch [25/50], Batch 71/120, Train Loss: 110.9954\n",
      "7610.838470458984\n",
      "Epoch [25/50], Batch 72/120, Train Loss: 114.5237\n",
      "7712.73583984375\n",
      "Epoch [25/50], Batch 73/120, Train Loss: 101.8974\n",
      "7800.21955871582\n",
      "Epoch [25/50], Batch 74/120, Train Loss: 87.4837\n",
      "7904.580596923828\n",
      "Epoch [25/50], Batch 75/120, Train Loss: 104.3610\n",
      "7997.018829345703\n",
      "Epoch [25/50], Batch 76/120, Train Loss: 92.4382\n",
      "8088.115798950195\n",
      "Epoch [25/50], Batch 77/120, Train Loss: 91.0970\n",
      "8192.886360168457\n",
      "Epoch [25/50], Batch 78/120, Train Loss: 104.7706\n",
      "8283.187194824219\n",
      "Epoch [25/50], Batch 79/120, Train Loss: 90.3008\n",
      "8400.556106567383\n",
      "Epoch [25/50], Batch 80/120, Train Loss: 117.3689\n",
      "8506.785636901855\n",
      "Epoch [25/50], Batch 81/120, Train Loss: 106.2295\n",
      "8598.269775390625\n",
      "Epoch [25/50], Batch 82/120, Train Loss: 91.4841\n",
      "8669.774215698242\n",
      "Epoch [25/50], Batch 83/120, Train Loss: 71.5044\n",
      "8764.905937194824\n",
      "Epoch [25/50], Batch 84/120, Train Loss: 95.1317\n",
      "8868.024063110352\n",
      "Epoch [25/50], Batch 85/120, Train Loss: 103.1181\n",
      "8979.35807800293\n",
      "Epoch [25/50], Batch 86/120, Train Loss: 111.3340\n",
      "9080.845481872559\n",
      "Epoch [25/50], Batch 87/120, Train Loss: 101.4874\n",
      "9193.12133026123\n",
      "Epoch [25/50], Batch 88/120, Train Loss: 112.2758\n",
      "9284.985679626465\n",
      "Epoch [25/50], Batch 89/120, Train Loss: 91.8643\n",
      "9376.92162322998\n",
      "Epoch [25/50], Batch 90/120, Train Loss: 91.9359\n",
      "9488.660804748535\n",
      "Epoch [25/50], Batch 91/120, Train Loss: 111.7392\n",
      "9574.2230758667\n",
      "Epoch [25/50], Batch 92/120, Train Loss: 85.5623\n",
      "9707.03263092041\n",
      "Epoch [25/50], Batch 93/120, Train Loss: 132.8096\n",
      "9811.106643676758\n",
      "Epoch [25/50], Batch 94/120, Train Loss: 104.0740\n",
      "9916.087867736816\n",
      "Epoch [25/50], Batch 95/120, Train Loss: 104.9812\n",
      "10019.980827331543\n",
      "Epoch [25/50], Batch 96/120, Train Loss: 103.8930\n",
      "10110.013771057129\n",
      "Epoch [25/50], Batch 97/120, Train Loss: 90.0329\n",
      "10216.633880615234\n",
      "Epoch [25/50], Batch 98/120, Train Loss: 106.6201\n",
      "10313.569396972656\n",
      "Epoch [25/50], Batch 99/120, Train Loss: 96.9355\n",
      "10421.546081542969\n",
      "Epoch [25/50], Batch 100/120, Train Loss: 107.9767\n",
      "10551.743606567383\n",
      "Epoch [25/50], Batch 101/120, Train Loss: 130.1975\n",
      "10646.100570678711\n",
      "Epoch [25/50], Batch 102/120, Train Loss: 94.3570\n",
      "10745.772491455078\n",
      "Epoch [25/50], Batch 103/120, Train Loss: 99.6719\n",
      "10877.214141845703\n",
      "Epoch [25/50], Batch 104/120, Train Loss: 131.4417\n",
      "11011.651489257812\n",
      "Epoch [25/50], Batch 105/120, Train Loss: 134.4373\n",
      "11111.415344238281\n",
      "Epoch [25/50], Batch 106/120, Train Loss: 99.7639\n",
      "11217.382354736328\n",
      "Epoch [25/50], Batch 107/120, Train Loss: 105.9670\n",
      "11318.641387939453\n",
      "Epoch [25/50], Batch 108/120, Train Loss: 101.2590\n",
      "11398.263641357422\n",
      "Epoch [25/50], Batch 109/120, Train Loss: 79.6223\n",
      "11505.865867614746\n",
      "Epoch [25/50], Batch 110/120, Train Loss: 107.6022\n",
      "11612.926124572754\n",
      "Epoch [25/50], Batch 111/120, Train Loss: 107.0603\n",
      "11724.596572875977\n",
      "Epoch [25/50], Batch 112/120, Train Loss: 111.6704\n",
      "11860.542739868164\n",
      "Epoch [25/50], Batch 113/120, Train Loss: 135.9462\n",
      "11966.486358642578\n",
      "Epoch [25/50], Batch 114/120, Train Loss: 105.9436\n",
      "12065.262969970703\n",
      "Epoch [25/50], Batch 115/120, Train Loss: 98.7766\n",
      "12182.682678222656\n",
      "Epoch [25/50], Batch 116/120, Train Loss: 117.4197\n",
      "12286.709915161133\n",
      "Epoch [25/50], Batch 117/120, Train Loss: 104.0272\n",
      "12376.476104736328\n",
      "Epoch [25/50], Batch 118/120, Train Loss: 89.7662\n",
      "12486.733840942383\n",
      "Epoch [25/50], Batch 119/120, Train Loss: 110.2577\n",
      "12603.129959106445\n",
      "Epoch [25/50], Batch 120/120, Train Loss: 116.3961\n",
      "Epoch [25/50], Train Loss: 105.0261, Validation Loss: 117.6132\n",
      "84.0345458984375\n",
      "Epoch [26/50], Batch 1/120, Train Loss: 84.0345\n",
      "196.0436553955078\n",
      "Epoch [26/50], Batch 2/120, Train Loss: 112.0091\n",
      "285.7200622558594\n",
      "Epoch [26/50], Batch 3/120, Train Loss: 89.6764\n",
      "401.86932373046875\n",
      "Epoch [26/50], Batch 4/120, Train Loss: 116.1493\n",
      "534.5347747802734\n",
      "Epoch [26/50], Batch 5/120, Train Loss: 132.6655\n",
      "648.9611434936523\n",
      "Epoch [26/50], Batch 6/120, Train Loss: 114.4264\n",
      "780.8457717895508\n",
      "Epoch [26/50], Batch 7/120, Train Loss: 131.8846\n",
      "877.1121826171875\n",
      "Epoch [26/50], Batch 8/120, Train Loss: 96.2664\n",
      "986.4950790405273\n",
      "Epoch [26/50], Batch 9/120, Train Loss: 109.3829\n",
      "1083.373664855957\n",
      "Epoch [26/50], Batch 10/120, Train Loss: 96.8786\n",
      "1211.689796447754\n",
      "Epoch [26/50], Batch 11/120, Train Loss: 128.3161\n",
      "1325.7734451293945\n",
      "Epoch [26/50], Batch 12/120, Train Loss: 114.0836\n",
      "1453.5632553100586\n",
      "Epoch [26/50], Batch 13/120, Train Loss: 127.7898\n",
      "1548.6198196411133\n",
      "Epoch [26/50], Batch 14/120, Train Loss: 95.0566\n",
      "1663.036117553711\n",
      "Epoch [26/50], Batch 15/120, Train Loss: 114.4163\n",
      "1760.2266464233398\n",
      "Epoch [26/50], Batch 16/120, Train Loss: 97.1905\n",
      "1879.400489807129\n",
      "Epoch [26/50], Batch 17/120, Train Loss: 119.1738\n",
      "1971.0503158569336\n",
      "Epoch [26/50], Batch 18/120, Train Loss: 91.6498\n",
      "2094.6073303222656\n",
      "Epoch [26/50], Batch 19/120, Train Loss: 123.5570\n",
      "2188.1024475097656\n",
      "Epoch [26/50], Batch 20/120, Train Loss: 93.4951\n",
      "2263.8141555786133\n",
      "Epoch [26/50], Batch 21/120, Train Loss: 75.7117\n",
      "2367.7665634155273\n",
      "Epoch [26/50], Batch 22/120, Train Loss: 103.9524\n",
      "2477.1754989624023\n",
      "Epoch [26/50], Batch 23/120, Train Loss: 109.4089\n",
      "2572.1465072631836\n",
      "Epoch [26/50], Batch 24/120, Train Loss: 94.9710\n",
      "2682.5209045410156\n",
      "Epoch [26/50], Batch 25/120, Train Loss: 110.3744\n",
      "2803.8587188720703\n",
      "Epoch [26/50], Batch 26/120, Train Loss: 121.3378\n",
      "2907.652053833008\n",
      "Epoch [26/50], Batch 27/120, Train Loss: 103.7933\n",
      "3003.6796493530273\n",
      "Epoch [26/50], Batch 28/120, Train Loss: 96.0276\n",
      "3120.5111236572266\n",
      "Epoch [26/50], Batch 29/120, Train Loss: 116.8315\n",
      "3220.495918273926\n",
      "Epoch [26/50], Batch 30/120, Train Loss: 99.9848\n",
      "3305.488296508789\n",
      "Epoch [26/50], Batch 31/120, Train Loss: 84.9924\n",
      "3407.52091217041\n",
      "Epoch [26/50], Batch 32/120, Train Loss: 102.0326\n",
      "3558.7973251342773\n",
      "Epoch [26/50], Batch 33/120, Train Loss: 151.2764\n",
      "3662.1101608276367\n",
      "Epoch [26/50], Batch 34/120, Train Loss: 103.3128\n",
      "3799.124137878418\n",
      "Epoch [26/50], Batch 35/120, Train Loss: 137.0140\n",
      "3900.906669616699\n",
      "Epoch [26/50], Batch 36/120, Train Loss: 101.7825\n",
      "4013.6275787353516\n",
      "Epoch [26/50], Batch 37/120, Train Loss: 112.7209\n",
      "4113.510528564453\n",
      "Epoch [26/50], Batch 38/120, Train Loss: 99.8829\n",
      "4214.5089111328125\n",
      "Epoch [26/50], Batch 39/120, Train Loss: 100.9984\n",
      "4301.133163452148\n",
      "Epoch [26/50], Batch 40/120, Train Loss: 86.6243\n",
      "4386.179641723633\n",
      "Epoch [26/50], Batch 41/120, Train Loss: 85.0465\n",
      "4474.14493560791\n",
      "Epoch [26/50], Batch 42/120, Train Loss: 87.9653\n",
      "4576.302093505859\n",
      "Epoch [26/50], Batch 43/120, Train Loss: 102.1572\n",
      "4701.130554199219\n",
      "Epoch [26/50], Batch 44/120, Train Loss: 124.8285\n",
      "4798.978805541992\n",
      "Epoch [26/50], Batch 45/120, Train Loss: 97.8483\n",
      "4897.859474182129\n",
      "Epoch [26/50], Batch 46/120, Train Loss: 98.8807\n",
      "5003.777244567871\n",
      "Epoch [26/50], Batch 47/120, Train Loss: 105.9178\n",
      "5113.373558044434\n",
      "Epoch [26/50], Batch 48/120, Train Loss: 109.5963\n",
      "5214.623718261719\n",
      "Epoch [26/50], Batch 49/120, Train Loss: 101.2502\n",
      "5324.408882141113\n",
      "Epoch [26/50], Batch 50/120, Train Loss: 109.7852\n",
      "5437.439888000488\n",
      "Epoch [26/50], Batch 51/120, Train Loss: 113.0310\n",
      "5536.991859436035\n",
      "Epoch [26/50], Batch 52/120, Train Loss: 99.5520\n",
      "5654.506446838379\n",
      "Epoch [26/50], Batch 53/120, Train Loss: 117.5146\n",
      "5741.155723571777\n",
      "Epoch [26/50], Batch 54/120, Train Loss: 86.6493\n",
      "5847.647415161133\n",
      "Epoch [26/50], Batch 55/120, Train Loss: 106.4917\n",
      "5964.998580932617\n",
      "Epoch [26/50], Batch 56/120, Train Loss: 117.3512\n",
      "6100.501968383789\n",
      "Epoch [26/50], Batch 57/120, Train Loss: 135.5034\n",
      "6194.926582336426\n",
      "Epoch [26/50], Batch 58/120, Train Loss: 94.4246\n",
      "6303.980812072754\n",
      "Epoch [26/50], Batch 59/120, Train Loss: 109.0542\n",
      "6429.57315826416\n",
      "Epoch [26/50], Batch 60/120, Train Loss: 125.5923\n",
      "6532.339653015137\n",
      "Epoch [26/50], Batch 61/120, Train Loss: 102.7665\n",
      "6639.215950012207\n",
      "Epoch [26/50], Batch 62/120, Train Loss: 106.8763\n",
      "6741.564926147461\n",
      "Epoch [26/50], Batch 63/120, Train Loss: 102.3490\n",
      "6839.714508056641\n",
      "Epoch [26/50], Batch 64/120, Train Loss: 98.1496\n",
      "6956.751174926758\n",
      "Epoch [26/50], Batch 65/120, Train Loss: 117.0367\n",
      "7046.124366760254\n",
      "Epoch [26/50], Batch 66/120, Train Loss: 89.3732\n",
      "7150.753532409668\n",
      "Epoch [26/50], Batch 67/120, Train Loss: 104.6292\n",
      "7263.612319946289\n",
      "Epoch [26/50], Batch 68/120, Train Loss: 112.8588\n",
      "7358.9393310546875\n",
      "Epoch [26/50], Batch 69/120, Train Loss: 95.3270\n",
      "7460.634567260742\n",
      "Epoch [26/50], Batch 70/120, Train Loss: 101.6952\n",
      "7567.305252075195\n",
      "Epoch [26/50], Batch 71/120, Train Loss: 106.6707\n",
      "7697.744522094727\n",
      "Epoch [26/50], Batch 72/120, Train Loss: 130.4393\n",
      "7820.054000854492\n",
      "Epoch [26/50], Batch 73/120, Train Loss: 122.3095\n",
      "7926.588806152344\n",
      "Epoch [26/50], Batch 74/120, Train Loss: 106.5348\n",
      "8036.735137939453\n",
      "Epoch [26/50], Batch 75/120, Train Loss: 110.1463\n",
      "8143.701042175293\n",
      "Epoch [26/50], Batch 76/120, Train Loss: 106.9659\n",
      "8254.696937561035\n",
      "Epoch [26/50], Batch 77/120, Train Loss: 110.9959\n",
      "8359.618545532227\n",
      "Epoch [26/50], Batch 78/120, Train Loss: 104.9216\n",
      "8476.019859313965\n",
      "Epoch [26/50], Batch 79/120, Train Loss: 116.4013\n",
      "8565.270851135254\n",
      "Epoch [26/50], Batch 80/120, Train Loss: 89.2510\n",
      "8666.128204345703\n",
      "Epoch [26/50], Batch 81/120, Train Loss: 100.8574\n",
      "8766.43547821045\n",
      "Epoch [26/50], Batch 82/120, Train Loss: 100.3073\n",
      "8853.458297729492\n",
      "Epoch [26/50], Batch 83/120, Train Loss: 87.0228\n",
      "8952.541702270508\n",
      "Epoch [26/50], Batch 84/120, Train Loss: 99.0834\n",
      "9042.969863891602\n",
      "Epoch [26/50], Batch 85/120, Train Loss: 90.4282\n",
      "9123.129196166992\n",
      "Epoch [26/50], Batch 86/120, Train Loss: 80.1593\n",
      "9210.76091003418\n",
      "Epoch [26/50], Batch 87/120, Train Loss: 87.6317\n",
      "9295.130653381348\n",
      "Epoch [26/50], Batch 88/120, Train Loss: 84.3697\n",
      "9416.03913116455\n",
      "Epoch [26/50], Batch 89/120, Train Loss: 120.9085\n",
      "9527.055847167969\n",
      "Epoch [26/50], Batch 90/120, Train Loss: 111.0167\n",
      "9619.16975402832\n",
      "Epoch [26/50], Batch 91/120, Train Loss: 92.1139\n",
      "9694.53744506836\n",
      "Epoch [26/50], Batch 92/120, Train Loss: 75.3677\n",
      "9774.184913635254\n",
      "Epoch [26/50], Batch 93/120, Train Loss: 79.6475\n",
      "9876.542808532715\n",
      "Epoch [26/50], Batch 94/120, Train Loss: 102.3579\n",
      "9961.209098815918\n",
      "Epoch [26/50], Batch 95/120, Train Loss: 84.6663\n",
      "10060.355026245117\n",
      "Epoch [26/50], Batch 96/120, Train Loss: 99.1459\n",
      "10159.014587402344\n",
      "Epoch [26/50], Batch 97/120, Train Loss: 98.6596\n",
      "10256.947311401367\n",
      "Epoch [26/50], Batch 98/120, Train Loss: 97.9327\n",
      "10345.687103271484\n",
      "Epoch [26/50], Batch 99/120, Train Loss: 88.7398\n",
      "10420.773422241211\n",
      "Epoch [26/50], Batch 100/120, Train Loss: 75.0863\n",
      "10539.822326660156\n",
      "Epoch [26/50], Batch 101/120, Train Loss: 119.0489\n",
      "10634.03532409668\n",
      "Epoch [26/50], Batch 102/120, Train Loss: 94.2130\n",
      "10732.91985321045\n",
      "Epoch [26/50], Batch 103/120, Train Loss: 98.8845\n",
      "10840.958435058594\n",
      "Epoch [26/50], Batch 104/120, Train Loss: 108.0386\n",
      "10956.74006652832\n",
      "Epoch [26/50], Batch 105/120, Train Loss: 115.7816\n",
      "11041.904388427734\n",
      "Epoch [26/50], Batch 106/120, Train Loss: 85.1643\n",
      "11149.673828125\n",
      "Epoch [26/50], Batch 107/120, Train Loss: 107.7694\n",
      "11262.68595123291\n",
      "Epoch [26/50], Batch 108/120, Train Loss: 113.0121\n",
      "11367.716384887695\n",
      "Epoch [26/50], Batch 109/120, Train Loss: 105.0304\n",
      "11463.531997680664\n",
      "Epoch [26/50], Batch 110/120, Train Loss: 95.8156\n",
      "11567.100601196289\n",
      "Epoch [26/50], Batch 111/120, Train Loss: 103.5686\n",
      "11684.510711669922\n",
      "Epoch [26/50], Batch 112/120, Train Loss: 117.4101\n",
      "11779.499137878418\n",
      "Epoch [26/50], Batch 113/120, Train Loss: 94.9884\n",
      "11885.85831451416\n",
      "Epoch [26/50], Batch 114/120, Train Loss: 106.3592\n",
      "11971.397811889648\n",
      "Epoch [26/50], Batch 115/120, Train Loss: 85.5395\n",
      "12071.274757385254\n",
      "Epoch [26/50], Batch 116/120, Train Loss: 99.8769\n",
      "12192.893669128418\n",
      "Epoch [26/50], Batch 117/120, Train Loss: 121.6189\n",
      "12301.34774017334\n",
      "Epoch [26/50], Batch 118/120, Train Loss: 108.4541\n",
      "12421.543991088867\n",
      "Epoch [26/50], Batch 119/120, Train Loss: 120.1963\n",
      "12540.405349731445\n",
      "Epoch [26/50], Batch 120/120, Train Loss: 118.8614\n",
      "Epoch [26/50], Train Loss: 104.5034, Validation Loss: 114.4707\n",
      "97.18814849853516\n",
      "Epoch [27/50], Batch 1/120, Train Loss: 97.1881\n",
      "201.85198211669922\n",
      "Epoch [27/50], Batch 2/120, Train Loss: 104.6638\n",
      "315.2711944580078\n",
      "Epoch [27/50], Batch 3/120, Train Loss: 113.4192\n",
      "426.7200469970703\n",
      "Epoch [27/50], Batch 4/120, Train Loss: 111.4489\n",
      "527.3555145263672\n",
      "Epoch [27/50], Batch 5/120, Train Loss: 100.6355\n",
      "622.0162200927734\n",
      "Epoch [27/50], Batch 6/120, Train Loss: 94.6607\n",
      "697.2533493041992\n",
      "Epoch [27/50], Batch 7/120, Train Loss: 75.2371\n",
      "800.046142578125\n",
      "Epoch [27/50], Batch 8/120, Train Loss: 102.7928\n",
      "901.5864562988281\n",
      "Epoch [27/50], Batch 9/120, Train Loss: 101.5403\n",
      "993.1058197021484\n",
      "Epoch [27/50], Batch 10/120, Train Loss: 91.5194\n",
      "1093.9293365478516\n",
      "Epoch [27/50], Batch 11/120, Train Loss: 100.8235\n",
      "1192.9223556518555\n",
      "Epoch [27/50], Batch 12/120, Train Loss: 98.9930\n",
      "1281.4288024902344\n",
      "Epoch [27/50], Batch 13/120, Train Loss: 88.5064\n",
      "1388.4497756958008\n",
      "Epoch [27/50], Batch 14/120, Train Loss: 107.0210\n",
      "1484.4889755249023\n",
      "Epoch [27/50], Batch 15/120, Train Loss: 96.0392\n",
      "1602.4481506347656\n",
      "Epoch [27/50], Batch 16/120, Train Loss: 117.9592\n",
      "1703.008285522461\n",
      "Epoch [27/50], Batch 17/120, Train Loss: 100.5601\n",
      "1808.2801818847656\n",
      "Epoch [27/50], Batch 18/120, Train Loss: 105.2719\n",
      "1884.7563018798828\n",
      "Epoch [27/50], Batch 19/120, Train Loss: 76.4761\n",
      "1985.257568359375\n",
      "Epoch [27/50], Batch 20/120, Train Loss: 100.5013\n",
      "2111.2870178222656\n",
      "Epoch [27/50], Batch 21/120, Train Loss: 126.0294\n",
      "2209.3658752441406\n",
      "Epoch [27/50], Batch 22/120, Train Loss: 98.0789\n",
      "2314.9003143310547\n",
      "Epoch [27/50], Batch 23/120, Train Loss: 105.5344\n",
      "2418.968307495117\n",
      "Epoch [27/50], Batch 24/120, Train Loss: 104.0680\n",
      "2556.818649291992\n",
      "Epoch [27/50], Batch 25/120, Train Loss: 137.8503\n",
      "2683.3449630737305\n",
      "Epoch [27/50], Batch 26/120, Train Loss: 126.5263\n",
      "2795.534049987793\n",
      "Epoch [27/50], Batch 27/120, Train Loss: 112.1891\n",
      "2893.4326553344727\n",
      "Epoch [27/50], Batch 28/120, Train Loss: 97.8986\n",
      "2992.0254974365234\n",
      "Epoch [27/50], Batch 29/120, Train Loss: 98.5928\n",
      "3099.5720596313477\n",
      "Epoch [27/50], Batch 30/120, Train Loss: 107.5466\n",
      "3233.76895904541\n",
      "Epoch [27/50], Batch 31/120, Train Loss: 134.1969\n",
      "3357.6750411987305\n",
      "Epoch [27/50], Batch 32/120, Train Loss: 123.9061\n",
      "3467.329818725586\n",
      "Epoch [27/50], Batch 33/120, Train Loss: 109.6548\n",
      "3567.642135620117\n",
      "Epoch [27/50], Batch 34/120, Train Loss: 100.3123\n",
      "3668.574592590332\n",
      "Epoch [27/50], Batch 35/120, Train Loss: 100.9325\n",
      "3774.5738220214844\n",
      "Epoch [27/50], Batch 36/120, Train Loss: 105.9992\n",
      "3874.567451477051\n",
      "Epoch [27/50], Batch 37/120, Train Loss: 99.9936\n",
      "3982.7485733032227\n",
      "Epoch [27/50], Batch 38/120, Train Loss: 108.1811\n",
      "4081.6923065185547\n",
      "Epoch [27/50], Batch 39/120, Train Loss: 98.9437\n",
      "4196.233642578125\n",
      "Epoch [27/50], Batch 40/120, Train Loss: 114.5413\n",
      "4309.158897399902\n",
      "Epoch [27/50], Batch 41/120, Train Loss: 112.9253\n",
      "4403.734146118164\n",
      "Epoch [27/50], Batch 42/120, Train Loss: 94.5752\n",
      "4516.982307434082\n",
      "Epoch [27/50], Batch 43/120, Train Loss: 113.2482\n",
      "4629.60977935791\n",
      "Epoch [27/50], Batch 44/120, Train Loss: 112.6275\n",
      "4709.5565185546875\n",
      "Epoch [27/50], Batch 45/120, Train Loss: 79.9467\n",
      "4841.625381469727\n",
      "Epoch [27/50], Batch 46/120, Train Loss: 132.0689\n",
      "4930.0791015625\n",
      "Epoch [27/50], Batch 47/120, Train Loss: 88.4537\n",
      "5057.748161315918\n",
      "Epoch [27/50], Batch 48/120, Train Loss: 127.6691\n",
      "5187.298759460449\n",
      "Epoch [27/50], Batch 49/120, Train Loss: 129.5506\n",
      "5281.9690017700195\n",
      "Epoch [27/50], Batch 50/120, Train Loss: 94.6702\n",
      "5393.256774902344\n",
      "Epoch [27/50], Batch 51/120, Train Loss: 111.2878\n",
      "5487.246383666992\n",
      "Epoch [27/50], Batch 52/120, Train Loss: 93.9896\n",
      "5589.521263122559\n",
      "Epoch [27/50], Batch 53/120, Train Loss: 102.2749\n",
      "5696.6079177856445\n",
      "Epoch [27/50], Batch 54/120, Train Loss: 107.0867\n",
      "5803.045875549316\n",
      "Epoch [27/50], Batch 55/120, Train Loss: 106.4380\n",
      "5894.997146606445\n",
      "Epoch [27/50], Batch 56/120, Train Loss: 91.9513\n",
      "6006.93376159668\n",
      "Epoch [27/50], Batch 57/120, Train Loss: 111.9366\n",
      "6110.945205688477\n",
      "Epoch [27/50], Batch 58/120, Train Loss: 104.0114\n",
      "6215.41609954834\n",
      "Epoch [27/50], Batch 59/120, Train Loss: 104.4709\n",
      "6327.029853820801\n",
      "Epoch [27/50], Batch 60/120, Train Loss: 111.6138\n",
      "6450.758766174316\n",
      "Epoch [27/50], Batch 61/120, Train Loss: 123.7289\n",
      "6541.730079650879\n",
      "Epoch [27/50], Batch 62/120, Train Loss: 90.9713\n",
      "6632.89444732666\n",
      "Epoch [27/50], Batch 63/120, Train Loss: 91.1644\n",
      "6758.738304138184\n",
      "Epoch [27/50], Batch 64/120, Train Loss: 125.8439\n",
      "6849.451316833496\n",
      "Epoch [27/50], Batch 65/120, Train Loss: 90.7130\n",
      "6950.883689880371\n",
      "Epoch [27/50], Batch 66/120, Train Loss: 101.4324\n",
      "7067.341743469238\n",
      "Epoch [27/50], Batch 67/120, Train Loss: 116.4581\n",
      "7165.99715423584\n",
      "Epoch [27/50], Batch 68/120, Train Loss: 98.6554\n",
      "7249.9597244262695\n",
      "Epoch [27/50], Batch 69/120, Train Loss: 83.9626\n",
      "7342.898384094238\n",
      "Epoch [27/50], Batch 70/120, Train Loss: 92.9387\n",
      "7442.558929443359\n",
      "Epoch [27/50], Batch 71/120, Train Loss: 99.6605\n",
      "7535.239318847656\n",
      "Epoch [27/50], Batch 72/120, Train Loss: 92.6804\n",
      "7634.604080200195\n",
      "Epoch [27/50], Batch 73/120, Train Loss: 99.3648\n",
      "7740.975540161133\n",
      "Epoch [27/50], Batch 74/120, Train Loss: 106.3715\n",
      "7846.302505493164\n",
      "Epoch [27/50], Batch 75/120, Train Loss: 105.3270\n",
      "7946.383239746094\n",
      "Epoch [27/50], Batch 76/120, Train Loss: 100.0807\n",
      "8053.090744018555\n",
      "Epoch [27/50], Batch 77/120, Train Loss: 106.7075\n",
      "8154.441879272461\n",
      "Epoch [27/50], Batch 78/120, Train Loss: 101.3511\n",
      "8245.266906738281\n",
      "Epoch [27/50], Batch 79/120, Train Loss: 90.8250\n",
      "8335.884880065918\n",
      "Epoch [27/50], Batch 80/120, Train Loss: 90.6180\n",
      "8435.12767791748\n",
      "Epoch [27/50], Batch 81/120, Train Loss: 99.2428\n",
      "8538.258544921875\n",
      "Epoch [27/50], Batch 82/120, Train Loss: 103.1309\n",
      "8636.103042602539\n",
      "Epoch [27/50], Batch 83/120, Train Loss: 97.8445\n",
      "8726.217834472656\n",
      "Epoch [27/50], Batch 84/120, Train Loss: 90.1148\n",
      "8827.364418029785\n",
      "Epoch [27/50], Batch 85/120, Train Loss: 101.1466\n",
      "8946.674903869629\n",
      "Epoch [27/50], Batch 86/120, Train Loss: 119.3105\n",
      "9056.137672424316\n",
      "Epoch [27/50], Batch 87/120, Train Loss: 109.4628\n",
      "9164.073150634766\n",
      "Epoch [27/50], Batch 88/120, Train Loss: 107.9355\n",
      "9274.092758178711\n",
      "Epoch [27/50], Batch 89/120, Train Loss: 110.0196\n",
      "9360.271347045898\n",
      "Epoch [27/50], Batch 90/120, Train Loss: 86.1786\n",
      "9472.075004577637\n",
      "Epoch [27/50], Batch 91/120, Train Loss: 111.8037\n",
      "9565.910835266113\n",
      "Epoch [27/50], Batch 92/120, Train Loss: 93.8358\n",
      "9666.86083984375\n",
      "Epoch [27/50], Batch 93/120, Train Loss: 100.9500\n",
      "9757.995239257812\n",
      "Epoch [27/50], Batch 94/120, Train Loss: 91.1344\n",
      "9854.842422485352\n",
      "Epoch [27/50], Batch 95/120, Train Loss: 96.8472\n",
      "9943.188858032227\n",
      "Epoch [27/50], Batch 96/120, Train Loss: 88.3464\n",
      "10026.322563171387\n",
      "Epoch [27/50], Batch 97/120, Train Loss: 83.1337\n",
      "10106.830200195312\n",
      "Epoch [27/50], Batch 98/120, Train Loss: 80.5076\n",
      "10219.708229064941\n",
      "Epoch [27/50], Batch 99/120, Train Loss: 112.8780\n",
      "10325.538475036621\n",
      "Epoch [27/50], Batch 100/120, Train Loss: 105.8302\n",
      "10415.201637268066\n",
      "Epoch [27/50], Batch 101/120, Train Loss: 89.6632\n",
      "10522.66431427002\n",
      "Epoch [27/50], Batch 102/120, Train Loss: 107.4627\n",
      "10619.792129516602\n",
      "Epoch [27/50], Batch 103/120, Train Loss: 97.1278\n",
      "10726.119522094727\n",
      "Epoch [27/50], Batch 104/120, Train Loss: 106.3274\n",
      "10818.891067504883\n",
      "Epoch [27/50], Batch 105/120, Train Loss: 92.7715\n",
      "10927.456077575684\n",
      "Epoch [27/50], Batch 106/120, Train Loss: 108.5650\n",
      "11042.39868927002\n",
      "Epoch [27/50], Batch 107/120, Train Loss: 114.9426\n",
      "11142.2612991333\n",
      "Epoch [27/50], Batch 108/120, Train Loss: 99.8626\n",
      "11232.838584899902\n",
      "Epoch [27/50], Batch 109/120, Train Loss: 90.5773\n",
      "11310.564819335938\n",
      "Epoch [27/50], Batch 110/120, Train Loss: 77.7262\n",
      "11391.531845092773\n",
      "Epoch [27/50], Batch 111/120, Train Loss: 80.9670\n",
      "11507.659042358398\n",
      "Epoch [27/50], Batch 112/120, Train Loss: 116.1272\n",
      "11629.240364074707\n",
      "Epoch [27/50], Batch 113/120, Train Loss: 121.5813\n",
      "11743.693634033203\n",
      "Epoch [27/50], Batch 114/120, Train Loss: 114.4533\n",
      "11846.548789978027\n",
      "Epoch [27/50], Batch 115/120, Train Loss: 102.8552\n",
      "11982.921104431152\n",
      "Epoch [27/50], Batch 116/120, Train Loss: 136.3723\n",
      "12081.93978881836\n",
      "Epoch [27/50], Batch 117/120, Train Loss: 99.0187\n",
      "12179.585159301758\n",
      "Epoch [27/50], Batch 118/120, Train Loss: 97.6454\n",
      "12298.095680236816\n",
      "Epoch [27/50], Batch 119/120, Train Loss: 118.5105\n",
      "12400.17204284668\n",
      "Epoch [27/50], Batch 120/120, Train Loss: 102.0764\n",
      "Epoch [27/50], Train Loss: 103.3348, Validation Loss: 115.3418\n",
      "111.09591674804688\n",
      "Epoch [28/50], Batch 1/120, Train Loss: 111.0959\n",
      "233.66893768310547\n",
      "Epoch [28/50], Batch 2/120, Train Loss: 122.5730\n",
      "340.7703628540039\n",
      "Epoch [28/50], Batch 3/120, Train Loss: 107.1014\n",
      "435.3760681152344\n",
      "Epoch [28/50], Batch 4/120, Train Loss: 94.6057\n",
      "535.8184509277344\n",
      "Epoch [28/50], Batch 5/120, Train Loss: 100.4424\n",
      "653.3446655273438\n",
      "Epoch [28/50], Batch 6/120, Train Loss: 117.5262\n",
      "749.1619644165039\n",
      "Epoch [28/50], Batch 7/120, Train Loss: 95.8173\n",
      "863.2543563842773\n",
      "Epoch [28/50], Batch 8/120, Train Loss: 114.0924\n",
      "963.5539321899414\n",
      "Epoch [28/50], Batch 9/120, Train Loss: 100.2996\n",
      "1049.3838729858398\n",
      "Epoch [28/50], Batch 10/120, Train Loss: 85.8299\n",
      "1156.7595901489258\n",
      "Epoch [28/50], Batch 11/120, Train Loss: 107.3757\n",
      "1248.5813827514648\n",
      "Epoch [28/50], Batch 12/120, Train Loss: 91.8218\n",
      "1354.5491104125977\n",
      "Epoch [28/50], Batch 13/120, Train Loss: 105.9677\n",
      "1463.2672500610352\n",
      "Epoch [28/50], Batch 14/120, Train Loss: 108.7181\n",
      "1570.7151565551758\n",
      "Epoch [28/50], Batch 15/120, Train Loss: 107.4479\n",
      "1679.3498916625977\n",
      "Epoch [28/50], Batch 16/120, Train Loss: 108.6347\n",
      "1808.811912536621\n",
      "Epoch [28/50], Batch 17/120, Train Loss: 129.4620\n",
      "1910.1262664794922\n",
      "Epoch [28/50], Batch 18/120, Train Loss: 101.3144\n",
      "2012.7440185546875\n",
      "Epoch [28/50], Batch 19/120, Train Loss: 102.6178\n",
      "2094.3115463256836\n",
      "Epoch [28/50], Batch 20/120, Train Loss: 81.5675\n",
      "2187.1481323242188\n",
      "Epoch [28/50], Batch 21/120, Train Loss: 92.8366\n",
      "2287.644577026367\n",
      "Epoch [28/50], Batch 22/120, Train Loss: 100.4964\n",
      "2384.4082565307617\n",
      "Epoch [28/50], Batch 23/120, Train Loss: 96.7637\n",
      "2481.7176208496094\n",
      "Epoch [28/50], Batch 24/120, Train Loss: 97.3094\n",
      "2570.4168395996094\n",
      "Epoch [28/50], Batch 25/120, Train Loss: 88.6992\n",
      "2719.7392578125\n",
      "Epoch [28/50], Batch 26/120, Train Loss: 149.3224\n",
      "2844.2780685424805\n",
      "Epoch [28/50], Batch 27/120, Train Loss: 124.5388\n",
      "2944.7104873657227\n",
      "Epoch [28/50], Batch 28/120, Train Loss: 100.4324\n",
      "3030.5383529663086\n",
      "Epoch [28/50], Batch 29/120, Train Loss: 85.8279\n",
      "3140.6005477905273\n",
      "Epoch [28/50], Batch 30/120, Train Loss: 110.0622\n",
      "3243.76863861084\n",
      "Epoch [28/50], Batch 31/120, Train Loss: 103.1681\n",
      "3334.387870788574\n",
      "Epoch [28/50], Batch 32/120, Train Loss: 90.6192\n",
      "3438.9767837524414\n",
      "Epoch [28/50], Batch 33/120, Train Loss: 104.5889\n",
      "3532.3079833984375\n",
      "Epoch [28/50], Batch 34/120, Train Loss: 93.3312\n",
      "3627.0074157714844\n",
      "Epoch [28/50], Batch 35/120, Train Loss: 94.6994\n",
      "3726.2822265625\n",
      "Epoch [28/50], Batch 36/120, Train Loss: 99.2748\n",
      "3832.5890350341797\n",
      "Epoch [28/50], Batch 37/120, Train Loss: 106.3068\n",
      "3969.9659881591797\n",
      "Epoch [28/50], Batch 38/120, Train Loss: 137.3770\n",
      "4095.9501571655273\n",
      "Epoch [28/50], Batch 39/120, Train Loss: 125.9842\n",
      "4176.377548217773\n",
      "Epoch [28/50], Batch 40/120, Train Loss: 80.4274\n",
      "4290.272605895996\n",
      "Epoch [28/50], Batch 41/120, Train Loss: 113.8951\n",
      "4392.094657897949\n",
      "Epoch [28/50], Batch 42/120, Train Loss: 101.8221\n",
      "4515.371879577637\n",
      "Epoch [28/50], Batch 43/120, Train Loss: 123.2772\n",
      "4614.874656677246\n",
      "Epoch [28/50], Batch 44/120, Train Loss: 99.5028\n",
      "4727.263298034668\n",
      "Epoch [28/50], Batch 45/120, Train Loss: 112.3886\n",
      "4820.59676361084\n",
      "Epoch [28/50], Batch 46/120, Train Loss: 93.3335\n",
      "4925.459747314453\n",
      "Epoch [28/50], Batch 47/120, Train Loss: 104.8630\n",
      "5032.74089050293\n",
      "Epoch [28/50], Batch 48/120, Train Loss: 107.2811\n",
      "5131.259216308594\n",
      "Epoch [28/50], Batch 49/120, Train Loss: 98.5183\n",
      "5236.423179626465\n",
      "Epoch [28/50], Batch 50/120, Train Loss: 105.1640\n",
      "5339.086624145508\n",
      "Epoch [28/50], Batch 51/120, Train Loss: 102.6634\n",
      "5431.430892944336\n",
      "Epoch [28/50], Batch 52/120, Train Loss: 92.3443\n",
      "5532.454971313477\n",
      "Epoch [28/50], Batch 53/120, Train Loss: 101.0241\n",
      "5630.207901000977\n",
      "Epoch [28/50], Batch 54/120, Train Loss: 97.7529\n",
      "5745.115310668945\n",
      "Epoch [28/50], Batch 55/120, Train Loss: 114.9074\n",
      "5835.346786499023\n",
      "Epoch [28/50], Batch 56/120, Train Loss: 90.2315\n",
      "5942.859474182129\n",
      "Epoch [28/50], Batch 57/120, Train Loss: 107.5127\n",
      "6028.393989562988\n",
      "Epoch [28/50], Batch 58/120, Train Loss: 85.5345\n",
      "6139.573219299316\n",
      "Epoch [28/50], Batch 59/120, Train Loss: 111.1792\n",
      "6233.127555847168\n",
      "Epoch [28/50], Batch 60/120, Train Loss: 93.5543\n",
      "6352.5216064453125\n",
      "Epoch [28/50], Batch 61/120, Train Loss: 119.3941\n",
      "6478.772003173828\n",
      "Epoch [28/50], Batch 62/120, Train Loss: 126.2504\n",
      "6587.903907775879\n",
      "Epoch [28/50], Batch 63/120, Train Loss: 109.1319\n",
      "6695.04362487793\n",
      "Epoch [28/50], Batch 64/120, Train Loss: 107.1397\n",
      "6798.061241149902\n",
      "Epoch [28/50], Batch 65/120, Train Loss: 103.0176\n",
      "6894.134559631348\n",
      "Epoch [28/50], Batch 66/120, Train Loss: 96.0733\n",
      "7003.910102844238\n",
      "Epoch [28/50], Batch 67/120, Train Loss: 109.7755\n",
      "7087.68416595459\n",
      "Epoch [28/50], Batch 68/120, Train Loss: 83.7741\n",
      "7208.042701721191\n",
      "Epoch [28/50], Batch 69/120, Train Loss: 120.3585\n",
      "7331.396514892578\n",
      "Epoch [28/50], Batch 70/120, Train Loss: 123.3538\n",
      "7437.005561828613\n",
      "Epoch [28/50], Batch 71/120, Train Loss: 105.6090\n",
      "7552.7275466918945\n",
      "Epoch [28/50], Batch 72/120, Train Loss: 115.7220\n",
      "7678.695724487305\n",
      "Epoch [28/50], Batch 73/120, Train Loss: 125.9682\n",
      "7764.513732910156\n",
      "Epoch [28/50], Batch 74/120, Train Loss: 85.8180\n",
      "7873.510055541992\n",
      "Epoch [28/50], Batch 75/120, Train Loss: 108.9963\n",
      "7986.985748291016\n",
      "Epoch [28/50], Batch 76/120, Train Loss: 113.4757\n",
      "8054.864486694336\n",
      "Epoch [28/50], Batch 77/120, Train Loss: 67.8787\n",
      "8154.855056762695\n",
      "Epoch [28/50], Batch 78/120, Train Loss: 99.9906\n",
      "8272.113189697266\n",
      "Epoch [28/50], Batch 79/120, Train Loss: 117.2581\n",
      "8369.387641906738\n",
      "Epoch [28/50], Batch 80/120, Train Loss: 97.2745\n",
      "8472.707054138184\n",
      "Epoch [28/50], Batch 81/120, Train Loss: 103.3194\n",
      "8574.765510559082\n",
      "Epoch [28/50], Batch 82/120, Train Loss: 102.0585\n",
      "8674.861991882324\n",
      "Epoch [28/50], Batch 83/120, Train Loss: 100.0965\n",
      "8786.177589416504\n",
      "Epoch [28/50], Batch 84/120, Train Loss: 111.3156\n",
      "8870.29556274414\n",
      "Epoch [28/50], Batch 85/120, Train Loss: 84.1180\n",
      "8973.838424682617\n",
      "Epoch [28/50], Batch 86/120, Train Loss: 103.5429\n",
      "9077.472579956055\n",
      "Epoch [28/50], Batch 87/120, Train Loss: 103.6342\n",
      "9182.533889770508\n",
      "Epoch [28/50], Batch 88/120, Train Loss: 105.0613\n",
      "9294.949142456055\n",
      "Epoch [28/50], Batch 89/120, Train Loss: 112.4153\n",
      "9399.004653930664\n",
      "Epoch [28/50], Batch 90/120, Train Loss: 104.0555\n",
      "9485.998817443848\n",
      "Epoch [28/50], Batch 91/120, Train Loss: 86.9942\n",
      "9577.089981079102\n",
      "Epoch [28/50], Batch 92/120, Train Loss: 91.0912\n",
      "9658.274139404297\n",
      "Epoch [28/50], Batch 93/120, Train Loss: 81.1842\n",
      "9757.838119506836\n",
      "Epoch [28/50], Batch 94/120, Train Loss: 99.5640\n",
      "9873.37442779541\n",
      "Epoch [28/50], Batch 95/120, Train Loss: 115.5363\n",
      "9986.970542907715\n",
      "Epoch [28/50], Batch 96/120, Train Loss: 113.5961\n",
      "10076.598587036133\n",
      "Epoch [28/50], Batch 97/120, Train Loss: 89.6280\n",
      "10178.428977966309\n",
      "Epoch [28/50], Batch 98/120, Train Loss: 101.8304\n",
      "10271.855827331543\n",
      "Epoch [28/50], Batch 99/120, Train Loss: 93.4268\n",
      "10362.282249450684\n",
      "Epoch [28/50], Batch 100/120, Train Loss: 90.4264\n",
      "10478.437446594238\n",
      "Epoch [28/50], Batch 101/120, Train Loss: 116.1552\n",
      "10591.355247497559\n",
      "Epoch [28/50], Batch 102/120, Train Loss: 112.9178\n",
      "10688.979888916016\n",
      "Epoch [28/50], Batch 103/120, Train Loss: 97.6246\n",
      "10788.447792053223\n",
      "Epoch [28/50], Batch 104/120, Train Loss: 99.4679\n",
      "10899.328651428223\n",
      "Epoch [28/50], Batch 105/120, Train Loss: 110.8809\n",
      "11019.495079040527\n",
      "Epoch [28/50], Batch 106/120, Train Loss: 120.1664\n",
      "11119.224128723145\n",
      "Epoch [28/50], Batch 107/120, Train Loss: 99.7290\n",
      "11215.22110748291\n",
      "Epoch [28/50], Batch 108/120, Train Loss: 95.9970\n",
      "11305.583702087402\n",
      "Epoch [28/50], Batch 109/120, Train Loss: 90.3626\n",
      "11411.990867614746\n",
      "Epoch [28/50], Batch 110/120, Train Loss: 106.4072\n",
      "11528.048637390137\n",
      "Epoch [28/50], Batch 111/120, Train Loss: 116.0578\n",
      "11635.87493133545\n",
      "Epoch [28/50], Batch 112/120, Train Loss: 107.8263\n",
      "11735.82396697998\n",
      "Epoch [28/50], Batch 113/120, Train Loss: 99.9490\n",
      "11818.02123260498\n",
      "Epoch [28/50], Batch 114/120, Train Loss: 82.1973\n",
      "11941.81047821045\n",
      "Epoch [28/50], Batch 115/120, Train Loss: 123.7892\n",
      "12027.98657989502\n",
      "Epoch [28/50], Batch 116/120, Train Loss: 86.1761\n",
      "12151.064529418945\n",
      "Epoch [28/50], Batch 117/120, Train Loss: 123.0779\n",
      "12256.977569580078\n",
      "Epoch [28/50], Batch 118/120, Train Loss: 105.9130\n",
      "12367.141296386719\n",
      "Epoch [28/50], Batch 119/120, Train Loss: 110.1637\n",
      "12453.991180419922\n",
      "Epoch [28/50], Batch 120/120, Train Loss: 86.8499\n",
      "Epoch [28/50], Train Loss: 103.7833, Validation Loss: 116.2350\n",
      "129.56678771972656\n",
      "Epoch [29/50], Batch 1/120, Train Loss: 129.5668\n",
      "226.43887329101562\n",
      "Epoch [29/50], Batch 2/120, Train Loss: 96.8721\n",
      "344.8066864013672\n",
      "Epoch [29/50], Batch 3/120, Train Loss: 118.3678\n",
      "443.523193359375\n",
      "Epoch [29/50], Batch 4/120, Train Loss: 98.7165\n",
      "579.2522430419922\n",
      "Epoch [29/50], Batch 5/120, Train Loss: 135.7290\n",
      "694.7600250244141\n",
      "Epoch [29/50], Batch 6/120, Train Loss: 115.5078\n",
      "785.1243743896484\n",
      "Epoch [29/50], Batch 7/120, Train Loss: 90.3643\n",
      "877.9762420654297\n",
      "Epoch [29/50], Batch 8/120, Train Loss: 92.8519\n",
      "966.8482513427734\n",
      "Epoch [29/50], Batch 9/120, Train Loss: 88.8720\n",
      "1098.199234008789\n",
      "Epoch [29/50], Batch 10/120, Train Loss: 131.3510\n",
      "1195.1010284423828\n",
      "Epoch [29/50], Batch 11/120, Train Loss: 96.9018\n",
      "1293.542709350586\n",
      "Epoch [29/50], Batch 12/120, Train Loss: 98.4417\n",
      "1397.166389465332\n",
      "Epoch [29/50], Batch 13/120, Train Loss: 103.6237\n",
      "1509.568832397461\n",
      "Epoch [29/50], Batch 14/120, Train Loss: 112.4024\n",
      "1609.2224884033203\n",
      "Epoch [29/50], Batch 15/120, Train Loss: 99.6537\n",
      "1715.4946365356445\n",
      "Epoch [29/50], Batch 16/120, Train Loss: 106.2721\n",
      "1809.9176864624023\n",
      "Epoch [29/50], Batch 17/120, Train Loss: 94.4230\n",
      "1886.9515762329102\n",
      "Epoch [29/50], Batch 18/120, Train Loss: 77.0339\n",
      "1997.9581832885742\n",
      "Epoch [29/50], Batch 19/120, Train Loss: 111.0066\n",
      "2095.4675674438477\n",
      "Epoch [29/50], Batch 20/120, Train Loss: 97.5094\n",
      "2188.382713317871\n",
      "Epoch [29/50], Batch 21/120, Train Loss: 92.9151\n",
      "2296.13818359375\n",
      "Epoch [29/50], Batch 22/120, Train Loss: 107.7555\n",
      "2405.803192138672\n",
      "Epoch [29/50], Batch 23/120, Train Loss: 109.6650\n",
      "2485.6679458618164\n",
      "Epoch [29/50], Batch 24/120, Train Loss: 79.8648\n",
      "2590.7358627319336\n",
      "Epoch [29/50], Batch 25/120, Train Loss: 105.0679\n",
      "2667.8395462036133\n",
      "Epoch [29/50], Batch 26/120, Train Loss: 77.1037\n",
      "2777.638801574707\n",
      "Epoch [29/50], Batch 27/120, Train Loss: 109.7993\n",
      "2889.976203918457\n",
      "Epoch [29/50], Batch 28/120, Train Loss: 112.3374\n",
      "3006.8240280151367\n",
      "Epoch [29/50], Batch 29/120, Train Loss: 116.8478\n",
      "3100.9992446899414\n",
      "Epoch [29/50], Batch 30/120, Train Loss: 94.1752\n",
      "3180.724464416504\n",
      "Epoch [29/50], Batch 31/120, Train Loss: 79.7252\n",
      "3287.0863723754883\n",
      "Epoch [29/50], Batch 32/120, Train Loss: 106.3619\n",
      "3403.8997192382812\n",
      "Epoch [29/50], Batch 33/120, Train Loss: 116.8133\n",
      "3523.397102355957\n",
      "Epoch [29/50], Batch 34/120, Train Loss: 119.4974\n",
      "3619.239158630371\n",
      "Epoch [29/50], Batch 35/120, Train Loss: 95.8421\n",
      "3727.65731048584\n",
      "Epoch [29/50], Batch 36/120, Train Loss: 108.4182\n",
      "3828.9348220825195\n",
      "Epoch [29/50], Batch 37/120, Train Loss: 101.2775\n",
      "3933.6743545532227\n",
      "Epoch [29/50], Batch 38/120, Train Loss: 104.7395\n",
      "4053.5141677856445\n",
      "Epoch [29/50], Batch 39/120, Train Loss: 119.8398\n",
      "4159.891098022461\n",
      "Epoch [29/50], Batch 40/120, Train Loss: 106.3769\n",
      "4280.955589294434\n",
      "Epoch [29/50], Batch 41/120, Train Loss: 121.0645\n",
      "4393.861274719238\n",
      "Epoch [29/50], Batch 42/120, Train Loss: 112.9057\n",
      "4500.291358947754\n",
      "Epoch [29/50], Batch 43/120, Train Loss: 106.4301\n",
      "4599.697822570801\n",
      "Epoch [29/50], Batch 44/120, Train Loss: 99.4065\n",
      "4717.772575378418\n",
      "Epoch [29/50], Batch 45/120, Train Loss: 118.0748\n",
      "4802.495796203613\n",
      "Epoch [29/50], Batch 46/120, Train Loss: 84.7232\n",
      "4909.979957580566\n",
      "Epoch [29/50], Batch 47/120, Train Loss: 107.4842\n",
      "5003.249649047852\n",
      "Epoch [29/50], Batch 48/120, Train Loss: 93.2697\n",
      "5086.825546264648\n",
      "Epoch [29/50], Batch 49/120, Train Loss: 83.5759\n",
      "5192.268600463867\n",
      "Epoch [29/50], Batch 50/120, Train Loss: 105.4431\n",
      "5293.601425170898\n",
      "Epoch [29/50], Batch 51/120, Train Loss: 101.3328\n",
      "5380.738311767578\n",
      "Epoch [29/50], Batch 52/120, Train Loss: 87.1369\n",
      "5493.583511352539\n",
      "Epoch [29/50], Batch 53/120, Train Loss: 112.8452\n",
      "5603.597145080566\n",
      "Epoch [29/50], Batch 54/120, Train Loss: 110.0136\n",
      "5711.4973068237305\n",
      "Epoch [29/50], Batch 55/120, Train Loss: 107.9002\n",
      "5798.554794311523\n",
      "Epoch [29/50], Batch 56/120, Train Loss: 87.0575\n",
      "5902.7694091796875\n",
      "Epoch [29/50], Batch 57/120, Train Loss: 104.2146\n",
      "5994.557678222656\n",
      "Epoch [29/50], Batch 58/120, Train Loss: 91.7883\n",
      "6073.81143951416\n",
      "Epoch [29/50], Batch 59/120, Train Loss: 79.2538\n",
      "6176.690010070801\n",
      "Epoch [29/50], Batch 60/120, Train Loss: 102.8786\n",
      "6264.68009185791\n",
      "Epoch [29/50], Batch 61/120, Train Loss: 87.9901\n",
      "6341.217948913574\n",
      "Epoch [29/50], Batch 62/120, Train Loss: 76.5379\n",
      "6445.9533615112305\n",
      "Epoch [29/50], Batch 63/120, Train Loss: 104.7354\n",
      "6529.304092407227\n",
      "Epoch [29/50], Batch 64/120, Train Loss: 83.3507\n",
      "6634.720123291016\n",
      "Epoch [29/50], Batch 65/120, Train Loss: 105.4160\n",
      "6733.6982345581055\n",
      "Epoch [29/50], Batch 66/120, Train Loss: 98.9781\n",
      "6845.5383377075195\n",
      "Epoch [29/50], Batch 67/120, Train Loss: 111.8401\n",
      "6942.7651290893555\n",
      "Epoch [29/50], Batch 68/120, Train Loss: 97.2268\n",
      "7023.590156555176\n",
      "Epoch [29/50], Batch 69/120, Train Loss: 80.8250\n",
      "7120.258995056152\n",
      "Epoch [29/50], Batch 70/120, Train Loss: 96.6688\n",
      "7203.997886657715\n",
      "Epoch [29/50], Batch 71/120, Train Loss: 83.7389\n",
      "7302.851997375488\n",
      "Epoch [29/50], Batch 72/120, Train Loss: 98.8541\n",
      "7417.6209716796875\n",
      "Epoch [29/50], Batch 73/120, Train Loss: 114.7690\n",
      "7527.828506469727\n",
      "Epoch [29/50], Batch 74/120, Train Loss: 110.2075\n",
      "7613.558906555176\n",
      "Epoch [29/50], Batch 75/120, Train Loss: 85.7304\n",
      "7717.940803527832\n",
      "Epoch [29/50], Batch 76/120, Train Loss: 104.3819\n",
      "7804.015480041504\n",
      "Epoch [29/50], Batch 77/120, Train Loss: 86.0747\n",
      "7915.667037963867\n",
      "Epoch [29/50], Batch 78/120, Train Loss: 111.6516\n",
      "8024.304000854492\n",
      "Epoch [29/50], Batch 79/120, Train Loss: 108.6370\n",
      "8116.464340209961\n",
      "Epoch [29/50], Batch 80/120, Train Loss: 92.1603\n",
      "8205.883201599121\n",
      "Epoch [29/50], Batch 81/120, Train Loss: 89.4189\n",
      "8304.944770812988\n",
      "Epoch [29/50], Batch 82/120, Train Loss: 99.0616\n",
      "8431.734764099121\n",
      "Epoch [29/50], Batch 83/120, Train Loss: 126.7900\n",
      "8544.159683227539\n",
      "Epoch [29/50], Batch 84/120, Train Loss: 112.4249\n",
      "8651.179145812988\n",
      "Epoch [29/50], Batch 85/120, Train Loss: 107.0195\n",
      "8760.835083007812\n",
      "Epoch [29/50], Batch 86/120, Train Loss: 109.6559\n",
      "8855.971153259277\n",
      "Epoch [29/50], Batch 87/120, Train Loss: 95.1361\n",
      "8956.323280334473\n",
      "Epoch [29/50], Batch 88/120, Train Loss: 100.3521\n",
      "9057.376083374023\n",
      "Epoch [29/50], Batch 89/120, Train Loss: 101.0528\n",
      "9167.059898376465\n",
      "Epoch [29/50], Batch 90/120, Train Loss: 109.6838\n",
      "9276.946891784668\n",
      "Epoch [29/50], Batch 91/120, Train Loss: 109.8870\n",
      "9396.714263916016\n",
      "Epoch [29/50], Batch 92/120, Train Loss: 119.7674\n",
      "9526.761337280273\n",
      "Epoch [29/50], Batch 93/120, Train Loss: 130.0471\n",
      "9626.021774291992\n",
      "Epoch [29/50], Batch 94/120, Train Loss: 99.2604\n",
      "9752.40161895752\n",
      "Epoch [29/50], Batch 95/120, Train Loss: 126.3798\n",
      "9879.129898071289\n",
      "Epoch [29/50], Batch 96/120, Train Loss: 126.7283\n",
      "9966.893432617188\n",
      "Epoch [29/50], Batch 97/120, Train Loss: 87.7635\n",
      "10075.91967010498\n",
      "Epoch [29/50], Batch 98/120, Train Loss: 109.0262\n",
      "10178.589302062988\n",
      "Epoch [29/50], Batch 99/120, Train Loss: 102.6696\n",
      "10280.126411437988\n",
      "Epoch [29/50], Batch 100/120, Train Loss: 101.5371\n",
      "10375.861671447754\n",
      "Epoch [29/50], Batch 101/120, Train Loss: 95.7353\n",
      "10485.06438446045\n",
      "Epoch [29/50], Batch 102/120, Train Loss: 109.2027\n",
      "10591.082931518555\n",
      "Epoch [29/50], Batch 103/120, Train Loss: 106.0185\n",
      "10691.014938354492\n",
      "Epoch [29/50], Batch 104/120, Train Loss: 99.9320\n",
      "10787.667427062988\n",
      "Epoch [29/50], Batch 105/120, Train Loss: 96.6525\n",
      "10898.482452392578\n",
      "Epoch [29/50], Batch 106/120, Train Loss: 110.8150\n",
      "11024.346893310547\n",
      "Epoch [29/50], Batch 107/120, Train Loss: 125.8644\n",
      "11113.532135009766\n",
      "Epoch [29/50], Batch 108/120, Train Loss: 89.1852\n",
      "11217.73112487793\n",
      "Epoch [29/50], Batch 109/120, Train Loss: 104.1990\n",
      "11299.525978088379\n",
      "Epoch [29/50], Batch 110/120, Train Loss: 81.7949\n",
      "11391.551818847656\n",
      "Epoch [29/50], Batch 111/120, Train Loss: 92.0258\n",
      "11498.338027954102\n",
      "Epoch [29/50], Batch 112/120, Train Loss: 106.7862\n",
      "11609.804473876953\n",
      "Epoch [29/50], Batch 113/120, Train Loss: 111.4664\n",
      "11714.624992370605\n",
      "Epoch [29/50], Batch 114/120, Train Loss: 104.8205\n",
      "11809.831558227539\n",
      "Epoch [29/50], Batch 115/120, Train Loss: 95.2066\n",
      "11897.135948181152\n",
      "Epoch [29/50], Batch 116/120, Train Loss: 87.3044\n",
      "11998.255027770996\n",
      "Epoch [29/50], Batch 117/120, Train Loss: 101.1191\n",
      "12104.65325164795\n",
      "Epoch [29/50], Batch 118/120, Train Loss: 106.3982\n",
      "12223.97061920166\n",
      "Epoch [29/50], Batch 119/120, Train Loss: 119.3174\n",
      "12307.705223083496\n",
      "Epoch [29/50], Batch 120/120, Train Loss: 83.7346\n",
      "Epoch [29/50], Train Loss: 102.5642, Validation Loss: 115.0383\n",
      "59.393646240234375\n",
      "Epoch [30/50], Batch 1/120, Train Loss: 59.3936\n",
      "156.17730712890625\n",
      "Epoch [30/50], Batch 2/120, Train Loss: 96.7837\n",
      "249.64608764648438\n",
      "Epoch [30/50], Batch 3/120, Train Loss: 93.4688\n",
      "342.94690704345703\n",
      "Epoch [30/50], Batch 4/120, Train Loss: 93.3008\n",
      "436.59993743896484\n",
      "Epoch [30/50], Batch 5/120, Train Loss: 93.6530\n",
      "556.795036315918\n",
      "Epoch [30/50], Batch 6/120, Train Loss: 120.1951\n",
      "668.8366394042969\n",
      "Epoch [30/50], Batch 7/120, Train Loss: 112.0416\n",
      "768.4627380371094\n",
      "Epoch [30/50], Batch 8/120, Train Loss: 99.6261\n",
      "871.9155883789062\n",
      "Epoch [30/50], Batch 9/120, Train Loss: 103.4529\n",
      "957.7112579345703\n",
      "Epoch [30/50], Batch 10/120, Train Loss: 85.7957\n",
      "1075.0006866455078\n",
      "Epoch [30/50], Batch 11/120, Train Loss: 117.2894\n",
      "1200.7076416015625\n",
      "Epoch [30/50], Batch 12/120, Train Loss: 125.7070\n",
      "1308.6517028808594\n",
      "Epoch [30/50], Batch 13/120, Train Loss: 107.9441\n",
      "1420.9690628051758\n",
      "Epoch [30/50], Batch 14/120, Train Loss: 112.3174\n",
      "1529.3166732788086\n",
      "Epoch [30/50], Batch 15/120, Train Loss: 108.3476\n",
      "1650.8812789916992\n",
      "Epoch [30/50], Batch 16/120, Train Loss: 121.5646\n",
      "1764.6397705078125\n",
      "Epoch [30/50], Batch 17/120, Train Loss: 113.7585\n",
      "1874.9436721801758\n",
      "Epoch [30/50], Batch 18/120, Train Loss: 110.3039\n",
      "1966.9690017700195\n",
      "Epoch [30/50], Batch 19/120, Train Loss: 92.0253\n",
      "2060.1689987182617\n",
      "Epoch [30/50], Batch 20/120, Train Loss: 93.2000\n",
      "2163.3645782470703\n",
      "Epoch [30/50], Batch 21/120, Train Loss: 103.1956\n",
      "2277.1314849853516\n",
      "Epoch [30/50], Batch 22/120, Train Loss: 113.7669\n",
      "2371.8670806884766\n",
      "Epoch [30/50], Batch 23/120, Train Loss: 94.7356\n",
      "2481.902015686035\n",
      "Epoch [30/50], Batch 24/120, Train Loss: 110.0349\n",
      "2588.051956176758\n",
      "Epoch [30/50], Batch 25/120, Train Loss: 106.1499\n",
      "2707.4542694091797\n",
      "Epoch [30/50], Batch 26/120, Train Loss: 119.4023\n",
      "2807.728302001953\n",
      "Epoch [30/50], Batch 27/120, Train Loss: 100.2740\n",
      "2910.565948486328\n",
      "Epoch [30/50], Batch 28/120, Train Loss: 102.8376\n",
      "3005.1126708984375\n",
      "Epoch [30/50], Batch 29/120, Train Loss: 94.5467\n",
      "3114.8378524780273\n",
      "Epoch [30/50], Batch 30/120, Train Loss: 109.7252\n",
      "3222.9733123779297\n",
      "Epoch [30/50], Batch 31/120, Train Loss: 108.1355\n",
      "3347.8584747314453\n",
      "Epoch [30/50], Batch 32/120, Train Loss: 124.8852\n",
      "3416.9220123291016\n",
      "Epoch [30/50], Batch 33/120, Train Loss: 69.0635\n",
      "3524.9024505615234\n",
      "Epoch [30/50], Batch 34/120, Train Loss: 107.9804\n",
      "3640.8729248046875\n",
      "Epoch [30/50], Batch 35/120, Train Loss: 115.9705\n",
      "3752.230987548828\n",
      "Epoch [30/50], Batch 36/120, Train Loss: 111.3581\n",
      "3864.387466430664\n",
      "Epoch [30/50], Batch 37/120, Train Loss: 112.1565\n",
      "3974.4417724609375\n",
      "Epoch [30/50], Batch 38/120, Train Loss: 110.0543\n",
      "4078.229537963867\n",
      "Epoch [30/50], Batch 39/120, Train Loss: 103.7878\n",
      "4169.146331787109\n",
      "Epoch [30/50], Batch 40/120, Train Loss: 90.9168\n",
      "4248.011451721191\n",
      "Epoch [30/50], Batch 41/120, Train Loss: 78.8651\n",
      "4339.633071899414\n",
      "Epoch [30/50], Batch 42/120, Train Loss: 91.6216\n",
      "4454.296180725098\n",
      "Epoch [30/50], Batch 43/120, Train Loss: 114.6631\n",
      "4567.082191467285\n",
      "Epoch [30/50], Batch 44/120, Train Loss: 112.7860\n",
      "4658.99723815918\n",
      "Epoch [30/50], Batch 45/120, Train Loss: 91.9150\n",
      "4761.298278808594\n",
      "Epoch [30/50], Batch 46/120, Train Loss: 102.3010\n",
      "4858.466690063477\n",
      "Epoch [30/50], Batch 47/120, Train Loss: 97.1684\n",
      "4960.778022766113\n",
      "Epoch [30/50], Batch 48/120, Train Loss: 102.3113\n",
      "5058.306785583496\n",
      "Epoch [30/50], Batch 49/120, Train Loss: 97.5288\n",
      "5169.709526062012\n",
      "Epoch [30/50], Batch 50/120, Train Loss: 111.4027\n",
      "5267.5768966674805\n",
      "Epoch [30/50], Batch 51/120, Train Loss: 97.8674\n",
      "5352.288764953613\n",
      "Epoch [30/50], Batch 52/120, Train Loss: 84.7119\n",
      "5448.5966873168945\n",
      "Epoch [30/50], Batch 53/120, Train Loss: 96.3079\n",
      "5529.401840209961\n",
      "Epoch [30/50], Batch 54/120, Train Loss: 80.8052\n",
      "5628.620628356934\n",
      "Epoch [30/50], Batch 55/120, Train Loss: 99.2188\n",
      "5730.829551696777\n",
      "Epoch [30/50], Batch 56/120, Train Loss: 102.2089\n",
      "5833.508201599121\n",
      "Epoch [30/50], Batch 57/120, Train Loss: 102.6786\n",
      "5956.680328369141\n",
      "Epoch [30/50], Batch 58/120, Train Loss: 123.1721\n",
      "6060.579025268555\n",
      "Epoch [30/50], Batch 59/120, Train Loss: 103.8987\n",
      "6152.822868347168\n",
      "Epoch [30/50], Batch 60/120, Train Loss: 92.2438\n",
      "6289.495933532715\n",
      "Epoch [30/50], Batch 61/120, Train Loss: 136.6731\n",
      "6417.8222732543945\n",
      "Epoch [30/50], Batch 62/120, Train Loss: 128.3263\n",
      "6527.5623779296875\n",
      "Epoch [30/50], Batch 63/120, Train Loss: 109.7401\n",
      "6632.957633972168\n",
      "Epoch [30/50], Batch 64/120, Train Loss: 105.3953\n",
      "6721.194221496582\n",
      "Epoch [30/50], Batch 65/120, Train Loss: 88.2366\n",
      "6839.466499328613\n",
      "Epoch [30/50], Batch 66/120, Train Loss: 118.2723\n",
      "6943.077102661133\n",
      "Epoch [30/50], Batch 67/120, Train Loss: 103.6106\n",
      "7028.905532836914\n",
      "Epoch [30/50], Batch 68/120, Train Loss: 85.8284\n",
      "7153.477760314941\n",
      "Epoch [30/50], Batch 69/120, Train Loss: 124.5722\n",
      "7247.498794555664\n",
      "Epoch [30/50], Batch 70/120, Train Loss: 94.0210\n",
      "7345.735572814941\n",
      "Epoch [30/50], Batch 71/120, Train Loss: 98.2368\n",
      "7454.508918762207\n",
      "Epoch [30/50], Batch 72/120, Train Loss: 108.7733\n",
      "7555.754615783691\n",
      "Epoch [30/50], Batch 73/120, Train Loss: 101.2457\n",
      "7647.085639953613\n",
      "Epoch [30/50], Batch 74/120, Train Loss: 91.3310\n",
      "7750.891845703125\n",
      "Epoch [30/50], Batch 75/120, Train Loss: 103.8062\n",
      "7857.469711303711\n",
      "Epoch [30/50], Batch 76/120, Train Loss: 106.5779\n",
      "7955.201278686523\n",
      "Epoch [30/50], Batch 77/120, Train Loss: 97.7316\n",
      "8046.259872436523\n",
      "Epoch [30/50], Batch 78/120, Train Loss: 91.0586\n",
      "8152.747451782227\n",
      "Epoch [30/50], Batch 79/120, Train Loss: 106.4876\n",
      "8254.272583007812\n",
      "Epoch [30/50], Batch 80/120, Train Loss: 101.5251\n",
      "8343.282196044922\n",
      "Epoch [30/50], Batch 81/120, Train Loss: 89.0096\n",
      "8451.722442626953\n",
      "Epoch [30/50], Batch 82/120, Train Loss: 108.4402\n",
      "8557.159217834473\n",
      "Epoch [30/50], Batch 83/120, Train Loss: 105.4368\n",
      "8650.224479675293\n",
      "Epoch [30/50], Batch 84/120, Train Loss: 93.0653\n",
      "8746.051216125488\n",
      "Epoch [30/50], Batch 85/120, Train Loss: 95.8267\n",
      "8859.884223937988\n",
      "Epoch [30/50], Batch 86/120, Train Loss: 113.8330\n",
      "8992.00592803955\n",
      "Epoch [30/50], Batch 87/120, Train Loss: 132.1217\n",
      "9106.043632507324\n",
      "Epoch [30/50], Batch 88/120, Train Loss: 114.0377\n",
      "9204.37622833252\n",
      "Epoch [30/50], Batch 89/120, Train Loss: 98.3326\n",
      "9310.128746032715\n",
      "Epoch [30/50], Batch 90/120, Train Loss: 105.7525\n",
      "9404.622863769531\n",
      "Epoch [30/50], Batch 91/120, Train Loss: 94.4941\n",
      "9512.878532409668\n",
      "Epoch [30/50], Batch 92/120, Train Loss: 108.2557\n",
      "9633.89868927002\n",
      "Epoch [30/50], Batch 93/120, Train Loss: 121.0202\n",
      "9742.5863571167\n",
      "Epoch [30/50], Batch 94/120, Train Loss: 108.6877\n",
      "9853.781578063965\n",
      "Epoch [30/50], Batch 95/120, Train Loss: 111.1952\n",
      "9967.973747253418\n",
      "Epoch [30/50], Batch 96/120, Train Loss: 114.1922\n",
      "10073.532211303711\n",
      "Epoch [30/50], Batch 97/120, Train Loss: 105.5585\n",
      "10187.678581237793\n",
      "Epoch [30/50], Batch 98/120, Train Loss: 114.1464\n",
      "10257.472297668457\n",
      "Epoch [30/50], Batch 99/120, Train Loss: 69.7937\n",
      "10330.778717041016\n",
      "Epoch [30/50], Batch 100/120, Train Loss: 73.3064\n",
      "10419.001426696777\n",
      "Epoch [30/50], Batch 101/120, Train Loss: 88.2227\n",
      "10525.402076721191\n",
      "Epoch [30/50], Batch 102/120, Train Loss: 106.4007\n",
      "10629.410736083984\n",
      "Epoch [30/50], Batch 103/120, Train Loss: 104.0087\n",
      "10710.894302368164\n",
      "Epoch [30/50], Batch 104/120, Train Loss: 81.4836\n",
      "10794.86051940918\n",
      "Epoch [30/50], Batch 105/120, Train Loss: 83.9662\n",
      "10888.580047607422\n",
      "Epoch [30/50], Batch 106/120, Train Loss: 93.7195\n",
      "10998.826400756836\n",
      "Epoch [30/50], Batch 107/120, Train Loss: 110.2464\n",
      "11125.27993774414\n",
      "Epoch [30/50], Batch 108/120, Train Loss: 126.4535\n",
      "11237.672241210938\n",
      "Epoch [30/50], Batch 109/120, Train Loss: 112.3923\n",
      "11311.95149230957\n",
      "Epoch [30/50], Batch 110/120, Train Loss: 74.2793\n",
      "11405.68637084961\n",
      "Epoch [30/50], Batch 111/120, Train Loss: 93.7349\n",
      "11518.59944152832\n",
      "Epoch [30/50], Batch 112/120, Train Loss: 112.9131\n",
      "11603.54931640625\n",
      "Epoch [30/50], Batch 113/120, Train Loss: 84.9499\n",
      "11685.749397277832\n",
      "Epoch [30/50], Batch 114/120, Train Loss: 82.2001\n",
      "11769.832801818848\n",
      "Epoch [30/50], Batch 115/120, Train Loss: 84.0834\n",
      "11872.884010314941\n",
      "Epoch [30/50], Batch 116/120, Train Loss: 103.0512\n",
      "11958.555130004883\n",
      "Epoch [30/50], Batch 117/120, Train Loss: 85.6711\n",
      "12059.928268432617\n",
      "Epoch [30/50], Batch 118/120, Train Loss: 101.3731\n",
      "12159.97095489502\n",
      "Epoch [30/50], Batch 119/120, Train Loss: 100.0427\n",
      "12260.660194396973\n",
      "Epoch [30/50], Batch 120/120, Train Loss: 100.6892\n",
      "Epoch [30/50], Train Loss: 102.1722, Validation Loss: 114.6029\n",
      "112.81861114501953\n",
      "Epoch [31/50], Batch 1/120, Train Loss: 112.8186\n",
      "209.2150115966797\n",
      "Epoch [31/50], Batch 2/120, Train Loss: 96.3964\n",
      "284.5184020996094\n",
      "Epoch [31/50], Batch 3/120, Train Loss: 75.3034\n",
      "368.98802947998047\n",
      "Epoch [31/50], Batch 4/120, Train Loss: 84.4696\n",
      "468.25635528564453\n",
      "Epoch [31/50], Batch 5/120, Train Loss: 99.2683\n",
      "561.8021697998047\n",
      "Epoch [31/50], Batch 6/120, Train Loss: 93.5458\n",
      "684.2287902832031\n",
      "Epoch [31/50], Batch 7/120, Train Loss: 122.4266\n",
      "775.6410217285156\n",
      "Epoch [31/50], Batch 8/120, Train Loss: 91.4122\n",
      "891.2599792480469\n",
      "Epoch [31/50], Batch 9/120, Train Loss: 115.6190\n",
      "993.0087509155273\n",
      "Epoch [31/50], Batch 10/120, Train Loss: 101.7488\n",
      "1109.6474151611328\n",
      "Epoch [31/50], Batch 11/120, Train Loss: 116.6387\n",
      "1216.0232238769531\n",
      "Epoch [31/50], Batch 12/120, Train Loss: 106.3758\n",
      "1323.4481658935547\n",
      "Epoch [31/50], Batch 13/120, Train Loss: 107.4249\n",
      "1447.767723083496\n",
      "Epoch [31/50], Batch 14/120, Train Loss: 124.3196\n",
      "1550.0349960327148\n",
      "Epoch [31/50], Batch 15/120, Train Loss: 102.2673\n",
      "1629.8467254638672\n",
      "Epoch [31/50], Batch 16/120, Train Loss: 79.8117\n",
      "1738.3683700561523\n",
      "Epoch [31/50], Batch 17/120, Train Loss: 108.5216\n",
      "1842.4443283081055\n",
      "Epoch [31/50], Batch 18/120, Train Loss: 104.0760\n",
      "1945.538558959961\n",
      "Epoch [31/50], Batch 19/120, Train Loss: 103.0942\n",
      "2060.728973388672\n",
      "Epoch [31/50], Batch 20/120, Train Loss: 115.1904\n",
      "2164.563278198242\n",
      "Epoch [31/50], Batch 21/120, Train Loss: 103.8343\n",
      "2249.435157775879\n",
      "Epoch [31/50], Batch 22/120, Train Loss: 84.8719\n",
      "2350.721694946289\n",
      "Epoch [31/50], Batch 23/120, Train Loss: 101.2865\n",
      "2430.6998748779297\n",
      "Epoch [31/50], Batch 24/120, Train Loss: 79.9782\n",
      "2522.2537689208984\n",
      "Epoch [31/50], Batch 25/120, Train Loss: 91.5539\n",
      "2637.0442657470703\n",
      "Epoch [31/50], Batch 26/120, Train Loss: 114.7905\n",
      "2716.4398193359375\n",
      "Epoch [31/50], Batch 27/120, Train Loss: 79.3956\n",
      "2813.843460083008\n",
      "Epoch [31/50], Batch 28/120, Train Loss: 97.4036\n",
      "2909.110870361328\n",
      "Epoch [31/50], Batch 29/120, Train Loss: 95.2674\n",
      "3021.079833984375\n",
      "Epoch [31/50], Batch 30/120, Train Loss: 111.9690\n",
      "3113.1314086914062\n",
      "Epoch [31/50], Batch 31/120, Train Loss: 92.0516\n",
      "3221.2218170166016\n",
      "Epoch [31/50], Batch 32/120, Train Loss: 108.0904\n",
      "3310.610221862793\n",
      "Epoch [31/50], Batch 33/120, Train Loss: 89.3884\n",
      "3416.3538513183594\n",
      "Epoch [31/50], Batch 34/120, Train Loss: 105.7436\n",
      "3527.1539306640625\n",
      "Epoch [31/50], Batch 35/120, Train Loss: 110.8001\n",
      "3610.6435546875\n",
      "Epoch [31/50], Batch 36/120, Train Loss: 83.4896\n",
      "3707.0367431640625\n",
      "Epoch [31/50], Batch 37/120, Train Loss: 96.3932\n",
      "3797.19718170166\n",
      "Epoch [31/50], Batch 38/120, Train Loss: 90.1604\n",
      "3894.4384231567383\n",
      "Epoch [31/50], Batch 39/120, Train Loss: 97.2412\n",
      "3991.7338638305664\n",
      "Epoch [31/50], Batch 40/120, Train Loss: 97.2954\n",
      "4072.6780166625977\n",
      "Epoch [31/50], Batch 41/120, Train Loss: 80.9442\n",
      "4185.019485473633\n",
      "Epoch [31/50], Batch 42/120, Train Loss: 112.3415\n",
      "4293.2602615356445\n",
      "Epoch [31/50], Batch 43/120, Train Loss: 108.2408\n",
      "4404.229820251465\n",
      "Epoch [31/50], Batch 44/120, Train Loss: 110.9696\n",
      "4534.330375671387\n",
      "Epoch [31/50], Batch 45/120, Train Loss: 130.1006\n",
      "4646.885223388672\n",
      "Epoch [31/50], Batch 46/120, Train Loss: 112.5548\n",
      "4761.809188842773\n",
      "Epoch [31/50], Batch 47/120, Train Loss: 114.9240\n",
      "4836.102508544922\n",
      "Epoch [31/50], Batch 48/120, Train Loss: 74.2933\n",
      "4924.301856994629\n",
      "Epoch [31/50], Batch 49/120, Train Loss: 88.1993\n",
      "5011.7128829956055\n",
      "Epoch [31/50], Batch 50/120, Train Loss: 87.4110\n",
      "5109.561683654785\n",
      "Epoch [31/50], Batch 51/120, Train Loss: 97.8488\n",
      "5198.4167404174805\n",
      "Epoch [31/50], Batch 52/120, Train Loss: 88.8551\n",
      "5309.777893066406\n",
      "Epoch [31/50], Batch 53/120, Train Loss: 111.3612\n",
      "5423.459136962891\n",
      "Epoch [31/50], Batch 54/120, Train Loss: 113.6812\n",
      "5519.835052490234\n",
      "Epoch [31/50], Batch 55/120, Train Loss: 96.3759\n",
      "5622.75910949707\n",
      "Epoch [31/50], Batch 56/120, Train Loss: 102.9241\n",
      "5706.260665893555\n",
      "Epoch [31/50], Batch 57/120, Train Loss: 83.5016\n",
      "5816.4343185424805\n",
      "Epoch [31/50], Batch 58/120, Train Loss: 110.1737\n",
      "5920.972030639648\n",
      "Epoch [31/50], Batch 59/120, Train Loss: 104.5377\n",
      "6019.367935180664\n",
      "Epoch [31/50], Batch 60/120, Train Loss: 98.3959\n",
      "6143.98575592041\n",
      "Epoch [31/50], Batch 61/120, Train Loss: 124.6178\n",
      "6231.422737121582\n",
      "Epoch [31/50], Batch 62/120, Train Loss: 87.4370\n",
      "6339.24267578125\n",
      "Epoch [31/50], Batch 63/120, Train Loss: 107.8199\n",
      "6437.641799926758\n",
      "Epoch [31/50], Batch 64/120, Train Loss: 98.3991\n",
      "6527.868522644043\n",
      "Epoch [31/50], Batch 65/120, Train Loss: 90.2267\n",
      "6621.4758224487305\n",
      "Epoch [31/50], Batch 66/120, Train Loss: 93.6073\n",
      "6726.151557922363\n",
      "Epoch [31/50], Batch 67/120, Train Loss: 104.6757\n",
      "6831.811454772949\n",
      "Epoch [31/50], Batch 68/120, Train Loss: 105.6599\n",
      "6932.605995178223\n",
      "Epoch [31/50], Batch 69/120, Train Loss: 100.7945\n",
      "7008.870452880859\n",
      "Epoch [31/50], Batch 70/120, Train Loss: 76.2645\n",
      "7101.938812255859\n",
      "Epoch [31/50], Batch 71/120, Train Loss: 93.0684\n",
      "7203.277763366699\n",
      "Epoch [31/50], Batch 72/120, Train Loss: 101.3390\n",
      "7303.519981384277\n",
      "Epoch [31/50], Batch 73/120, Train Loss: 100.2422\n",
      "7405.5810623168945\n",
      "Epoch [31/50], Batch 74/120, Train Loss: 102.0611\n",
      "7485.625091552734\n",
      "Epoch [31/50], Batch 75/120, Train Loss: 80.0440\n",
      "7573.57438659668\n",
      "Epoch [31/50], Batch 76/120, Train Loss: 87.9493\n",
      "7701.513137817383\n",
      "Epoch [31/50], Batch 77/120, Train Loss: 127.9388\n",
      "7810.618606567383\n",
      "Epoch [31/50], Batch 78/120, Train Loss: 109.1055\n",
      "7906.975555419922\n",
      "Epoch [31/50], Batch 79/120, Train Loss: 96.3569\n",
      "7994.130218505859\n",
      "Epoch [31/50], Batch 80/120, Train Loss: 87.1547\n",
      "8088.0280685424805\n",
      "Epoch [31/50], Batch 81/120, Train Loss: 93.8979\n",
      "8218.085334777832\n",
      "Epoch [31/50], Batch 82/120, Train Loss: 130.0573\n",
      "8317.47924041748\n",
      "Epoch [31/50], Batch 83/120, Train Loss: 99.3939\n",
      "8423.607566833496\n",
      "Epoch [31/50], Batch 84/120, Train Loss: 106.1283\n",
      "8515.081077575684\n",
      "Epoch [31/50], Batch 85/120, Train Loss: 91.4735\n",
      "8612.736686706543\n",
      "Epoch [31/50], Batch 86/120, Train Loss: 97.6556\n",
      "8712.344032287598\n",
      "Epoch [31/50], Batch 87/120, Train Loss: 99.6073\n",
      "8816.130546569824\n",
      "Epoch [31/50], Batch 88/120, Train Loss: 103.7865\n",
      "8910.676124572754\n",
      "Epoch [31/50], Batch 89/120, Train Loss: 94.5456\n",
      "9026.828788757324\n",
      "Epoch [31/50], Batch 90/120, Train Loss: 116.1527\n",
      "9138.222152709961\n",
      "Epoch [31/50], Batch 91/120, Train Loss: 111.3934\n",
      "9247.997261047363\n",
      "Epoch [31/50], Batch 92/120, Train Loss: 109.7751\n",
      "9341.321388244629\n",
      "Epoch [31/50], Batch 93/120, Train Loss: 93.3241\n",
      "9433.794288635254\n",
      "Epoch [31/50], Batch 94/120, Train Loss: 92.4729\n",
      "9541.408950805664\n",
      "Epoch [31/50], Batch 95/120, Train Loss: 107.6147\n",
      "9642.866020202637\n",
      "Epoch [31/50], Batch 96/120, Train Loss: 101.4571\n",
      "9727.061470031738\n",
      "Epoch [31/50], Batch 97/120, Train Loss: 84.1954\n",
      "9834.70329284668\n",
      "Epoch [31/50], Batch 98/120, Train Loss: 107.6418\n",
      "9927.419250488281\n",
      "Epoch [31/50], Batch 99/120, Train Loss: 92.7160\n",
      "10046.136291503906\n",
      "Epoch [31/50], Batch 100/120, Train Loss: 118.7170\n",
      "10133.743606567383\n",
      "Epoch [31/50], Batch 101/120, Train Loss: 87.6073\n",
      "10244.21841430664\n",
      "Epoch [31/50], Batch 102/120, Train Loss: 110.4748\n",
      "10352.081680297852\n",
      "Epoch [31/50], Batch 103/120, Train Loss: 107.8633\n",
      "10461.405303955078\n",
      "Epoch [31/50], Batch 104/120, Train Loss: 109.3236\n",
      "10553.740097045898\n",
      "Epoch [31/50], Batch 105/120, Train Loss: 92.3348\n",
      "10655.618133544922\n",
      "Epoch [31/50], Batch 106/120, Train Loss: 101.8780\n",
      "10760.14501953125\n",
      "Epoch [31/50], Batch 107/120, Train Loss: 104.5269\n",
      "10886.561882019043\n",
      "Epoch [31/50], Batch 108/120, Train Loss: 126.4169\n",
      "10980.989570617676\n",
      "Epoch [31/50], Batch 109/120, Train Loss: 94.4277\n",
      "11086.384483337402\n",
      "Epoch [31/50], Batch 110/120, Train Loss: 105.3949\n",
      "11195.636009216309\n",
      "Epoch [31/50], Batch 111/120, Train Loss: 109.2515\n",
      "11278.477851867676\n",
      "Epoch [31/50], Batch 112/120, Train Loss: 82.8418\n",
      "11374.660736083984\n",
      "Epoch [31/50], Batch 113/120, Train Loss: 96.1829\n",
      "11470.744323730469\n",
      "Epoch [31/50], Batch 114/120, Train Loss: 96.0836\n",
      "11549.863540649414\n",
      "Epoch [31/50], Batch 115/120, Train Loss: 79.1192\n",
      "11645.335800170898\n",
      "Epoch [31/50], Batch 116/120, Train Loss: 95.4723\n",
      "11717.164764404297\n",
      "Epoch [31/50], Batch 117/120, Train Loss: 71.8290\n",
      "11821.003517150879\n",
      "Epoch [31/50], Batch 118/120, Train Loss: 103.8388\n",
      "11906.115684509277\n",
      "Epoch [31/50], Batch 119/120, Train Loss: 85.1122\n",
      "12022.665046691895\n",
      "Epoch [31/50], Batch 120/120, Train Loss: 116.5494\n",
      "Epoch [31/50], Train Loss: 100.1889, Validation Loss: 114.4763\n",
      "107.14065551757812\n",
      "Epoch [32/50], Batch 1/120, Train Loss: 107.1407\n",
      "210.9013442993164\n",
      "Epoch [32/50], Batch 2/120, Train Loss: 103.7607\n",
      "297.1670913696289\n",
      "Epoch [32/50], Batch 3/120, Train Loss: 86.2657\n",
      "401.51319122314453\n",
      "Epoch [32/50], Batch 4/120, Train Loss: 104.3461\n",
      "514.8564529418945\n",
      "Epoch [32/50], Batch 5/120, Train Loss: 113.3433\n",
      "623.920295715332\n",
      "Epoch [32/50], Batch 6/120, Train Loss: 109.0638\n",
      "711.2512893676758\n",
      "Epoch [32/50], Batch 7/120, Train Loss: 87.3310\n",
      "814.0537643432617\n",
      "Epoch [32/50], Batch 8/120, Train Loss: 102.8025\n",
      "933.616584777832\n",
      "Epoch [32/50], Batch 9/120, Train Loss: 119.5628\n",
      "1040.1485748291016\n",
      "Epoch [32/50], Batch 10/120, Train Loss: 106.5320\n",
      "1133.6970520019531\n",
      "Epoch [32/50], Batch 11/120, Train Loss: 93.5485\n",
      "1215.388427734375\n",
      "Epoch [32/50], Batch 12/120, Train Loss: 81.6914\n",
      "1326.6887435913086\n",
      "Epoch [32/50], Batch 13/120, Train Loss: 111.3003\n",
      "1423.3774948120117\n",
      "Epoch [32/50], Batch 14/120, Train Loss: 96.6888\n",
      "1542.851692199707\n",
      "Epoch [32/50], Batch 15/120, Train Loss: 119.4742\n",
      "1676.9104232788086\n",
      "Epoch [32/50], Batch 16/120, Train Loss: 134.0587\n",
      "1752.269142150879\n",
      "Epoch [32/50], Batch 17/120, Train Loss: 75.3587\n",
      "1857.8249816894531\n",
      "Epoch [32/50], Batch 18/120, Train Loss: 105.5558\n",
      "1970.3235778808594\n",
      "Epoch [32/50], Batch 19/120, Train Loss: 112.4986\n",
      "2056.7068099975586\n",
      "Epoch [32/50], Batch 20/120, Train Loss: 86.3832\n",
      "2161.4308547973633\n",
      "Epoch [32/50], Batch 21/120, Train Loss: 104.7240\n",
      "2245.221305847168\n",
      "Epoch [32/50], Batch 22/120, Train Loss: 83.7905\n",
      "2338.7436294555664\n",
      "Epoch [32/50], Batch 23/120, Train Loss: 93.5223\n",
      "2460.9549560546875\n",
      "Epoch [32/50], Batch 24/120, Train Loss: 122.2113\n",
      "2556.1504669189453\n",
      "Epoch [32/50], Batch 25/120, Train Loss: 95.1955\n",
      "2676.6070861816406\n",
      "Epoch [32/50], Batch 26/120, Train Loss: 120.4566\n",
      "2755.3264770507812\n",
      "Epoch [32/50], Batch 27/120, Train Loss: 78.7194\n",
      "2844.3632431030273\n",
      "Epoch [32/50], Batch 28/120, Train Loss: 89.0368\n",
      "2945.332489013672\n",
      "Epoch [32/50], Batch 29/120, Train Loss: 100.9692\n",
      "3040.0708923339844\n",
      "Epoch [32/50], Batch 30/120, Train Loss: 94.7384\n",
      "3157.566017150879\n",
      "Epoch [32/50], Batch 31/120, Train Loss: 117.4951\n",
      "3255.883071899414\n",
      "Epoch [32/50], Batch 32/120, Train Loss: 98.3171\n",
      "3338.339309692383\n",
      "Epoch [32/50], Batch 33/120, Train Loss: 82.4562\n",
      "3429.993850708008\n",
      "Epoch [32/50], Batch 34/120, Train Loss: 91.6545\n",
      "3521.60701751709\n",
      "Epoch [32/50], Batch 35/120, Train Loss: 91.6132\n",
      "3606.7947540283203\n",
      "Epoch [32/50], Batch 36/120, Train Loss: 85.1877\n",
      "3707.399139404297\n",
      "Epoch [32/50], Batch 37/120, Train Loss: 100.6044\n",
      "3844.9365234375\n",
      "Epoch [32/50], Batch 38/120, Train Loss: 137.5374\n",
      "3951.140365600586\n",
      "Epoch [32/50], Batch 39/120, Train Loss: 106.2038\n",
      "4072.1807022094727\n",
      "Epoch [32/50], Batch 40/120, Train Loss: 121.0403\n",
      "4159.6892013549805\n",
      "Epoch [32/50], Batch 41/120, Train Loss: 87.5085\n",
      "4258.314262390137\n",
      "Epoch [32/50], Batch 42/120, Train Loss: 98.6251\n",
      "4346.958923339844\n",
      "Epoch [32/50], Batch 43/120, Train Loss: 88.6447\n",
      "4429.109756469727\n",
      "Epoch [32/50], Batch 44/120, Train Loss: 82.1508\n",
      "4547.429542541504\n",
      "Epoch [32/50], Batch 45/120, Train Loss: 118.3198\n",
      "4641.207298278809\n",
      "Epoch [32/50], Batch 46/120, Train Loss: 93.7778\n",
      "4730.6562423706055\n",
      "Epoch [32/50], Batch 47/120, Train Loss: 89.4489\n",
      "4833.825721740723\n",
      "Epoch [32/50], Batch 48/120, Train Loss: 103.1695\n",
      "4923.934761047363\n",
      "Epoch [32/50], Batch 49/120, Train Loss: 90.1090\n",
      "5004.586242675781\n",
      "Epoch [32/50], Batch 50/120, Train Loss: 80.6515\n",
      "5121.991241455078\n",
      "Epoch [32/50], Batch 51/120, Train Loss: 117.4050\n",
      "5237.376708984375\n",
      "Epoch [32/50], Batch 52/120, Train Loss: 115.3855\n",
      "5347.44987487793\n",
      "Epoch [32/50], Batch 53/120, Train Loss: 110.0732\n",
      "5444.881240844727\n",
      "Epoch [32/50], Batch 54/120, Train Loss: 97.4314\n",
      "5568.145858764648\n",
      "Epoch [32/50], Batch 55/120, Train Loss: 123.2646\n",
      "5663.465255737305\n",
      "Epoch [32/50], Batch 56/120, Train Loss: 95.3194\n",
      "5740.485572814941\n",
      "Epoch [32/50], Batch 57/120, Train Loss: 77.0203\n",
      "5836.4835205078125\n",
      "Epoch [32/50], Batch 58/120, Train Loss: 95.9979\n",
      "5913.344421386719\n",
      "Epoch [32/50], Batch 59/120, Train Loss: 76.8609\n",
      "6014.26155090332\n",
      "Epoch [32/50], Batch 60/120, Train Loss: 100.9171\n",
      "6121.034149169922\n",
      "Epoch [32/50], Batch 61/120, Train Loss: 106.7726\n",
      "6191.1728515625\n",
      "Epoch [32/50], Batch 62/120, Train Loss: 70.1387\n",
      "6321.580047607422\n",
      "Epoch [32/50], Batch 63/120, Train Loss: 130.4072\n",
      "6418.6767578125\n",
      "Epoch [32/50], Batch 64/120, Train Loss: 97.0967\n",
      "6542.667213439941\n",
      "Epoch [32/50], Batch 65/120, Train Loss: 123.9905\n",
      "6633.138694763184\n",
      "Epoch [32/50], Batch 66/120, Train Loss: 90.4715\n",
      "6734.931343078613\n",
      "Epoch [32/50], Batch 67/120, Train Loss: 101.7926\n",
      "6835.852653503418\n",
      "Epoch [32/50], Batch 68/120, Train Loss: 100.9213\n",
      "6925.337921142578\n",
      "Epoch [32/50], Batch 69/120, Train Loss: 89.4853\n",
      "7027.448776245117\n",
      "Epoch [32/50], Batch 70/120, Train Loss: 102.1109\n",
      "7131.311370849609\n",
      "Epoch [32/50], Batch 71/120, Train Loss: 103.8626\n",
      "7229.193984985352\n",
      "Epoch [32/50], Batch 72/120, Train Loss: 97.8826\n",
      "7327.352645874023\n",
      "Epoch [32/50], Batch 73/120, Train Loss: 98.1587\n",
      "7433.182952880859\n",
      "Epoch [32/50], Batch 74/120, Train Loss: 105.8303\n",
      "7552.316497802734\n",
      "Epoch [32/50], Batch 75/120, Train Loss: 119.1335\n",
      "7637.797172546387\n",
      "Epoch [32/50], Batch 76/120, Train Loss: 85.4807\n",
      "7751.825874328613\n",
      "Epoch [32/50], Batch 77/120, Train Loss: 114.0287\n",
      "7849.598030090332\n",
      "Epoch [32/50], Batch 78/120, Train Loss: 97.7722\n",
      "7930.768409729004\n",
      "Epoch [32/50], Batch 79/120, Train Loss: 81.1704\n",
      "8051.261405944824\n",
      "Epoch [32/50], Batch 80/120, Train Loss: 120.4930\n",
      "8127.010971069336\n",
      "Epoch [32/50], Batch 81/120, Train Loss: 75.7496\n",
      "8230.037460327148\n",
      "Epoch [32/50], Batch 82/120, Train Loss: 103.0265\n",
      "8322.738159179688\n",
      "Epoch [32/50], Batch 83/120, Train Loss: 92.7007\n",
      "8428.669799804688\n",
      "Epoch [32/50], Batch 84/120, Train Loss: 105.9316\n",
      "8528.471794128418\n",
      "Epoch [32/50], Batch 85/120, Train Loss: 99.8020\n",
      "8612.163688659668\n",
      "Epoch [32/50], Batch 86/120, Train Loss: 83.6919\n",
      "8707.555435180664\n",
      "Epoch [32/50], Batch 87/120, Train Loss: 95.3917\n",
      "8828.269813537598\n",
      "Epoch [32/50], Batch 88/120, Train Loss: 120.7144\n",
      "8932.904472351074\n",
      "Epoch [32/50], Batch 89/120, Train Loss: 104.6347\n",
      "9049.24909210205\n",
      "Epoch [32/50], Batch 90/120, Train Loss: 116.3446\n",
      "9155.669609069824\n",
      "Epoch [32/50], Batch 91/120, Train Loss: 106.4205\n",
      "9258.0132522583\n",
      "Epoch [32/50], Batch 92/120, Train Loss: 102.3436\n",
      "9350.406227111816\n",
      "Epoch [32/50], Batch 93/120, Train Loss: 92.3930\n",
      "9444.374084472656\n",
      "Epoch [32/50], Batch 94/120, Train Loss: 93.9679\n",
      "9525.615371704102\n",
      "Epoch [32/50], Batch 95/120, Train Loss: 81.2413\n",
      "9632.648460388184\n",
      "Epoch [32/50], Batch 96/120, Train Loss: 107.0331\n",
      "9723.932563781738\n",
      "Epoch [32/50], Batch 97/120, Train Loss: 91.2841\n",
      "9807.891296386719\n",
      "Epoch [32/50], Batch 98/120, Train Loss: 83.9587\n",
      "9885.440864562988\n",
      "Epoch [32/50], Batch 99/120, Train Loss: 77.5496\n",
      "9990.472229003906\n",
      "Epoch [32/50], Batch 100/120, Train Loss: 105.0314\n",
      "10088.59368133545\n",
      "Epoch [32/50], Batch 101/120, Train Loss: 98.1215\n",
      "10190.44149017334\n",
      "Epoch [32/50], Batch 102/120, Train Loss: 101.8478\n",
      "10316.216606140137\n",
      "Epoch [32/50], Batch 103/120, Train Loss: 125.7751\n",
      "10407.539894104004\n",
      "Epoch [32/50], Batch 104/120, Train Loss: 91.3233\n",
      "10503.10408782959\n",
      "Epoch [32/50], Batch 105/120, Train Loss: 95.5642\n",
      "10602.398765563965\n",
      "Epoch [32/50], Batch 106/120, Train Loss: 99.2947\n",
      "10705.80795288086\n",
      "Epoch [32/50], Batch 107/120, Train Loss: 103.4092\n",
      "10792.57096862793\n",
      "Epoch [32/50], Batch 108/120, Train Loss: 86.7630\n",
      "10890.534057617188\n",
      "Epoch [32/50], Batch 109/120, Train Loss: 97.9631\n",
      "11002.082458496094\n",
      "Epoch [32/50], Batch 110/120, Train Loss: 111.5484\n",
      "11111.70386505127\n",
      "Epoch [32/50], Batch 111/120, Train Loss: 109.6214\n",
      "11185.920181274414\n",
      "Epoch [32/50], Batch 112/120, Train Loss: 74.2163\n",
      "11294.026504516602\n",
      "Epoch [32/50], Batch 113/120, Train Loss: 108.1063\n",
      "11370.743789672852\n",
      "Epoch [32/50], Batch 114/120, Train Loss: 76.7173\n",
      "11473.136810302734\n",
      "Epoch [32/50], Batch 115/120, Train Loss: 102.3930\n",
      "11565.852401733398\n",
      "Epoch [32/50], Batch 116/120, Train Loss: 92.7156\n",
      "11691.501556396484\n",
      "Epoch [32/50], Batch 117/120, Train Loss: 125.6492\n",
      "11794.206161499023\n",
      "Epoch [32/50], Batch 118/120, Train Loss: 102.7046\n",
      "11890.132751464844\n",
      "Epoch [32/50], Batch 119/120, Train Loss: 95.9266\n",
      "12011.675132751465\n",
      "Epoch [32/50], Batch 120/120, Train Loss: 121.5424\n",
      "Epoch [32/50], Train Loss: 100.0973, Validation Loss: 114.8234\n",
      "104.01203918457031\n",
      "Epoch [33/50], Batch 1/120, Train Loss: 104.0120\n",
      "222.19703674316406\n",
      "Epoch [33/50], Batch 2/120, Train Loss: 118.1850\n",
      "328.2175064086914\n",
      "Epoch [33/50], Batch 3/120, Train Loss: 106.0205\n",
      "414.04911041259766\n",
      "Epoch [33/50], Batch 4/120, Train Loss: 85.8316\n",
      "525.7721710205078\n",
      "Epoch [33/50], Batch 5/120, Train Loss: 111.7231\n",
      "624.6469192504883\n",
      "Epoch [33/50], Batch 6/120, Train Loss: 98.8747\n",
      "718.8662872314453\n",
      "Epoch [33/50], Batch 7/120, Train Loss: 94.2194\n",
      "816.2294464111328\n",
      "Epoch [33/50], Batch 8/120, Train Loss: 97.3632\n",
      "937.5211029052734\n",
      "Epoch [33/50], Batch 9/120, Train Loss: 121.2917\n",
      "1016.8725891113281\n",
      "Epoch [33/50], Batch 10/120, Train Loss: 79.3515\n",
      "1131.5072479248047\n",
      "Epoch [33/50], Batch 11/120, Train Loss: 114.6347\n",
      "1217.4834899902344\n",
      "Epoch [33/50], Batch 12/120, Train Loss: 85.9762\n",
      "1314.9115295410156\n",
      "Epoch [33/50], Batch 13/120, Train Loss: 97.4280\n",
      "1416.2225341796875\n",
      "Epoch [33/50], Batch 14/120, Train Loss: 101.3110\n",
      "1509.1892471313477\n",
      "Epoch [33/50], Batch 15/120, Train Loss: 92.9667\n",
      "1627.025505065918\n",
      "Epoch [33/50], Batch 16/120, Train Loss: 117.8363\n",
      "1729.6496353149414\n",
      "Epoch [33/50], Batch 17/120, Train Loss: 102.6241\n",
      "1820.603660583496\n",
      "Epoch [33/50], Batch 18/120, Train Loss: 90.9540\n",
      "1941.2205047607422\n",
      "Epoch [33/50], Batch 19/120, Train Loss: 120.6168\n",
      "2025.5615234375\n",
      "Epoch [33/50], Batch 20/120, Train Loss: 84.3410\n",
      "2139.774833679199\n",
      "Epoch [33/50], Batch 21/120, Train Loss: 114.2133\n",
      "2255.191665649414\n",
      "Epoch [33/50], Batch 22/120, Train Loss: 115.4168\n",
      "2360.4954681396484\n",
      "Epoch [33/50], Batch 23/120, Train Loss: 105.3038\n",
      "2443.700309753418\n",
      "Epoch [33/50], Batch 24/120, Train Loss: 83.2048\n",
      "2549.8715286254883\n",
      "Epoch [33/50], Batch 25/120, Train Loss: 106.1712\n",
      "2645.8395919799805\n",
      "Epoch [33/50], Batch 26/120, Train Loss: 95.9681\n",
      "2761.963653564453\n",
      "Epoch [33/50], Batch 27/120, Train Loss: 116.1241\n",
      "2857.136444091797\n",
      "Epoch [33/50], Batch 28/120, Train Loss: 95.1728\n",
      "2959.31534576416\n",
      "Epoch [33/50], Batch 29/120, Train Loss: 102.1789\n",
      "3044.7351455688477\n",
      "Epoch [33/50], Batch 30/120, Train Loss: 85.4198\n",
      "3135.159065246582\n",
      "Epoch [33/50], Batch 31/120, Train Loss: 90.4239\n",
      "3251.668746948242\n",
      "Epoch [33/50], Batch 32/120, Train Loss: 116.5097\n",
      "3347.271713256836\n",
      "Epoch [33/50], Batch 33/120, Train Loss: 95.6030\n",
      "3456.1275329589844\n",
      "Epoch [33/50], Batch 34/120, Train Loss: 108.8558\n",
      "3566.335189819336\n",
      "Epoch [33/50], Batch 35/120, Train Loss: 110.2077\n",
      "3660.622734069824\n",
      "Epoch [33/50], Batch 36/120, Train Loss: 94.2875\n",
      "3747.869758605957\n",
      "Epoch [33/50], Batch 37/120, Train Loss: 87.2470\n",
      "3855.8918685913086\n",
      "Epoch [33/50], Batch 38/120, Train Loss: 108.0221\n",
      "3963.427803039551\n",
      "Epoch [33/50], Batch 39/120, Train Loss: 107.5359\n",
      "4064.2431564331055\n",
      "Epoch [33/50], Batch 40/120, Train Loss: 100.8154\n",
      "4159.433944702148\n",
      "Epoch [33/50], Batch 41/120, Train Loss: 95.1908\n",
      "4247.79719543457\n",
      "Epoch [33/50], Batch 42/120, Train Loss: 88.3633\n",
      "4339.8165283203125\n",
      "Epoch [33/50], Batch 43/120, Train Loss: 92.0193\n",
      "4449.067291259766\n",
      "Epoch [33/50], Batch 44/120, Train Loss: 109.2508\n",
      "4563.362243652344\n",
      "Epoch [33/50], Batch 45/120, Train Loss: 114.2950\n",
      "4677.916297912598\n",
      "Epoch [33/50], Batch 46/120, Train Loss: 114.5541\n",
      "4785.846778869629\n",
      "Epoch [33/50], Batch 47/120, Train Loss: 107.9305\n",
      "4860.321495056152\n",
      "Epoch [33/50], Batch 48/120, Train Loss: 74.4747\n",
      "4946.574073791504\n",
      "Epoch [33/50], Batch 49/120, Train Loss: 86.2526\n",
      "5033.326393127441\n",
      "Epoch [33/50], Batch 50/120, Train Loss: 86.7523\n",
      "5125.395286560059\n",
      "Epoch [33/50], Batch 51/120, Train Loss: 92.0689\n",
      "5228.636047363281\n",
      "Epoch [33/50], Batch 52/120, Train Loss: 103.2408\n",
      "5316.263977050781\n",
      "Epoch [33/50], Batch 53/120, Train Loss: 87.6279\n",
      "5424.311782836914\n",
      "Epoch [33/50], Batch 54/120, Train Loss: 108.0478\n",
      "5517.261894226074\n",
      "Epoch [33/50], Batch 55/120, Train Loss: 92.9501\n",
      "5622.87459564209\n",
      "Epoch [33/50], Batch 56/120, Train Loss: 105.6127\n",
      "5706.092620849609\n",
      "Epoch [33/50], Batch 57/120, Train Loss: 83.2180\n",
      "5807.238357543945\n",
      "Epoch [33/50], Batch 58/120, Train Loss: 101.1457\n",
      "5898.82112121582\n",
      "Epoch [33/50], Batch 59/120, Train Loss: 91.5828\n",
      "6011.522148132324\n",
      "Epoch [33/50], Batch 60/120, Train Loss: 112.7010\n",
      "6106.713088989258\n",
      "Epoch [33/50], Batch 61/120, Train Loss: 95.1909\n",
      "6188.625701904297\n",
      "Epoch [33/50], Batch 62/120, Train Loss: 81.9126\n",
      "6286.333953857422\n",
      "Epoch [33/50], Batch 63/120, Train Loss: 97.7083\n",
      "6379.018539428711\n",
      "Epoch [33/50], Batch 64/120, Train Loss: 92.6846\n",
      "6494.158309936523\n",
      "Epoch [33/50], Batch 65/120, Train Loss: 115.1398\n",
      "6602.77783203125\n",
      "Epoch [33/50], Batch 66/120, Train Loss: 108.6195\n",
      "6707.565582275391\n",
      "Epoch [33/50], Batch 67/120, Train Loss: 104.7878\n",
      "6804.83561706543\n",
      "Epoch [33/50], Batch 68/120, Train Loss: 97.2700\n",
      "6878.294776916504\n",
      "Epoch [33/50], Batch 69/120, Train Loss: 73.4592\n",
      "6974.448692321777\n",
      "Epoch [33/50], Batch 70/120, Train Loss: 96.1539\n",
      "7063.605766296387\n",
      "Epoch [33/50], Batch 71/120, Train Loss: 89.1571\n",
      "7177.112663269043\n",
      "Epoch [33/50], Batch 72/120, Train Loss: 113.5069\n",
      "7280.645690917969\n",
      "Epoch [33/50], Batch 73/120, Train Loss: 103.5330\n",
      "7383.8662109375\n",
      "Epoch [33/50], Batch 74/120, Train Loss: 103.2205\n",
      "7468.534370422363\n",
      "Epoch [33/50], Batch 75/120, Train Loss: 84.6682\n",
      "7560.09895324707\n",
      "Epoch [33/50], Batch 76/120, Train Loss: 91.5646\n",
      "7657.8120193481445\n",
      "Epoch [33/50], Batch 77/120, Train Loss: 97.7131\n",
      "7782.691093444824\n",
      "Epoch [33/50], Batch 78/120, Train Loss: 124.8791\n",
      "7894.521812438965\n",
      "Epoch [33/50], Batch 79/120, Train Loss: 111.8307\n",
      "8012.17911529541\n",
      "Epoch [33/50], Batch 80/120, Train Loss: 117.6573\n",
      "8117.7274169921875\n",
      "Epoch [33/50], Batch 81/120, Train Loss: 105.5483\n",
      "8205.238067626953\n",
      "Epoch [33/50], Batch 82/120, Train Loss: 87.5107\n",
      "8286.964706420898\n",
      "Epoch [33/50], Batch 83/120, Train Loss: 81.7266\n",
      "8394.94418334961\n",
      "Epoch [33/50], Batch 84/120, Train Loss: 107.9795\n",
      "8476.697326660156\n",
      "Epoch [33/50], Batch 85/120, Train Loss: 81.7531\n",
      "8586.511169433594\n",
      "Epoch [33/50], Batch 86/120, Train Loss: 109.8138\n",
      "8692.497833251953\n",
      "Epoch [33/50], Batch 87/120, Train Loss: 105.9867\n",
      "8797.671127319336\n",
      "Epoch [33/50], Batch 88/120, Train Loss: 105.1733\n",
      "8888.043472290039\n",
      "Epoch [33/50], Batch 89/120, Train Loss: 90.3723\n",
      "9033.420989990234\n",
      "Epoch [33/50], Batch 90/120, Train Loss: 145.3775\n",
      "9097.46792602539\n",
      "Epoch [33/50], Batch 91/120, Train Loss: 64.0469\n",
      "9197.240783691406\n",
      "Epoch [33/50], Batch 92/120, Train Loss: 99.7729\n",
      "9307.715225219727\n",
      "Epoch [33/50], Batch 93/120, Train Loss: 110.4744\n",
      "9378.465423583984\n",
      "Epoch [33/50], Batch 94/120, Train Loss: 70.7502\n",
      "9487.225143432617\n",
      "Epoch [33/50], Batch 95/120, Train Loss: 108.7597\n",
      "9574.78352355957\n",
      "Epoch [33/50], Batch 96/120, Train Loss: 87.5584\n",
      "9663.961837768555\n",
      "Epoch [33/50], Batch 97/120, Train Loss: 89.1783\n",
      "9754.614288330078\n",
      "Epoch [33/50], Batch 98/120, Train Loss: 90.6525\n",
      "9852.968139648438\n",
      "Epoch [33/50], Batch 99/120, Train Loss: 98.3539\n",
      "9964.766342163086\n",
      "Epoch [33/50], Batch 100/120, Train Loss: 111.7982\n",
      "10068.478515625\n",
      "Epoch [33/50], Batch 101/120, Train Loss: 103.7122\n",
      "10172.597007751465\n",
      "Epoch [33/50], Batch 102/120, Train Loss: 104.1185\n",
      "10265.402565002441\n",
      "Epoch [33/50], Batch 103/120, Train Loss: 92.8056\n",
      "10381.7138671875\n",
      "Epoch [33/50], Batch 104/120, Train Loss: 116.3113\n",
      "10456.362586975098\n",
      "Epoch [33/50], Batch 105/120, Train Loss: 74.6487\n",
      "10544.035469055176\n",
      "Epoch [33/50], Batch 106/120, Train Loss: 87.6729\n",
      "10639.17896270752\n",
      "Epoch [33/50], Batch 107/120, Train Loss: 95.1435\n",
      "10735.910247802734\n",
      "Epoch [33/50], Batch 108/120, Train Loss: 96.7313\n",
      "10828.522018432617\n",
      "Epoch [33/50], Batch 109/120, Train Loss: 92.6118\n",
      "10947.355285644531\n",
      "Epoch [33/50], Batch 110/120, Train Loss: 118.8333\n",
      "11055.671768188477\n",
      "Epoch [33/50], Batch 111/120, Train Loss: 108.3165\n",
      "11167.343185424805\n",
      "Epoch [33/50], Batch 112/120, Train Loss: 111.6714\n",
      "11258.051956176758\n",
      "Epoch [33/50], Batch 113/120, Train Loss: 90.7088\n",
      "11365.770126342773\n",
      "Epoch [33/50], Batch 114/120, Train Loss: 107.7182\n",
      "11468.740882873535\n",
      "Epoch [33/50], Batch 115/120, Train Loss: 102.9708\n",
      "11564.144981384277\n",
      "Epoch [33/50], Batch 116/120, Train Loss: 95.4041\n",
      "11678.683082580566\n",
      "Epoch [33/50], Batch 117/120, Train Loss: 114.5381\n",
      "11788.111045837402\n",
      "Epoch [33/50], Batch 118/120, Train Loss: 109.4280\n",
      "11885.080490112305\n",
      "Epoch [33/50], Batch 119/120, Train Loss: 96.9694\n",
      "11975.25210571289\n",
      "Epoch [33/50], Batch 120/120, Train Loss: 90.1716\n",
      "Epoch [33/50], Train Loss: 99.7938, Validation Loss: 114.4478\n",
      "110.83468627929688\n",
      "Epoch [34/50], Batch 1/120, Train Loss: 110.8347\n",
      "216.1824188232422\n",
      "Epoch [34/50], Batch 2/120, Train Loss: 105.3477\n",
      "288.73297119140625\n",
      "Epoch [34/50], Batch 3/120, Train Loss: 72.5506\n",
      "371.6824035644531\n",
      "Epoch [34/50], Batch 4/120, Train Loss: 82.9494\n",
      "478.95433044433594\n",
      "Epoch [34/50], Batch 5/120, Train Loss: 107.2719\n",
      "584.373779296875\n",
      "Epoch [34/50], Batch 6/120, Train Loss: 105.4194\n",
      "702.165657043457\n",
      "Epoch [34/50], Batch 7/120, Train Loss: 117.7919\n",
      "780.609977722168\n",
      "Epoch [34/50], Batch 8/120, Train Loss: 78.4443\n",
      "861.2499160766602\n",
      "Epoch [34/50], Batch 9/120, Train Loss: 80.6399\n",
      "970.5378265380859\n",
      "Epoch [34/50], Batch 10/120, Train Loss: 109.2879\n",
      "1055.9617004394531\n",
      "Epoch [34/50], Batch 11/120, Train Loss: 85.4239\n",
      "1177.7925872802734\n",
      "Epoch [34/50], Batch 12/120, Train Loss: 121.8309\n",
      "1265.5866088867188\n",
      "Epoch [34/50], Batch 13/120, Train Loss: 87.7940\n",
      "1364.6765899658203\n",
      "Epoch [34/50], Batch 14/120, Train Loss: 99.0900\n",
      "1451.5815734863281\n",
      "Epoch [34/50], Batch 15/120, Train Loss: 86.9050\n",
      "1531.4066314697266\n",
      "Epoch [34/50], Batch 16/120, Train Loss: 79.8251\n",
      "1639.5513153076172\n",
      "Epoch [34/50], Batch 17/120, Train Loss: 108.1447\n",
      "1728.131607055664\n",
      "Epoch [34/50], Batch 18/120, Train Loss: 88.5803\n",
      "1843.1979598999023\n",
      "Epoch [34/50], Batch 19/120, Train Loss: 115.0664\n",
      "1943.5680541992188\n",
      "Epoch [34/50], Batch 20/120, Train Loss: 100.3701\n",
      "2028.791748046875\n",
      "Epoch [34/50], Batch 21/120, Train Loss: 85.2237\n",
      "2143.871894836426\n",
      "Epoch [34/50], Batch 22/120, Train Loss: 115.0801\n",
      "2256.186882019043\n",
      "Epoch [34/50], Batch 23/120, Train Loss: 112.3150\n",
      "2370.090850830078\n",
      "Epoch [34/50], Batch 24/120, Train Loss: 113.9040\n",
      "2494.7084045410156\n",
      "Epoch [34/50], Batch 25/120, Train Loss: 124.6176\n",
      "2584.3420791625977\n",
      "Epoch [34/50], Batch 26/120, Train Loss: 89.6337\n",
      "2673.119270324707\n",
      "Epoch [34/50], Batch 27/120, Train Loss: 88.7772\n",
      "2779.6111068725586\n",
      "Epoch [34/50], Batch 28/120, Train Loss: 106.4918\n",
      "2862.814079284668\n",
      "Epoch [34/50], Batch 29/120, Train Loss: 83.2030\n",
      "2963.344551086426\n",
      "Epoch [34/50], Batch 30/120, Train Loss: 100.5305\n",
      "3075.589668273926\n",
      "Epoch [34/50], Batch 31/120, Train Loss: 112.2451\n",
      "3190.7320709228516\n",
      "Epoch [34/50], Batch 32/120, Train Loss: 115.1424\n",
      "3285.727020263672\n",
      "Epoch [34/50], Batch 33/120, Train Loss: 94.9949\n",
      "3429.4768981933594\n",
      "Epoch [34/50], Batch 34/120, Train Loss: 143.7499\n",
      "3525.886764526367\n",
      "Epoch [34/50], Batch 35/120, Train Loss: 96.4099\n",
      "3600.5849075317383\n",
      "Epoch [34/50], Batch 36/120, Train Loss: 74.6981\n",
      "3675.822624206543\n",
      "Epoch [34/50], Batch 37/120, Train Loss: 75.2377\n",
      "3766.158348083496\n",
      "Epoch [34/50], Batch 38/120, Train Loss: 90.3357\n",
      "3872.0293045043945\n",
      "Epoch [34/50], Batch 39/120, Train Loss: 105.8710\n",
      "3953.012565612793\n",
      "Epoch [34/50], Batch 40/120, Train Loss: 80.9833\n",
      "4066.0524673461914\n",
      "Epoch [34/50], Batch 41/120, Train Loss: 113.0399\n",
      "4165.163368225098\n",
      "Epoch [34/50], Batch 42/120, Train Loss: 99.1109\n",
      "4255.229515075684\n",
      "Epoch [34/50], Batch 43/120, Train Loss: 90.0661\n",
      "4356.672645568848\n",
      "Epoch [34/50], Batch 44/120, Train Loss: 101.4431\n",
      "4449.054229736328\n",
      "Epoch [34/50], Batch 45/120, Train Loss: 92.3816\n",
      "4550.827133178711\n",
      "Epoch [34/50], Batch 46/120, Train Loss: 101.7729\n",
      "4660.404449462891\n",
      "Epoch [34/50], Batch 47/120, Train Loss: 109.5773\n",
      "4772.217178344727\n",
      "Epoch [34/50], Batch 48/120, Train Loss: 111.8127\n",
      "4865.04118347168\n",
      "Epoch [34/50], Batch 49/120, Train Loss: 92.8240\n",
      "4992.705696105957\n",
      "Epoch [34/50], Batch 50/120, Train Loss: 127.6645\n",
      "5106.1596755981445\n",
      "Epoch [34/50], Batch 51/120, Train Loss: 113.4540\n",
      "5198.588066101074\n",
      "Epoch [34/50], Batch 52/120, Train Loss: 92.4284\n",
      "5312.040260314941\n",
      "Epoch [34/50], Batch 53/120, Train Loss: 113.4522\n",
      "5390.645645141602\n",
      "Epoch [34/50], Batch 54/120, Train Loss: 78.6054\n",
      "5490.242568969727\n",
      "Epoch [34/50], Batch 55/120, Train Loss: 99.5969\n",
      "5575.753799438477\n",
      "Epoch [34/50], Batch 56/120, Train Loss: 85.5112\n",
      "5673.613746643066\n",
      "Epoch [34/50], Batch 57/120, Train Loss: 97.8599\n",
      "5762.371253967285\n",
      "Epoch [34/50], Batch 58/120, Train Loss: 88.7575\n",
      "5848.8736572265625\n",
      "Epoch [34/50], Batch 59/120, Train Loss: 86.5024\n",
      "5944.15478515625\n",
      "Epoch [34/50], Batch 60/120, Train Loss: 95.2811\n",
      "6065.207138061523\n",
      "Epoch [34/50], Batch 61/120, Train Loss: 121.0524\n",
      "6158.457916259766\n",
      "Epoch [34/50], Batch 62/120, Train Loss: 93.2508\n",
      "6246.425506591797\n",
      "Epoch [34/50], Batch 63/120, Train Loss: 87.9676\n",
      "6336.515266418457\n",
      "Epoch [34/50], Batch 64/120, Train Loss: 90.0898\n",
      "6408.29842376709\n",
      "Epoch [34/50], Batch 65/120, Train Loss: 71.7832\n",
      "6495.219047546387\n",
      "Epoch [34/50], Batch 66/120, Train Loss: 86.9206\n",
      "6578.938438415527\n",
      "Epoch [34/50], Batch 67/120, Train Loss: 83.7194\n",
      "6660.826622009277\n",
      "Epoch [34/50], Batch 68/120, Train Loss: 81.8882\n",
      "6775.751045227051\n",
      "Epoch [34/50], Batch 69/120, Train Loss: 114.9244\n",
      "6894.615905761719\n",
      "Epoch [34/50], Batch 70/120, Train Loss: 118.8649\n",
      "7000.541793823242\n",
      "Epoch [34/50], Batch 71/120, Train Loss: 105.9259\n",
      "7077.554153442383\n",
      "Epoch [34/50], Batch 72/120, Train Loss: 77.0124\n",
      "7189.201889038086\n",
      "Epoch [34/50], Batch 73/120, Train Loss: 111.6477\n",
      "7319.950973510742\n",
      "Epoch [34/50], Batch 74/120, Train Loss: 130.7491\n",
      "7422.189483642578\n",
      "Epoch [34/50], Batch 75/120, Train Loss: 102.2385\n",
      "7528.427810668945\n",
      "Epoch [34/50], Batch 76/120, Train Loss: 106.2383\n",
      "7638.673316955566\n",
      "Epoch [34/50], Batch 77/120, Train Loss: 110.2455\n",
      "7748.818687438965\n",
      "Epoch [34/50], Batch 78/120, Train Loss: 110.1454\n",
      "7829.711128234863\n",
      "Epoch [34/50], Batch 79/120, Train Loss: 80.8924\n",
      "7931.452049255371\n",
      "Epoch [34/50], Batch 80/120, Train Loss: 101.7409\n",
      "8015.6765213012695\n",
      "Epoch [34/50], Batch 81/120, Train Loss: 84.2245\n",
      "8123.980751037598\n",
      "Epoch [34/50], Batch 82/120, Train Loss: 108.3042\n",
      "8217.660301208496\n",
      "Epoch [34/50], Batch 83/120, Train Loss: 93.6796\n",
      "8317.792366027832\n",
      "Epoch [34/50], Batch 84/120, Train Loss: 100.1321\n",
      "8409.65991973877\n",
      "Epoch [34/50], Batch 85/120, Train Loss: 91.8676\n",
      "8535.844604492188\n",
      "Epoch [34/50], Batch 86/120, Train Loss: 126.1847\n",
      "8636.411949157715\n",
      "Epoch [34/50], Batch 87/120, Train Loss: 100.5673\n",
      "8730.53589630127\n",
      "Epoch [34/50], Batch 88/120, Train Loss: 94.1239\n",
      "8808.082649230957\n",
      "Epoch [34/50], Batch 89/120, Train Loss: 77.5468\n",
      "8906.768096923828\n",
      "Epoch [34/50], Batch 90/120, Train Loss: 98.6854\n",
      "9014.038391113281\n",
      "Epoch [34/50], Batch 91/120, Train Loss: 107.2703\n",
      "9114.862869262695\n",
      "Epoch [34/50], Batch 92/120, Train Loss: 100.8245\n",
      "9218.745162963867\n",
      "Epoch [34/50], Batch 93/120, Train Loss: 103.8823\n",
      "9312.440719604492\n",
      "Epoch [34/50], Batch 94/120, Train Loss: 93.6956\n",
      "9415.419303894043\n",
      "Epoch [34/50], Batch 95/120, Train Loss: 102.9786\n",
      "9507.7739944458\n",
      "Epoch [34/50], Batch 96/120, Train Loss: 92.3547\n",
      "9602.563026428223\n",
      "Epoch [34/50], Batch 97/120, Train Loss: 94.7890\n",
      "9706.954216003418\n",
      "Epoch [34/50], Batch 98/120, Train Loss: 104.3912\n",
      "9780.162109375\n",
      "Epoch [34/50], Batch 99/120, Train Loss: 73.2079\n",
      "9869.441276550293\n",
      "Epoch [34/50], Batch 100/120, Train Loss: 89.2792\n",
      "9981.945457458496\n",
      "Epoch [34/50], Batch 101/120, Train Loss: 112.5042\n",
      "10080.877754211426\n",
      "Epoch [34/50], Batch 102/120, Train Loss: 98.9323\n",
      "10179.238929748535\n",
      "Epoch [34/50], Batch 103/120, Train Loss: 98.3612\n",
      "10308.329078674316\n",
      "Epoch [34/50], Batch 104/120, Train Loss: 129.0901\n",
      "10393.958084106445\n",
      "Epoch [34/50], Batch 105/120, Train Loss: 85.6290\n",
      "10487.850982666016\n",
      "Epoch [34/50], Batch 106/120, Train Loss: 93.8929\n",
      "10575.769958496094\n",
      "Epoch [34/50], Batch 107/120, Train Loss: 87.9190\n",
      "10692.164031982422\n",
      "Epoch [34/50], Batch 108/120, Train Loss: 116.3941\n",
      "10795.724769592285\n",
      "Epoch [34/50], Batch 109/120, Train Loss: 103.5607\n",
      "10907.245491027832\n",
      "Epoch [34/50], Batch 110/120, Train Loss: 111.5207\n",
      "11003.783348083496\n",
      "Epoch [34/50], Batch 111/120, Train Loss: 96.5379\n",
      "11098.187889099121\n",
      "Epoch [34/50], Batch 112/120, Train Loss: 94.4045\n",
      "11204.927375793457\n",
      "Epoch [34/50], Batch 113/120, Train Loss: 106.7395\n",
      "11317.08325958252\n",
      "Epoch [34/50], Batch 114/120, Train Loss: 112.1559\n",
      "11404.953483581543\n",
      "Epoch [34/50], Batch 115/120, Train Loss: 87.8702\n",
      "11494.522727966309\n",
      "Epoch [34/50], Batch 116/120, Train Loss: 89.5692\n",
      "11598.508766174316\n",
      "Epoch [34/50], Batch 117/120, Train Loss: 103.9860\n",
      "11700.898399353027\n",
      "Epoch [34/50], Batch 118/120, Train Loss: 102.3896\n",
      "11775.060066223145\n",
      "Epoch [34/50], Batch 119/120, Train Loss: 74.1617\n",
      "11878.848487854004\n",
      "Epoch [34/50], Batch 120/120, Train Loss: 103.7884\n",
      "Epoch [34/50], Train Loss: 98.9904, Validation Loss: 113.2285\n",
      "110.95812225341797\n",
      "Epoch [35/50], Batch 1/120, Train Loss: 110.9581\n",
      "222.10964965820312\n",
      "Epoch [35/50], Batch 2/120, Train Loss: 111.1515\n",
      "337.0149612426758\n",
      "Epoch [35/50], Batch 3/120, Train Loss: 114.9053\n",
      "425.1672592163086\n",
      "Epoch [35/50], Batch 4/120, Train Loss: 88.1523\n",
      "519.6904678344727\n",
      "Epoch [35/50], Batch 5/120, Train Loss: 94.5232\n",
      "619.5716018676758\n",
      "Epoch [35/50], Batch 6/120, Train Loss: 99.8811\n",
      "745.6814880371094\n",
      "Epoch [35/50], Batch 7/120, Train Loss: 126.1099\n",
      "836.8940811157227\n",
      "Epoch [35/50], Batch 8/120, Train Loss: 91.2126\n",
      "944.1679229736328\n",
      "Epoch [35/50], Batch 9/120, Train Loss: 107.2738\n",
      "1068.405906677246\n",
      "Epoch [35/50], Batch 10/120, Train Loss: 124.2380\n",
      "1154.2973403930664\n",
      "Epoch [35/50], Batch 11/120, Train Loss: 85.8914\n",
      "1260.7153015136719\n",
      "Epoch [35/50], Batch 12/120, Train Loss: 106.4180\n",
      "1356.7588348388672\n",
      "Epoch [35/50], Batch 13/120, Train Loss: 96.0435\n",
      "1453.441276550293\n",
      "Epoch [35/50], Batch 14/120, Train Loss: 96.6824\n",
      "1532.759780883789\n",
      "Epoch [35/50], Batch 15/120, Train Loss: 79.3185\n",
      "1630.1741638183594\n",
      "Epoch [35/50], Batch 16/120, Train Loss: 97.4144\n",
      "1714.0388946533203\n",
      "Epoch [35/50], Batch 17/120, Train Loss: 83.8647\n",
      "1826.6447296142578\n",
      "Epoch [35/50], Batch 18/120, Train Loss: 112.6058\n",
      "1921.8233337402344\n",
      "Epoch [35/50], Batch 19/120, Train Loss: 95.1786\n",
      "2025.3860626220703\n",
      "Epoch [35/50], Batch 20/120, Train Loss: 103.5627\n",
      "2088.6716690063477\n",
      "Epoch [35/50], Batch 21/120, Train Loss: 63.2856\n",
      "2202.005195617676\n",
      "Epoch [35/50], Batch 22/120, Train Loss: 113.3335\n",
      "2303.887351989746\n",
      "Epoch [35/50], Batch 23/120, Train Loss: 101.8822\n",
      "2396.520309448242\n",
      "Epoch [35/50], Batch 24/120, Train Loss: 92.6330\n",
      "2497.415573120117\n",
      "Epoch [35/50], Batch 25/120, Train Loss: 100.8953\n",
      "2592.479537963867\n",
      "Epoch [35/50], Batch 26/120, Train Loss: 95.0640\n",
      "2687.388885498047\n",
      "Epoch [35/50], Batch 27/120, Train Loss: 94.9093\n",
      "2797.4715270996094\n",
      "Epoch [35/50], Batch 28/120, Train Loss: 110.0826\n",
      "2901.6703186035156\n",
      "Epoch [35/50], Batch 29/120, Train Loss: 104.1988\n",
      "3022.235641479492\n",
      "Epoch [35/50], Batch 30/120, Train Loss: 120.5653\n",
      "3139.3081970214844\n",
      "Epoch [35/50], Batch 31/120, Train Loss: 117.0726\n",
      "3249.152877807617\n",
      "Epoch [35/50], Batch 32/120, Train Loss: 109.8447\n",
      "3361.729263305664\n",
      "Epoch [35/50], Batch 33/120, Train Loss: 112.5764\n",
      "3465.3587799072266\n",
      "Epoch [35/50], Batch 34/120, Train Loss: 103.6295\n",
      "3566.61181640625\n",
      "Epoch [35/50], Batch 35/120, Train Loss: 101.2530\n",
      "3671.528938293457\n",
      "Epoch [35/50], Batch 36/120, Train Loss: 104.9171\n",
      "3778.9049072265625\n",
      "Epoch [35/50], Batch 37/120, Train Loss: 107.3760\n",
      "3876.0079193115234\n",
      "Epoch [35/50], Batch 38/120, Train Loss: 97.1030\n",
      "3993.8076553344727\n",
      "Epoch [35/50], Batch 39/120, Train Loss: 117.7997\n",
      "4106.545234680176\n",
      "Epoch [35/50], Batch 40/120, Train Loss: 112.7376\n",
      "4207.196922302246\n",
      "Epoch [35/50], Batch 41/120, Train Loss: 100.6517\n",
      "4283.612342834473\n",
      "Epoch [35/50], Batch 42/120, Train Loss: 76.4154\n",
      "4374.97127532959\n",
      "Epoch [35/50], Batch 43/120, Train Loss: 91.3589\n",
      "4464.310386657715\n",
      "Epoch [35/50], Batch 44/120, Train Loss: 89.3391\n",
      "4585.405952453613\n",
      "Epoch [35/50], Batch 45/120, Train Loss: 121.0956\n",
      "4681.536109924316\n",
      "Epoch [35/50], Batch 46/120, Train Loss: 96.1302\n",
      "4789.113990783691\n",
      "Epoch [35/50], Batch 47/120, Train Loss: 107.5779\n",
      "4897.540550231934\n",
      "Epoch [35/50], Batch 48/120, Train Loss: 108.4266\n",
      "5001.958366394043\n",
      "Epoch [35/50], Batch 49/120, Train Loss: 104.4178\n",
      "5103.373825073242\n",
      "Epoch [35/50], Batch 50/120, Train Loss: 101.4155\n",
      "5190.5554122924805\n",
      "Epoch [35/50], Batch 51/120, Train Loss: 87.1816\n",
      "5293.432304382324\n",
      "Epoch [35/50], Batch 52/120, Train Loss: 102.8769\n",
      "5397.604713439941\n",
      "Epoch [35/50], Batch 53/120, Train Loss: 104.1724\n",
      "5482.719093322754\n",
      "Epoch [35/50], Batch 54/120, Train Loss: 85.1144\n",
      "5543.624168395996\n",
      "Epoch [35/50], Batch 55/120, Train Loss: 60.9051\n",
      "5651.1949462890625\n",
      "Epoch [35/50], Batch 56/120, Train Loss: 107.5708\n",
      "5745.241027832031\n",
      "Epoch [35/50], Batch 57/120, Train Loss: 94.0461\n",
      "5865.972366333008\n",
      "Epoch [35/50], Batch 58/120, Train Loss: 120.7313\n",
      "5974.147232055664\n",
      "Epoch [35/50], Batch 59/120, Train Loss: 108.1749\n",
      "6075.94416809082\n",
      "Epoch [35/50], Batch 60/120, Train Loss: 101.7969\n",
      "6163.074012756348\n",
      "Epoch [35/50], Batch 61/120, Train Loss: 87.1298\n",
      "6251.029205322266\n",
      "Epoch [35/50], Batch 62/120, Train Loss: 87.9552\n",
      "6351.528259277344\n",
      "Epoch [35/50], Batch 63/120, Train Loss: 100.4991\n",
      "6448.04012298584\n",
      "Epoch [35/50], Batch 64/120, Train Loss: 96.5119\n",
      "6532.748023986816\n",
      "Epoch [35/50], Batch 65/120, Train Loss: 84.7079\n",
      "6617.895156860352\n",
      "Epoch [35/50], Batch 66/120, Train Loss: 85.1471\n",
      "6740.910484313965\n",
      "Epoch [35/50], Batch 67/120, Train Loss: 123.0153\n",
      "6845.481018066406\n",
      "Epoch [35/50], Batch 68/120, Train Loss: 104.5705\n",
      "6932.151962280273\n",
      "Epoch [35/50], Batch 69/120, Train Loss: 86.6709\n",
      "7029.692451477051\n",
      "Epoch [35/50], Batch 70/120, Train Loss: 97.5405\n",
      "7135.922149658203\n",
      "Epoch [35/50], Batch 71/120, Train Loss: 106.2297\n",
      "7254.345748901367\n",
      "Epoch [35/50], Batch 72/120, Train Loss: 118.4236\n",
      "7333.823913574219\n",
      "Epoch [35/50], Batch 73/120, Train Loss: 79.4782\n",
      "7438.515518188477\n",
      "Epoch [35/50], Batch 74/120, Train Loss: 104.6916\n",
      "7548.167877197266\n",
      "Epoch [35/50], Batch 75/120, Train Loss: 109.6524\n",
      "7650.154846191406\n",
      "Epoch [35/50], Batch 76/120, Train Loss: 101.9870\n",
      "7769.570030212402\n",
      "Epoch [35/50], Batch 77/120, Train Loss: 119.4152\n",
      "7859.224327087402\n",
      "Epoch [35/50], Batch 78/120, Train Loss: 89.6543\n",
      "7978.563194274902\n",
      "Epoch [35/50], Batch 79/120, Train Loss: 119.3389\n",
      "8062.390174865723\n",
      "Epoch [35/50], Batch 80/120, Train Loss: 83.8270\n",
      "8148.387001037598\n",
      "Epoch [35/50], Batch 81/120, Train Loss: 85.9968\n",
      "8229.214317321777\n",
      "Epoch [35/50], Batch 82/120, Train Loss: 80.8273\n",
      "8315.225105285645\n",
      "Epoch [35/50], Batch 83/120, Train Loss: 86.0108\n",
      "8393.908248901367\n",
      "Epoch [35/50], Batch 84/120, Train Loss: 78.6831\n",
      "8470.360595703125\n",
      "Epoch [35/50], Batch 85/120, Train Loss: 76.4523\n",
      "8582.726043701172\n",
      "Epoch [35/50], Batch 86/120, Train Loss: 112.3654\n",
      "8685.377883911133\n",
      "Epoch [35/50], Batch 87/120, Train Loss: 102.6518\n",
      "8763.611770629883\n",
      "Epoch [35/50], Batch 88/120, Train Loss: 78.2339\n",
      "8855.088829040527\n",
      "Epoch [35/50], Batch 89/120, Train Loss: 91.4771\n",
      "8954.53881072998\n",
      "Epoch [35/50], Batch 90/120, Train Loss: 99.4500\n",
      "9037.47248840332\n",
      "Epoch [35/50], Batch 91/120, Train Loss: 82.9337\n",
      "9122.437896728516\n",
      "Epoch [35/50], Batch 92/120, Train Loss: 84.9654\n",
      "9213.145156860352\n",
      "Epoch [35/50], Batch 93/120, Train Loss: 90.7073\n",
      "9333.475051879883\n",
      "Epoch [35/50], Batch 94/120, Train Loss: 120.3299\n",
      "9454.981986999512\n",
      "Epoch [35/50], Batch 95/120, Train Loss: 121.5069\n",
      "9569.637733459473\n",
      "Epoch [35/50], Batch 96/120, Train Loss: 114.6557\n",
      "9668.738662719727\n",
      "Epoch [35/50], Batch 97/120, Train Loss: 99.1009\n",
      "9779.60001373291\n",
      "Epoch [35/50], Batch 98/120, Train Loss: 110.8614\n",
      "9863.554069519043\n",
      "Epoch [35/50], Batch 99/120, Train Loss: 83.9541\n",
      "9957.490707397461\n",
      "Epoch [35/50], Batch 100/120, Train Loss: 93.9366\n",
      "10047.075408935547\n",
      "Epoch [35/50], Batch 101/120, Train Loss: 89.5847\n",
      "10169.10317993164\n",
      "Epoch [35/50], Batch 102/120, Train Loss: 122.0278\n",
      "10266.018585205078\n",
      "Epoch [35/50], Batch 103/120, Train Loss: 96.9154\n",
      "10364.369369506836\n",
      "Epoch [35/50], Batch 104/120, Train Loss: 98.3508\n",
      "10454.028022766113\n",
      "Epoch [35/50], Batch 105/120, Train Loss: 89.6587\n",
      "10541.544967651367\n",
      "Epoch [35/50], Batch 106/120, Train Loss: 87.5169\n",
      "10632.002799987793\n",
      "Epoch [35/50], Batch 107/120, Train Loss: 90.4578\n",
      "10721.141845703125\n",
      "Epoch [35/50], Batch 108/120, Train Loss: 89.1390\n",
      "10843.9829788208\n",
      "Epoch [35/50], Batch 109/120, Train Loss: 122.8411\n",
      "10938.989524841309\n",
      "Epoch [35/50], Batch 110/120, Train Loss: 95.0065\n",
      "11035.950325012207\n",
      "Epoch [35/50], Batch 111/120, Train Loss: 96.9608\n",
      "11119.347396850586\n",
      "Epoch [35/50], Batch 112/120, Train Loss: 83.3971\n",
      "11238.26333618164\n",
      "Epoch [35/50], Batch 113/120, Train Loss: 118.9159\n",
      "11355.09457397461\n",
      "Epoch [35/50], Batch 114/120, Train Loss: 116.8312\n",
      "11432.649032592773\n",
      "Epoch [35/50], Batch 115/120, Train Loss: 77.5545\n",
      "11522.277221679688\n",
      "Epoch [35/50], Batch 116/120, Train Loss: 89.6282\n",
      "11613.478393554688\n",
      "Epoch [35/50], Batch 117/120, Train Loss: 91.2012\n",
      "11699.019386291504\n",
      "Epoch [35/50], Batch 118/120, Train Loss: 85.5410\n",
      "11792.703132629395\n",
      "Epoch [35/50], Batch 119/120, Train Loss: 93.6837\n",
      "11904.703025817871\n",
      "Epoch [35/50], Batch 120/120, Train Loss: 111.9999\n",
      "Epoch [35/50], Train Loss: 99.2059, Validation Loss: 115.1546\n",
      "89.008056640625\n",
      "Epoch [36/50], Batch 1/120, Train Loss: 89.0081\n",
      "183.51531982421875\n",
      "Epoch [36/50], Batch 2/120, Train Loss: 94.5073\n",
      "278.96814727783203\n",
      "Epoch [36/50], Batch 3/120, Train Loss: 95.4528\n",
      "378.44152069091797\n",
      "Epoch [36/50], Batch 4/120, Train Loss: 99.4734\n",
      "470.8023681640625\n",
      "Epoch [36/50], Batch 5/120, Train Loss: 92.3608\n",
      "577.8299789428711\n",
      "Epoch [36/50], Batch 6/120, Train Loss: 107.0276\n",
      "713.6400375366211\n",
      "Epoch [36/50], Batch 7/120, Train Loss: 135.8101\n",
      "814.902946472168\n",
      "Epoch [36/50], Batch 8/120, Train Loss: 101.2629\n",
      "913.4266510009766\n",
      "Epoch [36/50], Batch 9/120, Train Loss: 98.5237\n",
      "996.4092712402344\n",
      "Epoch [36/50], Batch 10/120, Train Loss: 82.9826\n",
      "1105.5348510742188\n",
      "Epoch [36/50], Batch 11/120, Train Loss: 109.1256\n",
      "1221.6500701904297\n",
      "Epoch [36/50], Batch 12/120, Train Loss: 116.1152\n",
      "1316.4944915771484\n",
      "Epoch [36/50], Batch 13/120, Train Loss: 94.8444\n",
      "1414.1416931152344\n",
      "Epoch [36/50], Batch 14/120, Train Loss: 97.6472\n",
      "1516.8677368164062\n",
      "Epoch [36/50], Batch 15/120, Train Loss: 102.7260\n",
      "1603.2512512207031\n",
      "Epoch [36/50], Batch 16/120, Train Loss: 86.3835\n",
      "1698.2391510009766\n",
      "Epoch [36/50], Batch 17/120, Train Loss: 94.9879\n",
      "1791.3996505737305\n",
      "Epoch [36/50], Batch 18/120, Train Loss: 93.1605\n",
      "1891.933937072754\n",
      "Epoch [36/50], Batch 19/120, Train Loss: 100.5343\n",
      "1989.1057586669922\n",
      "Epoch [36/50], Batch 20/120, Train Loss: 97.1718\n",
      "2093.0984954833984\n",
      "Epoch [36/50], Batch 21/120, Train Loss: 103.9927\n",
      "2206.5078353881836\n",
      "Epoch [36/50], Batch 22/120, Train Loss: 113.4093\n",
      "2297.363380432129\n",
      "Epoch [36/50], Batch 23/120, Train Loss: 90.8555\n",
      "2390.3644790649414\n",
      "Epoch [36/50], Batch 24/120, Train Loss: 93.0011\n",
      "2488.8269805908203\n",
      "Epoch [36/50], Batch 25/120, Train Loss: 98.4625\n",
      "2615.304946899414\n",
      "Epoch [36/50], Batch 26/120, Train Loss: 126.4780\n",
      "2723.0217819213867\n",
      "Epoch [36/50], Batch 27/120, Train Loss: 107.7168\n",
      "2806.007148742676\n",
      "Epoch [36/50], Batch 28/120, Train Loss: 82.9854\n",
      "2912.412239074707\n",
      "Epoch [36/50], Batch 29/120, Train Loss: 106.4051\n",
      "2990.4673614501953\n",
      "Epoch [36/50], Batch 30/120, Train Loss: 78.0551\n",
      "3081.491912841797\n",
      "Epoch [36/50], Batch 31/120, Train Loss: 91.0246\n",
      "3179.455795288086\n",
      "Epoch [36/50], Batch 32/120, Train Loss: 97.9639\n",
      "3282.87646484375\n",
      "Epoch [36/50], Batch 33/120, Train Loss: 103.4207\n",
      "3380.212844848633\n",
      "Epoch [36/50], Batch 34/120, Train Loss: 97.3364\n",
      "3484.9066162109375\n",
      "Epoch [36/50], Batch 35/120, Train Loss: 104.6938\n",
      "3584.036605834961\n",
      "Epoch [36/50], Batch 36/120, Train Loss: 99.1300\n",
      "3694.2612686157227\n",
      "Epoch [36/50], Batch 37/120, Train Loss: 110.2247\n",
      "3806.546562194824\n",
      "Epoch [36/50], Batch 38/120, Train Loss: 112.2853\n",
      "3897.0067825317383\n",
      "Epoch [36/50], Batch 39/120, Train Loss: 90.4602\n",
      "4009.5890045166016\n",
      "Epoch [36/50], Batch 40/120, Train Loss: 112.5822\n",
      "4093.673110961914\n",
      "Epoch [36/50], Batch 41/120, Train Loss: 84.0841\n",
      "4180.360481262207\n",
      "Epoch [36/50], Batch 42/120, Train Loss: 86.6874\n",
      "4272.533668518066\n",
      "Epoch [36/50], Batch 43/120, Train Loss: 92.1732\n",
      "4374.788841247559\n",
      "Epoch [36/50], Batch 44/120, Train Loss: 102.2552\n",
      "4463.394569396973\n",
      "Epoch [36/50], Batch 45/120, Train Loss: 88.6057\n",
      "4573.560081481934\n",
      "Epoch [36/50], Batch 46/120, Train Loss: 110.1655\n",
      "4686.115303039551\n",
      "Epoch [36/50], Batch 47/120, Train Loss: 112.5552\n",
      "4802.070152282715\n",
      "Epoch [36/50], Batch 48/120, Train Loss: 115.9548\n",
      "4880.027671813965\n",
      "Epoch [36/50], Batch 49/120, Train Loss: 77.9575\n",
      "4983.355537414551\n",
      "Epoch [36/50], Batch 50/120, Train Loss: 103.3279\n",
      "5084.499412536621\n",
      "Epoch [36/50], Batch 51/120, Train Loss: 101.1439\n",
      "5169.495986938477\n",
      "Epoch [36/50], Batch 52/120, Train Loss: 84.9966\n",
      "5277.005187988281\n",
      "Epoch [36/50], Batch 53/120, Train Loss: 107.5092\n",
      "5388.24853515625\n",
      "Epoch [36/50], Batch 54/120, Train Loss: 111.2433\n",
      "5513.621932983398\n",
      "Epoch [36/50], Batch 55/120, Train Loss: 125.3734\n",
      "5576.1699295043945\n",
      "Epoch [36/50], Batch 56/120, Train Loss: 62.5480\n",
      "5658.911659240723\n",
      "Epoch [36/50], Batch 57/120, Train Loss: 82.7417\n",
      "5757.694839477539\n",
      "Epoch [36/50], Batch 58/120, Train Loss: 98.7832\n",
      "5868.5877685546875\n",
      "Epoch [36/50], Batch 59/120, Train Loss: 110.8929\n",
      "5952.27571105957\n",
      "Epoch [36/50], Batch 60/120, Train Loss: 83.6879\n",
      "6064.706413269043\n",
      "Epoch [36/50], Batch 61/120, Train Loss: 112.4307\n",
      "6155.4692459106445\n",
      "Epoch [36/50], Batch 62/120, Train Loss: 90.7628\n",
      "6234.47038269043\n",
      "Epoch [36/50], Batch 63/120, Train Loss: 79.0011\n",
      "6346.255676269531\n",
      "Epoch [36/50], Batch 64/120, Train Loss: 111.7853\n",
      "6440.337989807129\n",
      "Epoch [36/50], Batch 65/120, Train Loss: 94.0823\n",
      "6557.722282409668\n",
      "Epoch [36/50], Batch 66/120, Train Loss: 117.3843\n",
      "6667.904487609863\n",
      "Epoch [36/50], Batch 67/120, Train Loss: 110.1822\n",
      "6765.892364501953\n",
      "Epoch [36/50], Batch 68/120, Train Loss: 97.9879\n",
      "6858.335350036621\n",
      "Epoch [36/50], Batch 69/120, Train Loss: 92.4430\n",
      "6940.150856018066\n",
      "Epoch [36/50], Batch 70/120, Train Loss: 81.8155\n",
      "7041.067344665527\n",
      "Epoch [36/50], Batch 71/120, Train Loss: 100.9165\n",
      "7159.016159057617\n",
      "Epoch [36/50], Batch 72/120, Train Loss: 117.9488\n",
      "7257.624465942383\n",
      "Epoch [36/50], Batch 73/120, Train Loss: 98.6083\n",
      "7354.8026123046875\n",
      "Epoch [36/50], Batch 74/120, Train Loss: 97.1781\n",
      "7461.294418334961\n",
      "Epoch [36/50], Batch 75/120, Train Loss: 106.4918\n",
      "7561.122894287109\n",
      "Epoch [36/50], Batch 76/120, Train Loss: 99.8285\n",
      "7639.819206237793\n",
      "Epoch [36/50], Batch 77/120, Train Loss: 78.6963\n",
      "7732.241233825684\n",
      "Epoch [36/50], Batch 78/120, Train Loss: 92.4220\n",
      "7825.596122741699\n",
      "Epoch [36/50], Batch 79/120, Train Loss: 93.3549\n",
      "7913.951042175293\n",
      "Epoch [36/50], Batch 80/120, Train Loss: 88.3549\n",
      "7996.131034851074\n",
      "Epoch [36/50], Batch 81/120, Train Loss: 82.1800\n",
      "8077.238334655762\n",
      "Epoch [36/50], Batch 82/120, Train Loss: 81.1073\n",
      "8176.344276428223\n",
      "Epoch [36/50], Batch 83/120, Train Loss: 99.1059\n",
      "8300.119499206543\n",
      "Epoch [36/50], Batch 84/120, Train Loss: 123.7752\n",
      "8387.35457611084\n",
      "Epoch [36/50], Batch 85/120, Train Loss: 87.2351\n",
      "8485.344627380371\n",
      "Epoch [36/50], Batch 86/120, Train Loss: 97.9901\n",
      "8570.12296295166\n",
      "Epoch [36/50], Batch 87/120, Train Loss: 84.7783\n",
      "8665.70417022705\n",
      "Epoch [36/50], Batch 88/120, Train Loss: 95.5812\n",
      "8802.981880187988\n",
      "Epoch [36/50], Batch 89/120, Train Loss: 137.2777\n",
      "8903.877647399902\n",
      "Epoch [36/50], Batch 90/120, Train Loss: 100.8958\n",
      "8985.124725341797\n",
      "Epoch [36/50], Batch 91/120, Train Loss: 81.2471\n",
      "9074.862831115723\n",
      "Epoch [36/50], Batch 92/120, Train Loss: 89.7381\n",
      "9185.450996398926\n",
      "Epoch [36/50], Batch 93/120, Train Loss: 110.5882\n",
      "9272.021141052246\n",
      "Epoch [36/50], Batch 94/120, Train Loss: 86.5701\n",
      "9367.998878479004\n",
      "Epoch [36/50], Batch 95/120, Train Loss: 95.9777\n",
      "9455.150787353516\n",
      "Epoch [36/50], Batch 96/120, Train Loss: 87.1519\n",
      "9548.67700958252\n",
      "Epoch [36/50], Batch 97/120, Train Loss: 93.5262\n",
      "9666.847557067871\n",
      "Epoch [36/50], Batch 98/120, Train Loss: 118.1705\n",
      "9739.137718200684\n",
      "Epoch [36/50], Batch 99/120, Train Loss: 72.2902\n",
      "9831.698463439941\n",
      "Epoch [36/50], Batch 100/120, Train Loss: 92.5607\n",
      "9924.767272949219\n",
      "Epoch [36/50], Batch 101/120, Train Loss: 93.0688\n",
      "10017.48957824707\n",
      "Epoch [36/50], Batch 102/120, Train Loss: 92.7223\n",
      "10143.199165344238\n",
      "Epoch [36/50], Batch 103/120, Train Loss: 125.7096\n",
      "10254.132865905762\n",
      "Epoch [36/50], Batch 104/120, Train Loss: 110.9337\n",
      "10358.733116149902\n",
      "Epoch [36/50], Batch 105/120, Train Loss: 104.6003\n",
      "10454.672996520996\n",
      "Epoch [36/50], Batch 106/120, Train Loss: 95.9399\n",
      "10550.5132522583\n",
      "Epoch [36/50], Batch 107/120, Train Loss: 95.8403\n",
      "10642.763221740723\n",
      "Epoch [36/50], Batch 108/120, Train Loss: 92.2500\n",
      "10739.893394470215\n",
      "Epoch [36/50], Batch 109/120, Train Loss: 97.1302\n",
      "10823.948524475098\n",
      "Epoch [36/50], Batch 110/120, Train Loss: 84.0551\n",
      "10906.628364562988\n",
      "Epoch [36/50], Batch 111/120, Train Loss: 82.6798\n",
      "10999.166000366211\n",
      "Epoch [36/50], Batch 112/120, Train Loss: 92.5376\n",
      "11097.708801269531\n",
      "Epoch [36/50], Batch 113/120, Train Loss: 98.5428\n",
      "11220.288177490234\n",
      "Epoch [36/50], Batch 114/120, Train Loss: 122.5794\n",
      "11310.555679321289\n",
      "Epoch [36/50], Batch 115/120, Train Loss: 90.2675\n",
      "11403.05941772461\n",
      "Epoch [36/50], Batch 116/120, Train Loss: 92.5037\n",
      "11512.536254882812\n",
      "Epoch [36/50], Batch 117/120, Train Loss: 109.4768\n",
      "11601.36328125\n",
      "Epoch [36/50], Batch 118/120, Train Loss: 88.8270\n",
      "11698.658027648926\n",
      "Epoch [36/50], Batch 119/120, Train Loss: 97.2947\n",
      "11815.853736877441\n",
      "Epoch [36/50], Batch 120/120, Train Loss: 117.1957\n",
      "Epoch [36/50], Train Loss: 98.4654, Validation Loss: 114.0302\n",
      "94.95587158203125\n",
      "Epoch [37/50], Batch 1/120, Train Loss: 94.9559\n",
      "201.07847595214844\n",
      "Epoch [37/50], Batch 2/120, Train Loss: 106.1226\n",
      "304.43414306640625\n",
      "Epoch [37/50], Batch 3/120, Train Loss: 103.3557\n",
      "408.95704650878906\n",
      "Epoch [37/50], Batch 4/120, Train Loss: 104.5229\n",
      "535.4665603637695\n",
      "Epoch [37/50], Batch 5/120, Train Loss: 126.5095\n",
      "609.8908081054688\n",
      "Epoch [37/50], Batch 6/120, Train Loss: 74.4242\n",
      "720.9447402954102\n",
      "Epoch [37/50], Batch 7/120, Train Loss: 111.0539\n",
      "827.1411666870117\n",
      "Epoch [37/50], Batch 8/120, Train Loss: 106.1964\n",
      "936.1078948974609\n",
      "Epoch [37/50], Batch 9/120, Train Loss: 108.9667\n",
      "1033.0922927856445\n",
      "Epoch [37/50], Batch 10/120, Train Loss: 96.9844\n",
      "1137.4916458129883\n",
      "Epoch [37/50], Batch 11/120, Train Loss: 104.3994\n",
      "1223.0133819580078\n",
      "Epoch [37/50], Batch 12/120, Train Loss: 85.5217\n",
      "1325.9653625488281\n",
      "Epoch [37/50], Batch 13/120, Train Loss: 102.9520\n",
      "1432.0173873901367\n",
      "Epoch [37/50], Batch 14/120, Train Loss: 106.0520\n",
      "1532.3963470458984\n",
      "Epoch [37/50], Batch 15/120, Train Loss: 100.3790\n",
      "1647.8846054077148\n",
      "Epoch [37/50], Batch 16/120, Train Loss: 115.4883\n",
      "1751.387596130371\n",
      "Epoch [37/50], Batch 17/120, Train Loss: 103.5030\n",
      "1846.7917404174805\n",
      "Epoch [37/50], Batch 18/120, Train Loss: 95.4041\n",
      "1943.1418075561523\n",
      "Epoch [37/50], Batch 19/120, Train Loss: 96.3501\n",
      "2039.710350036621\n",
      "Epoch [37/50], Batch 20/120, Train Loss: 96.5685\n",
      "2135.725196838379\n",
      "Epoch [37/50], Batch 21/120, Train Loss: 96.0148\n",
      "2218.926933288574\n",
      "Epoch [37/50], Batch 22/120, Train Loss: 83.2017\n",
      "2280.9400939941406\n",
      "Epoch [37/50], Batch 23/120, Train Loss: 62.0132\n",
      "2393.7508850097656\n",
      "Epoch [37/50], Batch 24/120, Train Loss: 112.8108\n",
      "2487.664749145508\n",
      "Epoch [37/50], Batch 25/120, Train Loss: 93.9139\n",
      "2604.7230072021484\n",
      "Epoch [37/50], Batch 26/120, Train Loss: 117.0583\n",
      "2728.9051818847656\n",
      "Epoch [37/50], Batch 27/120, Train Loss: 124.1822\n",
      "2819.799850463867\n",
      "Epoch [37/50], Batch 28/120, Train Loss: 90.8947\n",
      "2924.842010498047\n",
      "Epoch [37/50], Batch 29/120, Train Loss: 105.0422\n",
      "3014.899642944336\n",
      "Epoch [37/50], Batch 30/120, Train Loss: 90.0576\n",
      "3093.0004119873047\n",
      "Epoch [37/50], Batch 31/120, Train Loss: 78.1008\n",
      "3193.824287414551\n",
      "Epoch [37/50], Batch 32/120, Train Loss: 100.8239\n",
      "3305.2588806152344\n",
      "Epoch [37/50], Batch 33/120, Train Loss: 111.4346\n",
      "3397.964797973633\n",
      "Epoch [37/50], Batch 34/120, Train Loss: 92.7059\n",
      "3504.534111022949\n",
      "Epoch [37/50], Batch 35/120, Train Loss: 106.5693\n",
      "3600.525062561035\n",
      "Epoch [37/50], Batch 36/120, Train Loss: 95.9910\n",
      "3696.6810760498047\n",
      "Epoch [37/50], Batch 37/120, Train Loss: 96.1560\n",
      "3781.905204772949\n",
      "Epoch [37/50], Batch 38/120, Train Loss: 85.2241\n",
      "3882.608444213867\n",
      "Epoch [37/50], Batch 39/120, Train Loss: 100.7032\n",
      "3983.51895904541\n",
      "Epoch [37/50], Batch 40/120, Train Loss: 100.9105\n",
      "4096.853157043457\n",
      "Epoch [37/50], Batch 41/120, Train Loss: 113.3342\n",
      "4186.238143920898\n",
      "Epoch [37/50], Batch 42/120, Train Loss: 89.3850\n",
      "4285.408050537109\n",
      "Epoch [37/50], Batch 43/120, Train Loss: 99.1699\n",
      "4410.454872131348\n",
      "Epoch [37/50], Batch 44/120, Train Loss: 125.0468\n",
      "4518.480278015137\n",
      "Epoch [37/50], Batch 45/120, Train Loss: 108.0254\n",
      "4609.167663574219\n",
      "Epoch [37/50], Batch 46/120, Train Loss: 90.6874\n",
      "4729.169616699219\n",
      "Epoch [37/50], Batch 47/120, Train Loss: 120.0020\n",
      "4815.578514099121\n",
      "Epoch [37/50], Batch 48/120, Train Loss: 86.4089\n",
      "4893.185768127441\n",
      "Epoch [37/50], Batch 49/120, Train Loss: 77.6073\n",
      "5001.934669494629\n",
      "Epoch [37/50], Batch 50/120, Train Loss: 108.7489\n",
      "5105.417152404785\n",
      "Epoch [37/50], Batch 51/120, Train Loss: 103.4825\n",
      "5218.41471862793\n",
      "Epoch [37/50], Batch 52/120, Train Loss: 112.9976\n",
      "5321.934066772461\n",
      "Epoch [37/50], Batch 53/120, Train Loss: 103.5193\n",
      "5417.374237060547\n",
      "Epoch [37/50], Batch 54/120, Train Loss: 95.4402\n",
      "5507.661529541016\n",
      "Epoch [37/50], Batch 55/120, Train Loss: 90.2873\n",
      "5628.503677368164\n",
      "Epoch [37/50], Batch 56/120, Train Loss: 120.8421\n",
      "5727.341682434082\n",
      "Epoch [37/50], Batch 57/120, Train Loss: 98.8380\n",
      "5810.563407897949\n",
      "Epoch [37/50], Batch 58/120, Train Loss: 83.2217\n",
      "5915.916351318359\n",
      "Epoch [37/50], Batch 59/120, Train Loss: 105.3529\n",
      "6003.998931884766\n",
      "Epoch [37/50], Batch 60/120, Train Loss: 88.0826\n",
      "6092.345321655273\n",
      "Epoch [37/50], Batch 61/120, Train Loss: 88.3464\n",
      "6198.21223449707\n",
      "Epoch [37/50], Batch 62/120, Train Loss: 105.8669\n",
      "6296.125564575195\n",
      "Epoch [37/50], Batch 63/120, Train Loss: 97.9133\n",
      "6392.678268432617\n",
      "Epoch [37/50], Batch 64/120, Train Loss: 96.5527\n",
      "6481.670928955078\n",
      "Epoch [37/50], Batch 65/120, Train Loss: 88.9927\n",
      "6569.371543884277\n",
      "Epoch [37/50], Batch 66/120, Train Loss: 87.7006\n",
      "6689.97989654541\n",
      "Epoch [37/50], Batch 67/120, Train Loss: 120.6084\n",
      "6786.467445373535\n",
      "Epoch [37/50], Batch 68/120, Train Loss: 96.4875\n",
      "6882.703025817871\n",
      "Epoch [37/50], Batch 69/120, Train Loss: 96.2356\n",
      "6983.6747970581055\n",
      "Epoch [37/50], Batch 70/120, Train Loss: 100.9718\n",
      "7077.0288162231445\n",
      "Epoch [37/50], Batch 71/120, Train Loss: 93.3540\n",
      "7189.714195251465\n",
      "Epoch [37/50], Batch 72/120, Train Loss: 112.6854\n",
      "7303.89266204834\n",
      "Epoch [37/50], Batch 73/120, Train Loss: 114.1785\n",
      "7405.408309936523\n",
      "Epoch [37/50], Batch 74/120, Train Loss: 101.5156\n",
      "7487.787940979004\n",
      "Epoch [37/50], Batch 75/120, Train Loss: 82.3796\n",
      "7602.126533508301\n",
      "Epoch [37/50], Batch 76/120, Train Loss: 114.3386\n",
      "7707.177940368652\n",
      "Epoch [37/50], Batch 77/120, Train Loss: 105.0514\n",
      "7794.713775634766\n",
      "Epoch [37/50], Batch 78/120, Train Loss: 87.5358\n",
      "7902.415756225586\n",
      "Epoch [37/50], Batch 79/120, Train Loss: 107.7020\n",
      "7997.608795166016\n",
      "Epoch [37/50], Batch 80/120, Train Loss: 95.1930\n",
      "8101.721145629883\n",
      "Epoch [37/50], Batch 81/120, Train Loss: 104.1124\n",
      "8199.514724731445\n",
      "Epoch [37/50], Batch 82/120, Train Loss: 97.7936\n",
      "8300.355270385742\n",
      "Epoch [37/50], Batch 83/120, Train Loss: 100.8405\n",
      "8381.520324707031\n",
      "Epoch [37/50], Batch 84/120, Train Loss: 81.1651\n",
      "8492.78970336914\n",
      "Epoch [37/50], Batch 85/120, Train Loss: 111.2694\n",
      "8580.857154846191\n",
      "Epoch [37/50], Batch 86/120, Train Loss: 88.0675\n",
      "8672.955513000488\n",
      "Epoch [37/50], Batch 87/120, Train Loss: 92.0984\n",
      "8769.333656311035\n",
      "Epoch [37/50], Batch 88/120, Train Loss: 96.3781\n",
      "8850.545501708984\n",
      "Epoch [37/50], Batch 89/120, Train Loss: 81.2118\n",
      "8945.657318115234\n",
      "Epoch [37/50], Batch 90/120, Train Loss: 95.1118\n",
      "9055.197677612305\n",
      "Epoch [37/50], Batch 91/120, Train Loss: 109.5404\n",
      "9141.711128234863\n",
      "Epoch [37/50], Batch 92/120, Train Loss: 86.5135\n",
      "9244.2290725708\n",
      "Epoch [37/50], Batch 93/120, Train Loss: 102.5179\n",
      "9337.439170837402\n",
      "Epoch [37/50], Batch 94/120, Train Loss: 93.2101\n",
      "9438.784080505371\n",
      "Epoch [37/50], Batch 95/120, Train Loss: 101.3449\n",
      "9548.356918334961\n",
      "Epoch [37/50], Batch 96/120, Train Loss: 109.5728\n",
      "9629.49917602539\n",
      "Epoch [37/50], Batch 97/120, Train Loss: 81.1423\n",
      "9712.740661621094\n",
      "Epoch [37/50], Batch 98/120, Train Loss: 83.2415\n",
      "9836.290588378906\n",
      "Epoch [37/50], Batch 99/120, Train Loss: 123.5499\n",
      "9945.952346801758\n",
      "Epoch [37/50], Batch 100/120, Train Loss: 109.6618\n",
      "10063.916534423828\n",
      "Epoch [37/50], Batch 101/120, Train Loss: 117.9642\n",
      "10149.046920776367\n",
      "Epoch [37/50], Batch 102/120, Train Loss: 85.1304\n",
      "10242.608810424805\n",
      "Epoch [37/50], Batch 103/120, Train Loss: 93.5619\n",
      "10351.436706542969\n",
      "Epoch [37/50], Batch 104/120, Train Loss: 108.8279\n",
      "10459.237609863281\n",
      "Epoch [37/50], Batch 105/120, Train Loss: 107.8009\n",
      "10543.159492492676\n",
      "Epoch [37/50], Batch 106/120, Train Loss: 83.9219\n",
      "10635.44223022461\n",
      "Epoch [37/50], Batch 107/120, Train Loss: 92.2827\n",
      "10717.879684448242\n",
      "Epoch [37/50], Batch 108/120, Train Loss: 82.4375\n",
      "10832.979782104492\n",
      "Epoch [37/50], Batch 109/120, Train Loss: 115.1001\n",
      "10934.834129333496\n",
      "Epoch [37/50], Batch 110/120, Train Loss: 101.8543\n",
      "11016.92455291748\n",
      "Epoch [37/50], Batch 111/120, Train Loss: 82.0904\n",
      "11130.611267089844\n",
      "Epoch [37/50], Batch 112/120, Train Loss: 113.6867\n",
      "11217.291694641113\n",
      "Epoch [37/50], Batch 113/120, Train Loss: 86.6804\n",
      "11290.221076965332\n",
      "Epoch [37/50], Batch 114/120, Train Loss: 72.9294\n",
      "11378.469383239746\n",
      "Epoch [37/50], Batch 115/120, Train Loss: 88.2483\n",
      "11470.594367980957\n",
      "Epoch [37/50], Batch 116/120, Train Loss: 92.1250\n",
      "11571.844032287598\n",
      "Epoch [37/50], Batch 117/120, Train Loss: 101.2497\n",
      "11680.65406036377\n",
      "Epoch [37/50], Batch 118/120, Train Loss: 108.8100\n",
      "11771.634773254395\n",
      "Epoch [37/50], Batch 119/120, Train Loss: 90.9807\n",
      "11887.872215270996\n",
      "Epoch [37/50], Batch 120/120, Train Loss: 116.2374\n",
      "Epoch [37/50], Train Loss: 99.0656, Validation Loss: 114.8489\n",
      "72.94705200195312\n",
      "Epoch [38/50], Batch 1/120, Train Loss: 72.9471\n",
      "171.46328735351562\n",
      "Epoch [38/50], Batch 2/120, Train Loss: 98.5162\n",
      "254.33438110351562\n",
      "Epoch [38/50], Batch 3/120, Train Loss: 82.8711\n",
      "366.4093017578125\n",
      "Epoch [38/50], Batch 4/120, Train Loss: 112.0749\n",
      "471.73992919921875\n",
      "Epoch [38/50], Batch 5/120, Train Loss: 105.3306\n",
      "566.9121246337891\n",
      "Epoch [38/50], Batch 6/120, Train Loss: 95.1722\n",
      "677.261474609375\n",
      "Epoch [38/50], Batch 7/120, Train Loss: 110.3493\n",
      "775.7130889892578\n",
      "Epoch [38/50], Batch 8/120, Train Loss: 98.4516\n",
      "871.8139953613281\n",
      "Epoch [38/50], Batch 9/120, Train Loss: 96.1009\n",
      "976.38623046875\n",
      "Epoch [38/50], Batch 10/120, Train Loss: 104.5722\n",
      "1048.540626525879\n",
      "Epoch [38/50], Batch 11/120, Train Loss: 72.1544\n",
      "1142.8480911254883\n",
      "Epoch [38/50], Batch 12/120, Train Loss: 94.3075\n",
      "1231.7579345703125\n",
      "Epoch [38/50], Batch 13/120, Train Loss: 88.9098\n",
      "1330.8041610717773\n",
      "Epoch [38/50], Batch 14/120, Train Loss: 99.0462\n",
      "1421.4765701293945\n",
      "Epoch [38/50], Batch 15/120, Train Loss: 90.6724\n",
      "1506.4344177246094\n",
      "Epoch [38/50], Batch 16/120, Train Loss: 84.9578\n",
      "1607.906509399414\n",
      "Epoch [38/50], Batch 17/120, Train Loss: 101.4721\n",
      "1693.8719787597656\n",
      "Epoch [38/50], Batch 18/120, Train Loss: 85.9655\n",
      "1877.1080017089844\n",
      "Epoch [38/50], Batch 19/120, Train Loss: 183.2360\n",
      "1975.6818389892578\n",
      "Epoch [38/50], Batch 20/120, Train Loss: 98.5738\n",
      "2070.825614929199\n",
      "Epoch [38/50], Batch 21/120, Train Loss: 95.1438\n",
      "2151.685516357422\n",
      "Epoch [38/50], Batch 22/120, Train Loss: 80.8599\n",
      "2262.1498641967773\n",
      "Epoch [38/50], Batch 23/120, Train Loss: 110.4643\n",
      "2351.946128845215\n",
      "Epoch [38/50], Batch 24/120, Train Loss: 89.7963\n",
      "2447.664863586426\n",
      "Epoch [38/50], Batch 25/120, Train Loss: 95.7187\n",
      "2554.2516555786133\n",
      "Epoch [38/50], Batch 26/120, Train Loss: 106.5868\n",
      "2671.772720336914\n",
      "Epoch [38/50], Batch 27/120, Train Loss: 117.5211\n",
      "2771.9721755981445\n",
      "Epoch [38/50], Batch 28/120, Train Loss: 100.1995\n",
      "2857.2300720214844\n",
      "Epoch [38/50], Batch 29/120, Train Loss: 85.2579\n",
      "2942.121353149414\n",
      "Epoch [38/50], Batch 30/120, Train Loss: 84.8913\n",
      "3046.5896530151367\n",
      "Epoch [38/50], Batch 31/120, Train Loss: 104.4683\n",
      "3150.4043350219727\n",
      "Epoch [38/50], Batch 32/120, Train Loss: 103.8147\n",
      "3244.098175048828\n",
      "Epoch [38/50], Batch 33/120, Train Loss: 93.6938\n",
      "3354.0706787109375\n",
      "Epoch [38/50], Batch 34/120, Train Loss: 109.9725\n",
      "3438.932098388672\n",
      "Epoch [38/50], Batch 35/120, Train Loss: 84.8614\n",
      "3555.622627258301\n",
      "Epoch [38/50], Batch 36/120, Train Loss: 116.6905\n",
      "3641.173027038574\n",
      "Epoch [38/50], Batch 37/120, Train Loss: 85.5504\n",
      "3744.6363830566406\n",
      "Epoch [38/50], Batch 38/120, Train Loss: 103.4634\n",
      "3813.0505905151367\n",
      "Epoch [38/50], Batch 39/120, Train Loss: 68.4142\n",
      "3904.176658630371\n",
      "Epoch [38/50], Batch 40/120, Train Loss: 91.1261\n",
      "3996.4228591918945\n",
      "Epoch [38/50], Batch 41/120, Train Loss: 92.2462\n",
      "4105.402870178223\n",
      "Epoch [38/50], Batch 42/120, Train Loss: 108.9800\n",
      "4237.780967712402\n",
      "Epoch [38/50], Batch 43/120, Train Loss: 132.3781\n",
      "4330.433769226074\n",
      "Epoch [38/50], Batch 44/120, Train Loss: 92.6528\n",
      "4440.632881164551\n",
      "Epoch [38/50], Batch 45/120, Train Loss: 110.1991\n",
      "4551.436714172363\n",
      "Epoch [38/50], Batch 46/120, Train Loss: 110.8038\n",
      "4653.938499450684\n",
      "Epoch [38/50], Batch 47/120, Train Loss: 102.5018\n",
      "4754.154716491699\n",
      "Epoch [38/50], Batch 48/120, Train Loss: 100.2162\n",
      "4831.118423461914\n",
      "Epoch [38/50], Batch 49/120, Train Loss: 76.9637\n",
      "4936.632957458496\n",
      "Epoch [38/50], Batch 50/120, Train Loss: 105.5145\n",
      "5024.709434509277\n",
      "Epoch [38/50], Batch 51/120, Train Loss: 88.0765\n",
      "5127.047981262207\n",
      "Epoch [38/50], Batch 52/120, Train Loss: 102.3385\n",
      "5211.598289489746\n",
      "Epoch [38/50], Batch 53/120, Train Loss: 84.5503\n",
      "5287.037055969238\n",
      "Epoch [38/50], Batch 54/120, Train Loss: 75.4388\n",
      "5375.340263366699\n",
      "Epoch [38/50], Batch 55/120, Train Loss: 88.3032\n",
      "5450.199668884277\n",
      "Epoch [38/50], Batch 56/120, Train Loss: 74.8594\n",
      "5545.954627990723\n",
      "Epoch [38/50], Batch 57/120, Train Loss: 95.7550\n",
      "5633.555397033691\n",
      "Epoch [38/50], Batch 58/120, Train Loss: 87.6008\n",
      "5729.791954040527\n",
      "Epoch [38/50], Batch 59/120, Train Loss: 96.2366\n",
      "5820.349281311035\n",
      "Epoch [38/50], Batch 60/120, Train Loss: 90.5573\n",
      "5922.216766357422\n",
      "Epoch [38/50], Batch 61/120, Train Loss: 101.8675\n",
      "6025.639755249023\n",
      "Epoch [38/50], Batch 62/120, Train Loss: 103.4230\n",
      "6129.334030151367\n",
      "Epoch [38/50], Batch 63/120, Train Loss: 103.6943\n",
      "6222.023254394531\n",
      "Epoch [38/50], Batch 64/120, Train Loss: 92.6892\n",
      "6341.391143798828\n",
      "Epoch [38/50], Batch 65/120, Train Loss: 119.3679\n",
      "6422.914207458496\n",
      "Epoch [38/50], Batch 66/120, Train Loss: 81.5231\n",
      "6511.176094055176\n",
      "Epoch [38/50], Batch 67/120, Train Loss: 88.2619\n",
      "6639.3645095825195\n",
      "Epoch [38/50], Batch 68/120, Train Loss: 128.1884\n",
      "6744.122032165527\n",
      "Epoch [38/50], Batch 69/120, Train Loss: 104.7575\n",
      "6837.6945877075195\n",
      "Epoch [38/50], Batch 70/120, Train Loss: 93.5726\n",
      "6948.0397872924805\n",
      "Epoch [38/50], Batch 71/120, Train Loss: 110.3452\n",
      "7025.5432052612305\n",
      "Epoch [38/50], Batch 72/120, Train Loss: 77.5034\n",
      "7124.120903015137\n",
      "Epoch [38/50], Batch 73/120, Train Loss: 98.5777\n",
      "7212.379096984863\n",
      "Epoch [38/50], Batch 74/120, Train Loss: 88.2582\n",
      "7301.133453369141\n",
      "Epoch [38/50], Batch 75/120, Train Loss: 88.7544\n",
      "7386.605743408203\n",
      "Epoch [38/50], Batch 76/120, Train Loss: 85.4723\n",
      "7469.862686157227\n",
      "Epoch [38/50], Batch 77/120, Train Loss: 83.2569\n",
      "7568.633529663086\n",
      "Epoch [38/50], Batch 78/120, Train Loss: 98.7708\n",
      "7660.059494018555\n",
      "Epoch [38/50], Batch 79/120, Train Loss: 91.4260\n",
      "7753.404884338379\n",
      "Epoch [38/50], Batch 80/120, Train Loss: 93.3454\n",
      "7850.270553588867\n",
      "Epoch [38/50], Batch 81/120, Train Loss: 96.8657\n",
      "7953.929428100586\n",
      "Epoch [38/50], Batch 82/120, Train Loss: 103.6589\n",
      "8038.399864196777\n",
      "Epoch [38/50], Batch 83/120, Train Loss: 84.4704\n",
      "8120.640228271484\n",
      "Epoch [38/50], Batch 84/120, Train Loss: 82.2404\n",
      "8208.39298248291\n",
      "Epoch [38/50], Batch 85/120, Train Loss: 87.7528\n",
      "8299.348197937012\n",
      "Epoch [38/50], Batch 86/120, Train Loss: 90.9552\n",
      "8392.276329040527\n",
      "Epoch [38/50], Batch 87/120, Train Loss: 92.9281\n",
      "8521.185539245605\n",
      "Epoch [38/50], Batch 88/120, Train Loss: 128.9092\n",
      "8620.987258911133\n",
      "Epoch [38/50], Batch 89/120, Train Loss: 99.8017\n",
      "8725.836517333984\n",
      "Epoch [38/50], Batch 90/120, Train Loss: 104.8493\n",
      "8818.272750854492\n",
      "Epoch [38/50], Batch 91/120, Train Loss: 92.4362\n",
      "8922.435287475586\n",
      "Epoch [38/50], Batch 92/120, Train Loss: 104.1625\n",
      "8999.636672973633\n",
      "Epoch [38/50], Batch 93/120, Train Loss: 77.2014\n",
      "9114.016082763672\n",
      "Epoch [38/50], Batch 94/120, Train Loss: 114.3794\n",
      "9233.725845336914\n",
      "Epoch [38/50], Batch 95/120, Train Loss: 119.7098\n",
      "9333.685432434082\n",
      "Epoch [38/50], Batch 96/120, Train Loss: 99.9596\n",
      "9441.057312011719\n",
      "Epoch [38/50], Batch 97/120, Train Loss: 107.3719\n",
      "9547.857177734375\n",
      "Epoch [38/50], Batch 98/120, Train Loss: 106.7999\n",
      "9655.433151245117\n",
      "Epoch [38/50], Batch 99/120, Train Loss: 107.5760\n",
      "9763.816131591797\n",
      "Epoch [38/50], Batch 100/120, Train Loss: 108.3830\n",
      "9873.92456817627\n",
      "Epoch [38/50], Batch 101/120, Train Loss: 110.1084\n",
      "9960.862297058105\n",
      "Epoch [38/50], Batch 102/120, Train Loss: 86.9377\n",
      "10050.609474182129\n",
      "Epoch [38/50], Batch 103/120, Train Loss: 89.7472\n",
      "10147.89501953125\n",
      "Epoch [38/50], Batch 104/120, Train Loss: 97.2855\n",
      "10248.856750488281\n",
      "Epoch [38/50], Batch 105/120, Train Loss: 100.9617\n",
      "10353.141830444336\n",
      "Epoch [38/50], Batch 106/120, Train Loss: 104.2851\n",
      "10442.152114868164\n",
      "Epoch [38/50], Batch 107/120, Train Loss: 89.0103\n",
      "10551.54248046875\n",
      "Epoch [38/50], Batch 108/120, Train Loss: 109.3904\n",
      "10651.258171081543\n",
      "Epoch [38/50], Batch 109/120, Train Loss: 99.7157\n",
      "10756.128433227539\n",
      "Epoch [38/50], Batch 110/120, Train Loss: 104.8703\n",
      "10839.057846069336\n",
      "Epoch [38/50], Batch 111/120, Train Loss: 82.9294\n",
      "10949.171783447266\n",
      "Epoch [38/50], Batch 112/120, Train Loss: 110.1139\n",
      "11053.87663269043\n",
      "Epoch [38/50], Batch 113/120, Train Loss: 104.7048\n",
      "11161.051254272461\n",
      "Epoch [38/50], Batch 114/120, Train Loss: 107.1746\n",
      "11270.083892822266\n",
      "Epoch [38/50], Batch 115/120, Train Loss: 109.0326\n",
      "11410.61801147461\n",
      "Epoch [38/50], Batch 116/120, Train Loss: 140.5341\n",
      "11504.1640625\n",
      "Epoch [38/50], Batch 117/120, Train Loss: 93.5461\n",
      "11589.69564819336\n",
      "Epoch [38/50], Batch 118/120, Train Loss: 85.5316\n",
      "11687.143348693848\n",
      "Epoch [38/50], Batch 119/120, Train Loss: 97.4477\n",
      "11776.761024475098\n",
      "Epoch [38/50], Batch 120/120, Train Loss: 89.6177\n",
      "Epoch [38/50], Train Loss: 98.1397, Validation Loss: 114.1820\n",
      "103.56488037109375\n",
      "Epoch [39/50], Batch 1/120, Train Loss: 103.5649\n",
      "209.0277099609375\n",
      "Epoch [39/50], Batch 2/120, Train Loss: 105.4628\n",
      "302.55445098876953\n",
      "Epoch [39/50], Batch 3/120, Train Loss: 93.5267\n",
      "405.54781341552734\n",
      "Epoch [39/50], Batch 4/120, Train Loss: 102.9934\n",
      "507.6922302246094\n",
      "Epoch [39/50], Batch 5/120, Train Loss: 102.1444\n",
      "610.1547393798828\n",
      "Epoch [39/50], Batch 6/120, Train Loss: 102.4625\n",
      "705.5589294433594\n",
      "Epoch [39/50], Batch 7/120, Train Loss: 95.4042\n",
      "810.897834777832\n",
      "Epoch [39/50], Batch 8/120, Train Loss: 105.3389\n",
      "902.6722793579102\n",
      "Epoch [39/50], Batch 9/120, Train Loss: 91.7744\n",
      "1001.6361923217773\n",
      "Epoch [39/50], Batch 10/120, Train Loss: 98.9639\n",
      "1106.8594360351562\n",
      "Epoch [39/50], Batch 11/120, Train Loss: 105.2232\n",
      "1200.0841827392578\n",
      "Epoch [39/50], Batch 12/120, Train Loss: 93.2247\n",
      "1290.2318878173828\n",
      "Epoch [39/50], Batch 13/120, Train Loss: 90.1477\n",
      "1358.6853408813477\n",
      "Epoch [39/50], Batch 14/120, Train Loss: 68.4535\n",
      "1456.5032119750977\n",
      "Epoch [39/50], Batch 15/120, Train Loss: 97.8179\n",
      "1548.675163269043\n",
      "Epoch [39/50], Batch 16/120, Train Loss: 92.1720\n",
      "1637.7277297973633\n",
      "Epoch [39/50], Batch 17/120, Train Loss: 89.0526\n",
      "1729.7537307739258\n",
      "Epoch [39/50], Batch 18/120, Train Loss: 92.0260\n",
      "1825.7969131469727\n",
      "Epoch [39/50], Batch 19/120, Train Loss: 96.0432\n",
      "1904.636474609375\n",
      "Epoch [39/50], Batch 20/120, Train Loss: 78.8396\n",
      "2012.1249923706055\n",
      "Epoch [39/50], Batch 21/120, Train Loss: 107.4885\n",
      "2100.6972045898438\n",
      "Epoch [39/50], Batch 22/120, Train Loss: 88.5722\n",
      "2196.805221557617\n",
      "Epoch [39/50], Batch 23/120, Train Loss: 96.1080\n",
      "2289.5923080444336\n",
      "Epoch [39/50], Batch 24/120, Train Loss: 92.7871\n",
      "2399.387809753418\n",
      "Epoch [39/50], Batch 25/120, Train Loss: 109.7955\n",
      "2509.257987976074\n",
      "Epoch [39/50], Batch 26/120, Train Loss: 109.8702\n",
      "2604.0423278808594\n",
      "Epoch [39/50], Batch 27/120, Train Loss: 94.7843\n",
      "2681.989471435547\n",
      "Epoch [39/50], Batch 28/120, Train Loss: 77.9471\n",
      "2785.8931884765625\n",
      "Epoch [39/50], Batch 29/120, Train Loss: 103.9037\n",
      "2864.7816162109375\n",
      "Epoch [39/50], Batch 30/120, Train Loss: 78.8884\n",
      "2970.592216491699\n",
      "Epoch [39/50], Batch 31/120, Train Loss: 105.8106\n",
      "3065.3173828125\n",
      "Epoch [39/50], Batch 32/120, Train Loss: 94.7252\n",
      "3176.3358612060547\n",
      "Epoch [39/50], Batch 33/120, Train Loss: 111.0185\n",
      "3279.46923828125\n",
      "Epoch [39/50], Batch 34/120, Train Loss: 103.1334\n",
      "3380.6185455322266\n",
      "Epoch [39/50], Batch 35/120, Train Loss: 101.1493\n",
      "3503.3797760009766\n",
      "Epoch [39/50], Batch 36/120, Train Loss: 122.7612\n",
      "3590.666961669922\n",
      "Epoch [39/50], Batch 37/120, Train Loss: 87.2872\n",
      "3696.159912109375\n",
      "Epoch [39/50], Batch 38/120, Train Loss: 105.4930\n",
      "3781.9703216552734\n",
      "Epoch [39/50], Batch 39/120, Train Loss: 85.8104\n",
      "3880.1895446777344\n",
      "Epoch [39/50], Batch 40/120, Train Loss: 98.2192\n",
      "3974.876449584961\n",
      "Epoch [39/50], Batch 41/120, Train Loss: 94.6869\n",
      "4072.160804748535\n",
      "Epoch [39/50], Batch 42/120, Train Loss: 97.2844\n",
      "4173.586967468262\n",
      "Epoch [39/50], Batch 43/120, Train Loss: 101.4262\n",
      "4265.398109436035\n",
      "Epoch [39/50], Batch 44/120, Train Loss: 91.8111\n",
      "4363.559196472168\n",
      "Epoch [39/50], Batch 45/120, Train Loss: 98.1611\n",
      "4474.201072692871\n",
      "Epoch [39/50], Batch 46/120, Train Loss: 110.6419\n",
      "4577.625617980957\n",
      "Epoch [39/50], Batch 47/120, Train Loss: 103.4245\n",
      "4692.4675216674805\n",
      "Epoch [39/50], Batch 48/120, Train Loss: 114.8419\n",
      "4782.55721282959\n",
      "Epoch [39/50], Batch 49/120, Train Loss: 90.0897\n",
      "4882.868667602539\n",
      "Epoch [39/50], Batch 50/120, Train Loss: 100.3115\n",
      "5005.624603271484\n",
      "Epoch [39/50], Batch 51/120, Train Loss: 122.7559\n",
      "5082.09700012207\n",
      "Epoch [39/50], Batch 52/120, Train Loss: 76.4724\n",
      "5176.788711547852\n",
      "Epoch [39/50], Batch 53/120, Train Loss: 94.6917\n",
      "5288.3549728393555\n",
      "Epoch [39/50], Batch 54/120, Train Loss: 111.5663\n",
      "5396.402908325195\n",
      "Epoch [39/50], Batch 55/120, Train Loss: 108.0479\n",
      "5499.6176681518555\n",
      "Epoch [39/50], Batch 56/120, Train Loss: 103.2148\n",
      "5597.9357833862305\n",
      "Epoch [39/50], Batch 57/120, Train Loss: 98.3181\n",
      "5717.756172180176\n",
      "Epoch [39/50], Batch 58/120, Train Loss: 119.8204\n",
      "5817.452919006348\n",
      "Epoch [39/50], Batch 59/120, Train Loss: 99.6967\n",
      "5925.165702819824\n",
      "Epoch [39/50], Batch 60/120, Train Loss: 107.7128\n",
      "6011.065780639648\n",
      "Epoch [39/50], Batch 61/120, Train Loss: 85.9001\n",
      "6115.912132263184\n",
      "Epoch [39/50], Batch 62/120, Train Loss: 104.8464\n",
      "6212.918197631836\n",
      "Epoch [39/50], Batch 63/120, Train Loss: 97.0061\n",
      "6303.1922607421875\n",
      "Epoch [39/50], Batch 64/120, Train Loss: 90.2741\n",
      "6423.837478637695\n",
      "Epoch [39/50], Batch 65/120, Train Loss: 120.6452\n",
      "6527.340789794922\n",
      "Epoch [39/50], Batch 66/120, Train Loss: 103.5033\n",
      "6621.811256408691\n",
      "Epoch [39/50], Batch 67/120, Train Loss: 94.4705\n",
      "6718.767890930176\n",
      "Epoch [39/50], Batch 68/120, Train Loss: 96.9566\n",
      "6818.4174728393555\n",
      "Epoch [39/50], Batch 69/120, Train Loss: 99.6496\n",
      "6908.367744445801\n",
      "Epoch [39/50], Batch 70/120, Train Loss: 89.9503\n",
      "7029.058631896973\n",
      "Epoch [39/50], Batch 71/120, Train Loss: 120.6909\n",
      "7111.37996673584\n",
      "Epoch [39/50], Batch 72/120, Train Loss: 82.3213\n",
      "7212.0319747924805\n",
      "Epoch [39/50], Batch 73/120, Train Loss: 100.6520\n",
      "7309.4172286987305\n",
      "Epoch [39/50], Batch 74/120, Train Loss: 97.3853\n",
      "7404.943046569824\n",
      "Epoch [39/50], Batch 75/120, Train Loss: 95.5258\n",
      "7510.690986633301\n",
      "Epoch [39/50], Batch 76/120, Train Loss: 105.7479\n",
      "7607.02596282959\n",
      "Epoch [39/50], Batch 77/120, Train Loss: 96.3350\n",
      "7681.940391540527\n",
      "Epoch [39/50], Batch 78/120, Train Loss: 74.9144\n",
      "7760.515312194824\n",
      "Epoch [39/50], Batch 79/120, Train Loss: 78.5749\n",
      "7876.633659362793\n",
      "Epoch [39/50], Batch 80/120, Train Loss: 116.1183\n",
      "7974.405120849609\n",
      "Epoch [39/50], Batch 81/120, Train Loss: 97.7715\n",
      "8080.290328979492\n",
      "Epoch [39/50], Batch 82/120, Train Loss: 105.8852\n",
      "8167.234397888184\n",
      "Epoch [39/50], Batch 83/120, Train Loss: 86.9441\n",
      "8273.077239990234\n",
      "Epoch [39/50], Batch 84/120, Train Loss: 105.8428\n",
      "8377.321990966797\n",
      "Epoch [39/50], Batch 85/120, Train Loss: 104.2448\n",
      "8487.980293273926\n",
      "Epoch [39/50], Batch 86/120, Train Loss: 110.6583\n",
      "8585.164070129395\n",
      "Epoch [39/50], Batch 87/120, Train Loss: 97.1838\n",
      "8692.481018066406\n",
      "Epoch [39/50], Batch 88/120, Train Loss: 107.3169\n",
      "8768.661529541016\n",
      "Epoch [39/50], Batch 89/120, Train Loss: 76.1805\n",
      "8860.242050170898\n",
      "Epoch [39/50], Batch 90/120, Train Loss: 91.5805\n",
      "8957.924835205078\n",
      "Epoch [39/50], Batch 91/120, Train Loss: 97.6828\n",
      "9039.310104370117\n",
      "Epoch [39/50], Batch 92/120, Train Loss: 81.3853\n",
      "9133.490264892578\n",
      "Epoch [39/50], Batch 93/120, Train Loss: 94.1802\n",
      "9236.653259277344\n",
      "Epoch [39/50], Batch 94/120, Train Loss: 103.1630\n",
      "9334.547256469727\n",
      "Epoch [39/50], Batch 95/120, Train Loss: 97.8940\n",
      "9436.28677368164\n",
      "Epoch [39/50], Batch 96/120, Train Loss: 101.7395\n",
      "9511.250015258789\n",
      "Epoch [39/50], Batch 97/120, Train Loss: 74.9632\n",
      "9632.12718963623\n",
      "Epoch [39/50], Batch 98/120, Train Loss: 120.8772\n",
      "9747.545440673828\n",
      "Epoch [39/50], Batch 99/120, Train Loss: 115.4183\n",
      "9852.136856079102\n",
      "Epoch [39/50], Batch 100/120, Train Loss: 104.5914\n",
      "9954.020500183105\n",
      "Epoch [39/50], Batch 101/120, Train Loss: 101.8836\n",
      "10031.301597595215\n",
      "Epoch [39/50], Batch 102/120, Train Loss: 77.2811\n",
      "10123.913436889648\n",
      "Epoch [39/50], Batch 103/120, Train Loss: 92.6118\n",
      "10195.051177978516\n",
      "Epoch [39/50], Batch 104/120, Train Loss: 71.1377\n",
      "10285.249404907227\n",
      "Epoch [39/50], Batch 105/120, Train Loss: 90.1982\n",
      "10371.728057861328\n",
      "Epoch [39/50], Batch 106/120, Train Loss: 86.4787\n",
      "10477.666473388672\n",
      "Epoch [39/50], Batch 107/120, Train Loss: 105.9384\n",
      "10585.721099853516\n",
      "Epoch [39/50], Batch 108/120, Train Loss: 108.0546\n",
      "10674.316375732422\n",
      "Epoch [39/50], Batch 109/120, Train Loss: 88.5953\n",
      "10778.354064941406\n",
      "Epoch [39/50], Batch 110/120, Train Loss: 104.0377\n",
      "10865.386291503906\n",
      "Epoch [39/50], Batch 111/120, Train Loss: 87.0322\n",
      "10948.582870483398\n",
      "Epoch [39/50], Batch 112/120, Train Loss: 83.1966\n",
      "11030.270706176758\n",
      "Epoch [39/50], Batch 113/120, Train Loss: 81.6878\n",
      "11148.278785705566\n",
      "Epoch [39/50], Batch 114/120, Train Loss: 118.0081\n",
      "11241.6494140625\n",
      "Epoch [39/50], Batch 115/120, Train Loss: 93.3706\n",
      "11330.243629455566\n",
      "Epoch [39/50], Batch 116/120, Train Loss: 88.5942\n",
      "11420.27481842041\n",
      "Epoch [39/50], Batch 117/120, Train Loss: 90.0312\n",
      "11512.157218933105\n",
      "Epoch [39/50], Batch 118/120, Train Loss: 91.8824\n",
      "11608.0791015625\n",
      "Epoch [39/50], Batch 119/120, Train Loss: 95.9219\n",
      "11684.390937805176\n",
      "Epoch [39/50], Batch 120/120, Train Loss: 76.3118\n",
      "Epoch [39/50], Train Loss: 97.3699, Validation Loss: 113.5604\n",
      "103.34013366699219\n",
      "Epoch [40/50], Batch 1/120, Train Loss: 103.3401\n",
      "206.61824798583984\n",
      "Epoch [40/50], Batch 2/120, Train Loss: 103.2781\n",
      "317.27532958984375\n",
      "Epoch [40/50], Batch 3/120, Train Loss: 110.6571\n",
      "407.0468978881836\n",
      "Epoch [40/50], Batch 4/120, Train Loss: 89.7716\n",
      "528.8808898925781\n",
      "Epoch [40/50], Batch 5/120, Train Loss: 121.8340\n",
      "632.8962707519531\n",
      "Epoch [40/50], Batch 6/120, Train Loss: 104.0154\n",
      "742.8844451904297\n",
      "Epoch [40/50], Batch 7/120, Train Loss: 109.9882\n",
      "850.7672653198242\n",
      "Epoch [40/50], Batch 8/120, Train Loss: 107.8828\n",
      "936.1433181762695\n",
      "Epoch [40/50], Batch 9/120, Train Loss: 85.3761\n",
      "1048.0056991577148\n",
      "Epoch [40/50], Batch 10/120, Train Loss: 111.8624\n",
      "1156.8758926391602\n",
      "Epoch [40/50], Batch 11/120, Train Loss: 108.8702\n",
      "1265.927017211914\n",
      "Epoch [40/50], Batch 12/120, Train Loss: 109.0511\n",
      "1362.1356506347656\n",
      "Epoch [40/50], Batch 13/120, Train Loss: 96.2086\n",
      "1492.4347381591797\n",
      "Epoch [40/50], Batch 14/120, Train Loss: 130.2991\n",
      "1602.762954711914\n",
      "Epoch [40/50], Batch 15/120, Train Loss: 110.3282\n",
      "1686.2162322998047\n",
      "Epoch [40/50], Batch 16/120, Train Loss: 83.4533\n",
      "1785.5023651123047\n",
      "Epoch [40/50], Batch 17/120, Train Loss: 99.2861\n",
      "1882.8975372314453\n",
      "Epoch [40/50], Batch 18/120, Train Loss: 97.3952\n",
      "1969.6710891723633\n",
      "Epoch [40/50], Batch 19/120, Train Loss: 86.7736\n",
      "2059.679054260254\n",
      "Epoch [40/50], Batch 20/120, Train Loss: 90.0080\n",
      "2164.311668395996\n",
      "Epoch [40/50], Batch 21/120, Train Loss: 104.6326\n",
      "2258.4605255126953\n",
      "Epoch [40/50], Batch 22/120, Train Loss: 94.1489\n",
      "2373.8212127685547\n",
      "Epoch [40/50], Batch 23/120, Train Loss: 115.3607\n",
      "2495.2185134887695\n",
      "Epoch [40/50], Batch 24/120, Train Loss: 121.3973\n",
      "2592.458106994629\n",
      "Epoch [40/50], Batch 25/120, Train Loss: 97.2396\n",
      "2694.4475479125977\n",
      "Epoch [40/50], Batch 26/120, Train Loss: 101.9894\n",
      "2790.103073120117\n",
      "Epoch [40/50], Batch 27/120, Train Loss: 95.6555\n",
      "2882.61279296875\n",
      "Epoch [40/50], Batch 28/120, Train Loss: 92.5097\n",
      "2990.703758239746\n",
      "Epoch [40/50], Batch 29/120, Train Loss: 108.0910\n",
      "3107.6469650268555\n",
      "Epoch [40/50], Batch 30/120, Train Loss: 116.9432\n",
      "3193.4377212524414\n",
      "Epoch [40/50], Batch 31/120, Train Loss: 85.7908\n",
      "3299.217971801758\n",
      "Epoch [40/50], Batch 32/120, Train Loss: 105.7803\n",
      "3376.177764892578\n",
      "Epoch [40/50], Batch 33/120, Train Loss: 76.9598\n",
      "3479.6448135375977\n",
      "Epoch [40/50], Batch 34/120, Train Loss: 103.4670\n",
      "3576.61678314209\n",
      "Epoch [40/50], Batch 35/120, Train Loss: 96.9720\n",
      "3675.419319152832\n",
      "Epoch [40/50], Batch 36/120, Train Loss: 98.8025\n",
      "3772.521614074707\n",
      "Epoch [40/50], Batch 37/120, Train Loss: 97.1023\n",
      "3885.424102783203\n",
      "Epoch [40/50], Batch 38/120, Train Loss: 112.9025\n",
      "3969.2978286743164\n",
      "Epoch [40/50], Batch 39/120, Train Loss: 83.8737\n",
      "4060.3610229492188\n",
      "Epoch [40/50], Batch 40/120, Train Loss: 91.0632\n",
      "4154.889839172363\n",
      "Epoch [40/50], Batch 41/120, Train Loss: 94.5288\n",
      "4266.463096618652\n",
      "Epoch [40/50], Batch 42/120, Train Loss: 111.5733\n",
      "4364.765022277832\n",
      "Epoch [40/50], Batch 43/120, Train Loss: 98.3019\n",
      "4469.661041259766\n",
      "Epoch [40/50], Batch 44/120, Train Loss: 104.8960\n",
      "4563.083648681641\n",
      "Epoch [40/50], Batch 45/120, Train Loss: 93.4226\n",
      "4645.531440734863\n",
      "Epoch [40/50], Batch 46/120, Train Loss: 82.4478\n",
      "4741.9580001831055\n",
      "Epoch [40/50], Batch 47/120, Train Loss: 96.4266\n",
      "4833.352027893066\n",
      "Epoch [40/50], Batch 48/120, Train Loss: 91.3940\n",
      "4937.346519470215\n",
      "Epoch [40/50], Batch 49/120, Train Loss: 103.9945\n",
      "5029.748237609863\n",
      "Epoch [40/50], Batch 50/120, Train Loss: 92.4017\n",
      "5135.576347351074\n",
      "Epoch [40/50], Batch 51/120, Train Loss: 105.8281\n",
      "5221.341468811035\n",
      "Epoch [40/50], Batch 52/120, Train Loss: 85.7651\n",
      "5304.470420837402\n",
      "Epoch [40/50], Batch 53/120, Train Loss: 83.1290\n",
      "5409.64315032959\n",
      "Epoch [40/50], Batch 54/120, Train Loss: 105.1727\n",
      "5494.694206237793\n",
      "Epoch [40/50], Batch 55/120, Train Loss: 85.0511\n",
      "5571.5224685668945\n",
      "Epoch [40/50], Batch 56/120, Train Loss: 76.8283\n",
      "5674.49796295166\n",
      "Epoch [40/50], Batch 57/120, Train Loss: 102.9755\n",
      "5768.964294433594\n",
      "Epoch [40/50], Batch 58/120, Train Loss: 94.4663\n",
      "5864.120697021484\n",
      "Epoch [40/50], Batch 59/120, Train Loss: 95.1564\n",
      "5967.736602783203\n",
      "Epoch [40/50], Batch 60/120, Train Loss: 103.6159\n",
      "6062.8948974609375\n",
      "Epoch [40/50], Batch 61/120, Train Loss: 95.1583\n",
      "6141.631942749023\n",
      "Epoch [40/50], Batch 62/120, Train Loss: 78.7370\n",
      "6250.274063110352\n",
      "Epoch [40/50], Batch 63/120, Train Loss: 108.6421\n",
      "6321.938621520996\n",
      "Epoch [40/50], Batch 64/120, Train Loss: 71.6646\n",
      "6408.292762756348\n",
      "Epoch [40/50], Batch 65/120, Train Loss: 86.3541\n",
      "6506.536094665527\n",
      "Epoch [40/50], Batch 66/120, Train Loss: 98.2433\n",
      "6596.144760131836\n",
      "Epoch [40/50], Batch 67/120, Train Loss: 89.6087\n",
      "6686.55354309082\n",
      "Epoch [40/50], Batch 68/120, Train Loss: 90.4088\n",
      "6794.885589599609\n",
      "Epoch [40/50], Batch 69/120, Train Loss: 108.3320\n",
      "6885.052833557129\n",
      "Epoch [40/50], Batch 70/120, Train Loss: 90.1672\n",
      "6974.0336837768555\n",
      "Epoch [40/50], Batch 71/120, Train Loss: 88.9809\n",
      "7066.396766662598\n",
      "Epoch [40/50], Batch 72/120, Train Loss: 92.3631\n",
      "7159.950294494629\n",
      "Epoch [40/50], Batch 73/120, Train Loss: 93.5535\n",
      "7242.652008056641\n",
      "Epoch [40/50], Batch 74/120, Train Loss: 82.7017\n",
      "7357.268325805664\n",
      "Epoch [40/50], Batch 75/120, Train Loss: 114.6163\n",
      "7444.915580749512\n",
      "Epoch [40/50], Batch 76/120, Train Loss: 87.6473\n",
      "7549.031661987305\n",
      "Epoch [40/50], Batch 77/120, Train Loss: 104.1161\n",
      "7640.711471557617\n",
      "Epoch [40/50], Batch 78/120, Train Loss: 91.6798\n",
      "7769.079483032227\n",
      "Epoch [40/50], Batch 79/120, Train Loss: 128.3680\n",
      "7857.501266479492\n",
      "Epoch [40/50], Batch 80/120, Train Loss: 88.4218\n",
      "7936.970779418945\n",
      "Epoch [40/50], Batch 81/120, Train Loss: 79.4695\n",
      "8024.449783325195\n",
      "Epoch [40/50], Batch 82/120, Train Loss: 87.4790\n",
      "8105.557769775391\n",
      "Epoch [40/50], Batch 83/120, Train Loss: 81.1080\n",
      "8195.395027160645\n",
      "Epoch [40/50], Batch 84/120, Train Loss: 89.8373\n",
      "8285.135902404785\n",
      "Epoch [40/50], Batch 85/120, Train Loss: 89.7409\n",
      "8391.230163574219\n",
      "Epoch [40/50], Batch 86/120, Train Loss: 106.0943\n",
      "8497.360717773438\n",
      "Epoch [40/50], Batch 87/120, Train Loss: 106.1306\n",
      "8602.313217163086\n",
      "Epoch [40/50], Batch 88/120, Train Loss: 104.9525\n",
      "8691.855812072754\n",
      "Epoch [40/50], Batch 89/120, Train Loss: 89.5426\n",
      "8805.379783630371\n",
      "Epoch [40/50], Batch 90/120, Train Loss: 113.5240\n",
      "8907.478324890137\n",
      "Epoch [40/50], Batch 91/120, Train Loss: 102.0985\n",
      "9016.874099731445\n",
      "Epoch [40/50], Batch 92/120, Train Loss: 109.3958\n",
      "9093.736770629883\n",
      "Epoch [40/50], Batch 93/120, Train Loss: 76.8627\n",
      "9191.175834655762\n",
      "Epoch [40/50], Batch 94/120, Train Loss: 97.4391\n",
      "9265.012992858887\n",
      "Epoch [40/50], Batch 95/120, Train Loss: 73.8372\n",
      "9346.552635192871\n",
      "Epoch [40/50], Batch 96/120, Train Loss: 81.5396\n",
      "9447.992866516113\n",
      "Epoch [40/50], Batch 97/120, Train Loss: 101.4402\n",
      "9550.214302062988\n",
      "Epoch [40/50], Batch 98/120, Train Loss: 102.2214\n",
      "9648.467552185059\n",
      "Epoch [40/50], Batch 99/120, Train Loss: 98.2533\n",
      "9751.521781921387\n",
      "Epoch [40/50], Batch 100/120, Train Loss: 103.0542\n",
      "9868.083534240723\n",
      "Epoch [40/50], Batch 101/120, Train Loss: 116.5618\n",
      "9946.935684204102\n",
      "Epoch [40/50], Batch 102/120, Train Loss: 78.8521\n",
      "10039.276260375977\n",
      "Epoch [40/50], Batch 103/120, Train Loss: 92.3406\n",
      "10128.719223022461\n",
      "Epoch [40/50], Batch 104/120, Train Loss: 89.4430\n",
      "10222.619247436523\n",
      "Epoch [40/50], Batch 105/120, Train Loss: 93.9000\n",
      "10333.932167053223\n",
      "Epoch [40/50], Batch 106/120, Train Loss: 111.3129\n",
      "10425.708984375\n",
      "Epoch [40/50], Batch 107/120, Train Loss: 91.7768\n",
      "10517.1714553833\n",
      "Epoch [40/50], Batch 108/120, Train Loss: 91.4625\n",
      "10624.613182067871\n",
      "Epoch [40/50], Batch 109/120, Train Loss: 107.4417\n",
      "10738.163185119629\n",
      "Epoch [40/50], Batch 110/120, Train Loss: 113.5500\n",
      "10855.82317352295\n",
      "Epoch [40/50], Batch 111/120, Train Loss: 117.6600\n",
      "10947.853134155273\n",
      "Epoch [40/50], Batch 112/120, Train Loss: 92.0300\n",
      "11033.720703125\n",
      "Epoch [40/50], Batch 113/120, Train Loss: 85.8676\n",
      "11126.938186645508\n",
      "Epoch [40/50], Batch 114/120, Train Loss: 93.2175\n",
      "11242.067581176758\n",
      "Epoch [40/50], Batch 115/120, Train Loss: 115.1294\n",
      "11349.013816833496\n",
      "Epoch [40/50], Batch 116/120, Train Loss: 106.9462\n",
      "11435.948066711426\n",
      "Epoch [40/50], Batch 117/120, Train Loss: 86.9342\n",
      "11530.067817687988\n",
      "Epoch [40/50], Batch 118/120, Train Loss: 94.1198\n",
      "11620.052680969238\n",
      "Epoch [40/50], Batch 119/120, Train Loss: 89.9849\n",
      "11706.150596618652\n",
      "Epoch [40/50], Batch 120/120, Train Loss: 86.0979\n",
      "Epoch [40/50], Train Loss: 97.5513, Validation Loss: 116.7117\n",
      "104.60755920410156\n",
      "Epoch [41/50], Batch 1/120, Train Loss: 104.6076\n",
      "203.29363250732422\n",
      "Epoch [41/50], Batch 2/120, Train Loss: 98.6861\n",
      "276.74173736572266\n",
      "Epoch [41/50], Batch 3/120, Train Loss: 73.4481\n",
      "375.95472717285156\n",
      "Epoch [41/50], Batch 4/120, Train Loss: 99.2130\n",
      "485.12644958496094\n",
      "Epoch [41/50], Batch 5/120, Train Loss: 109.1717\n",
      "568.4682159423828\n",
      "Epoch [41/50], Batch 6/120, Train Loss: 83.3418\n",
      "660.3395538330078\n",
      "Epoch [41/50], Batch 7/120, Train Loss: 91.8713\n",
      "749.0895385742188\n",
      "Epoch [41/50], Batch 8/120, Train Loss: 88.7500\n",
      "839.4430084228516\n",
      "Epoch [41/50], Batch 9/120, Train Loss: 90.3535\n",
      "934.3574829101562\n",
      "Epoch [41/50], Batch 10/120, Train Loss: 94.9145\n",
      "1048.7353210449219\n",
      "Epoch [41/50], Batch 11/120, Train Loss: 114.3778\n",
      "1123.6533737182617\n",
      "Epoch [41/50], Batch 12/120, Train Loss: 74.9181\n",
      "1204.705940246582\n",
      "Epoch [41/50], Batch 13/120, Train Loss: 81.0526\n",
      "1307.4497756958008\n",
      "Epoch [41/50], Batch 14/120, Train Loss: 102.7438\n",
      "1423.2955780029297\n",
      "Epoch [41/50], Batch 15/120, Train Loss: 115.8458\n",
      "1533.5800018310547\n",
      "Epoch [41/50], Batch 16/120, Train Loss: 110.2844\n",
      "1639.3969039916992\n",
      "Epoch [41/50], Batch 17/120, Train Loss: 105.8169\n",
      "1744.5411224365234\n",
      "Epoch [41/50], Batch 18/120, Train Loss: 105.1442\n",
      "1838.5361328125\n",
      "Epoch [41/50], Batch 19/120, Train Loss: 93.9950\n",
      "1940.9064712524414\n",
      "Epoch [41/50], Batch 20/120, Train Loss: 102.3703\n",
      "2042.7068405151367\n",
      "Epoch [41/50], Batch 21/120, Train Loss: 101.8004\n",
      "2144.739616394043\n",
      "Epoch [41/50], Batch 22/120, Train Loss: 102.0328\n",
      "2230.582130432129\n",
      "Epoch [41/50], Batch 23/120, Train Loss: 85.8425\n",
      "2336.1541137695312\n",
      "Epoch [41/50], Batch 24/120, Train Loss: 105.5720\n",
      "2450.5209045410156\n",
      "Epoch [41/50], Batch 25/120, Train Loss: 114.3668\n",
      "2539.9881439208984\n",
      "Epoch [41/50], Batch 26/120, Train Loss: 89.4672\n",
      "2632.143569946289\n",
      "Epoch [41/50], Batch 27/120, Train Loss: 92.1554\n",
      "2717.3915786743164\n",
      "Epoch [41/50], Batch 28/120, Train Loss: 85.2480\n",
      "2808.535820007324\n",
      "Epoch [41/50], Batch 29/120, Train Loss: 91.1442\n",
      "2917.6955490112305\n",
      "Epoch [41/50], Batch 30/120, Train Loss: 109.1597\n",
      "3021.680107116699\n",
      "Epoch [41/50], Batch 31/120, Train Loss: 103.9846\n",
      "3119.03768157959\n",
      "Epoch [41/50], Batch 32/120, Train Loss: 97.3576\n",
      "3201.4005432128906\n",
      "Epoch [41/50], Batch 33/120, Train Loss: 82.3629\n",
      "3290.548568725586\n",
      "Epoch [41/50], Batch 34/120, Train Loss: 89.1480\n",
      "3381.59903717041\n",
      "Epoch [41/50], Batch 35/120, Train Loss: 91.0505\n",
      "3476.500877380371\n",
      "Epoch [41/50], Batch 36/120, Train Loss: 94.9018\n",
      "3567.616241455078\n",
      "Epoch [41/50], Batch 37/120, Train Loss: 91.1154\n",
      "3664.3690032958984\n",
      "Epoch [41/50], Batch 38/120, Train Loss: 96.7528\n",
      "3770.9486389160156\n",
      "Epoch [41/50], Batch 39/120, Train Loss: 106.5796\n",
      "3874.4609909057617\n",
      "Epoch [41/50], Batch 40/120, Train Loss: 103.5124\n",
      "3975.596366882324\n",
      "Epoch [41/50], Batch 41/120, Train Loss: 101.1354\n",
      "4047.7033615112305\n",
      "Epoch [41/50], Batch 42/120, Train Loss: 72.1070\n",
      "4146.054862976074\n",
      "Epoch [41/50], Batch 43/120, Train Loss: 98.3515\n",
      "4254.173873901367\n",
      "Epoch [41/50], Batch 44/120, Train Loss: 108.1190\n",
      "4351.940200805664\n",
      "Epoch [41/50], Batch 45/120, Train Loss: 97.7663\n",
      "4437.450698852539\n",
      "Epoch [41/50], Batch 46/120, Train Loss: 85.5105\n",
      "4544.531150817871\n",
      "Epoch [41/50], Batch 47/120, Train Loss: 107.0805\n",
      "4637.679725646973\n",
      "Epoch [41/50], Batch 48/120, Train Loss: 93.1486\n",
      "4723.528144836426\n",
      "Epoch [41/50], Batch 49/120, Train Loss: 85.8484\n",
      "4819.289939880371\n",
      "Epoch [41/50], Batch 50/120, Train Loss: 95.7618\n",
      "4929.201942443848\n",
      "Epoch [41/50], Batch 51/120, Train Loss: 109.9120\n",
      "5016.891250610352\n",
      "Epoch [41/50], Batch 52/120, Train Loss: 87.6893\n",
      "5124.361129760742\n",
      "Epoch [41/50], Batch 53/120, Train Loss: 107.4699\n",
      "5214.946502685547\n",
      "Epoch [41/50], Batch 54/120, Train Loss: 90.5854\n",
      "5322.152893066406\n",
      "Epoch [41/50], Batch 55/120, Train Loss: 107.2064\n",
      "5409.7285232543945\n",
      "Epoch [41/50], Batch 56/120, Train Loss: 87.5756\n",
      "5493.313011169434\n",
      "Epoch [41/50], Batch 57/120, Train Loss: 83.5845\n",
      "5576.86319732666\n",
      "Epoch [41/50], Batch 58/120, Train Loss: 83.5502\n",
      "5698.944969177246\n",
      "Epoch [41/50], Batch 59/120, Train Loss: 122.0818\n",
      "5798.2338943481445\n",
      "Epoch [41/50], Batch 60/120, Train Loss: 99.2889\n",
      "5895.075263977051\n",
      "Epoch [41/50], Batch 61/120, Train Loss: 96.8414\n",
      "5988.401100158691\n",
      "Epoch [41/50], Batch 62/120, Train Loss: 93.3258\n",
      "6074.3872146606445\n",
      "Epoch [41/50], Batch 63/120, Train Loss: 85.9861\n",
      "6170.438209533691\n",
      "Epoch [41/50], Batch 64/120, Train Loss: 96.0510\n",
      "6270.423683166504\n",
      "Epoch [41/50], Batch 65/120, Train Loss: 99.9855\n",
      "6344.230850219727\n",
      "Epoch [41/50], Batch 66/120, Train Loss: 73.8072\n",
      "6442.487808227539\n",
      "Epoch [41/50], Batch 67/120, Train Loss: 98.2570\n",
      "6554.127517700195\n",
      "Epoch [41/50], Batch 68/120, Train Loss: 111.6397\n",
      "6654.341751098633\n",
      "Epoch [41/50], Batch 69/120, Train Loss: 100.2142\n",
      "6767.60693359375\n",
      "Epoch [41/50], Batch 70/120, Train Loss: 113.2652\n",
      "6873.183090209961\n",
      "Epoch [41/50], Batch 71/120, Train Loss: 105.5762\n",
      "6966.693008422852\n",
      "Epoch [41/50], Batch 72/120, Train Loss: 93.5099\n",
      "7058.177459716797\n",
      "Epoch [41/50], Batch 73/120, Train Loss: 91.4845\n",
      "7181.608024597168\n",
      "Epoch [41/50], Batch 74/120, Train Loss: 123.4306\n",
      "7268.792503356934\n",
      "Epoch [41/50], Batch 75/120, Train Loss: 87.1845\n",
      "7370.973655700684\n",
      "Epoch [41/50], Batch 76/120, Train Loss: 102.1812\n",
      "7457.4742431640625\n",
      "Epoch [41/50], Batch 77/120, Train Loss: 86.5006\n",
      "7559.844375610352\n",
      "Epoch [41/50], Batch 78/120, Train Loss: 102.3701\n",
      "7656.848678588867\n",
      "Epoch [41/50], Batch 79/120, Train Loss: 97.0043\n",
      "7718.245223999023\n",
      "Epoch [41/50], Batch 80/120, Train Loss: 61.3965\n",
      "7811.66682434082\n",
      "Epoch [41/50], Batch 81/120, Train Loss: 93.4216\n",
      "7900.679336547852\n",
      "Epoch [41/50], Batch 82/120, Train Loss: 89.0125\n",
      "8004.85041809082\n",
      "Epoch [41/50], Batch 83/120, Train Loss: 104.1711\n",
      "8093.545959472656\n",
      "Epoch [41/50], Batch 84/120, Train Loss: 88.6955\n",
      "8198.372680664062\n",
      "Epoch [41/50], Batch 85/120, Train Loss: 104.8267\n",
      "8298.7670211792\n",
      "Epoch [41/50], Batch 86/120, Train Loss: 100.3943\n",
      "8398.712356567383\n",
      "Epoch [41/50], Batch 87/120, Train Loss: 99.9453\n",
      "8480.021453857422\n",
      "Epoch [41/50], Batch 88/120, Train Loss: 81.3091\n",
      "8575.14250946045\n",
      "Epoch [41/50], Batch 89/120, Train Loss: 95.1211\n",
      "8676.934196472168\n",
      "Epoch [41/50], Batch 90/120, Train Loss: 101.7917\n",
      "8772.013313293457\n",
      "Epoch [41/50], Batch 91/120, Train Loss: 95.0791\n",
      "8884.926856994629\n",
      "Epoch [41/50], Batch 92/120, Train Loss: 112.9135\n",
      "8998.339881896973\n",
      "Epoch [41/50], Batch 93/120, Train Loss: 113.4130\n",
      "9100.839546203613\n",
      "Epoch [41/50], Batch 94/120, Train Loss: 102.4997\n",
      "9223.773468017578\n",
      "Epoch [41/50], Batch 95/120, Train Loss: 122.9339\n",
      "9305.76554107666\n",
      "Epoch [41/50], Batch 96/120, Train Loss: 81.9921\n",
      "9406.2396774292\n",
      "Epoch [41/50], Batch 97/120, Train Loss: 100.4741\n",
      "9523.51375579834\n",
      "Epoch [41/50], Batch 98/120, Train Loss: 117.2741\n",
      "9644.316932678223\n",
      "Epoch [41/50], Batch 99/120, Train Loss: 120.8032\n",
      "9747.649742126465\n",
      "Epoch [41/50], Batch 100/120, Train Loss: 103.3328\n",
      "9846.767776489258\n",
      "Epoch [41/50], Batch 101/120, Train Loss: 99.1180\n",
      "9931.446792602539\n",
      "Epoch [41/50], Batch 102/120, Train Loss: 84.6790\n",
      "10006.901794433594\n",
      "Epoch [41/50], Batch 103/120, Train Loss: 75.4550\n",
      "10091.563598632812\n",
      "Epoch [41/50], Batch 104/120, Train Loss: 84.6618\n",
      "10192.795364379883\n",
      "Epoch [41/50], Batch 105/120, Train Loss: 101.2318\n",
      "10279.201332092285\n",
      "Epoch [41/50], Batch 106/120, Train Loss: 86.4060\n",
      "10372.02074432373\n",
      "Epoch [41/50], Batch 107/120, Train Loss: 92.8194\n",
      "10491.791564941406\n",
      "Epoch [41/50], Batch 108/120, Train Loss: 119.7708\n",
      "10579.172348022461\n",
      "Epoch [41/50], Batch 109/120, Train Loss: 87.3808\n",
      "10670.684555053711\n",
      "Epoch [41/50], Batch 110/120, Train Loss: 91.5122\n",
      "10758.784317016602\n",
      "Epoch [41/50], Batch 111/120, Train Loss: 88.0998\n",
      "10839.153144836426\n",
      "Epoch [41/50], Batch 112/120, Train Loss: 80.3688\n",
      "10914.351104736328\n",
      "Epoch [41/50], Batch 113/120, Train Loss: 75.1980\n",
      "11021.27409362793\n",
      "Epoch [41/50], Batch 114/120, Train Loss: 106.9230\n",
      "11143.432861328125\n",
      "Epoch [41/50], Batch 115/120, Train Loss: 122.1588\n",
      "11230.0863571167\n",
      "Epoch [41/50], Batch 116/120, Train Loss: 86.6535\n",
      "11322.401756286621\n",
      "Epoch [41/50], Batch 117/120, Train Loss: 92.3154\n",
      "11423.870643615723\n",
      "Epoch [41/50], Batch 118/120, Train Loss: 101.4689\n",
      "11551.847007751465\n",
      "Epoch [41/50], Batch 119/120, Train Loss: 127.9764\n",
      "11641.441230773926\n",
      "Epoch [41/50], Batch 120/120, Train Loss: 89.5942\n",
      "Epoch [41/50], Train Loss: 97.0120, Validation Loss: 114.4742\n",
      "108.58499145507812\n",
      "Epoch [42/50], Batch 1/120, Train Loss: 108.5850\n",
      "200.6971664428711\n",
      "Epoch [42/50], Batch 2/120, Train Loss: 92.1122\n",
      "320.22293853759766\n",
      "Epoch [42/50], Batch 3/120, Train Loss: 119.5258\n",
      "415.38021087646484\n",
      "Epoch [42/50], Batch 4/120, Train Loss: 95.1573\n",
      "503.60179901123047\n",
      "Epoch [42/50], Batch 5/120, Train Loss: 88.2216\n",
      "616.9413070678711\n",
      "Epoch [42/50], Batch 6/120, Train Loss: 113.3395\n",
      "724.6534729003906\n",
      "Epoch [42/50], Batch 7/120, Train Loss: 107.7122\n",
      "809.9002838134766\n",
      "Epoch [42/50], Batch 8/120, Train Loss: 85.2468\n",
      "936.0585403442383\n",
      "Epoch [42/50], Batch 9/120, Train Loss: 126.1583\n",
      "1031.7549667358398\n",
      "Epoch [42/50], Batch 10/120, Train Loss: 95.6964\n",
      "1151.2662963867188\n",
      "Epoch [42/50], Batch 11/120, Train Loss: 119.5113\n",
      "1263.4327392578125\n",
      "Epoch [42/50], Batch 12/120, Train Loss: 112.1664\n",
      "1356.8512878417969\n",
      "Epoch [42/50], Batch 13/120, Train Loss: 93.4185\n",
      "1449.3106842041016\n",
      "Epoch [42/50], Batch 14/120, Train Loss: 92.4594\n",
      "1551.321792602539\n",
      "Epoch [42/50], Batch 15/120, Train Loss: 102.0111\n",
      "1649.5806121826172\n",
      "Epoch [42/50], Batch 16/120, Train Loss: 98.2588\n",
      "1726.0735626220703\n",
      "Epoch [42/50], Batch 17/120, Train Loss: 76.4930\n",
      "1823.8179244995117\n",
      "Epoch [42/50], Batch 18/120, Train Loss: 97.7444\n",
      "1923.2512588500977\n",
      "Epoch [42/50], Batch 19/120, Train Loss: 99.4333\n",
      "1982.708755493164\n",
      "Epoch [42/50], Batch 20/120, Train Loss: 59.4575\n",
      "2086.107711791992\n",
      "Epoch [42/50], Batch 21/120, Train Loss: 103.3990\n",
      "2195.5412521362305\n",
      "Epoch [42/50], Batch 22/120, Train Loss: 109.4335\n",
      "2307.3578720092773\n",
      "Epoch [42/50], Batch 23/120, Train Loss: 111.8166\n",
      "2383.328659057617\n",
      "Epoch [42/50], Batch 24/120, Train Loss: 75.9708\n",
      "2470.8602447509766\n",
      "Epoch [42/50], Batch 25/120, Train Loss: 87.5316\n",
      "2571.5663299560547\n",
      "Epoch [42/50], Batch 26/120, Train Loss: 100.7061\n",
      "2666.90926361084\n",
      "Epoch [42/50], Batch 27/120, Train Loss: 95.3429\n",
      "2753.380302429199\n",
      "Epoch [42/50], Batch 28/120, Train Loss: 86.4710\n",
      "2849.140510559082\n",
      "Epoch [42/50], Batch 29/120, Train Loss: 95.7602\n",
      "2925.211845397949\n",
      "Epoch [42/50], Batch 30/120, Train Loss: 76.0713\n",
      "3032.2307357788086\n",
      "Epoch [42/50], Batch 31/120, Train Loss: 107.0189\n",
      "3126.81209564209\n",
      "Epoch [42/50], Batch 32/120, Train Loss: 94.5814\n",
      "3231.391487121582\n",
      "Epoch [42/50], Batch 33/120, Train Loss: 104.5794\n",
      "3323.1248092651367\n",
      "Epoch [42/50], Batch 34/120, Train Loss: 91.7333\n",
      "3436.008857727051\n",
      "Epoch [42/50], Batch 35/120, Train Loss: 112.8840\n",
      "3524.91104888916\n",
      "Epoch [42/50], Batch 36/120, Train Loss: 88.9022\n",
      "3627.231590270996\n",
      "Epoch [42/50], Batch 37/120, Train Loss: 102.3205\n",
      "3726.6144104003906\n",
      "Epoch [42/50], Batch 38/120, Train Loss: 99.3828\n",
      "3818.684036254883\n",
      "Epoch [42/50], Batch 39/120, Train Loss: 92.0696\n",
      "3926.1208877563477\n",
      "Epoch [42/50], Batch 40/120, Train Loss: 107.4369\n",
      "4025.3740768432617\n",
      "Epoch [42/50], Batch 41/120, Train Loss: 99.2532\n",
      "4123.227668762207\n",
      "Epoch [42/50], Batch 42/120, Train Loss: 97.8536\n",
      "4210.383827209473\n",
      "Epoch [42/50], Batch 43/120, Train Loss: 87.1562\n",
      "4313.124366760254\n",
      "Epoch [42/50], Batch 44/120, Train Loss: 102.7405\n",
      "4410.923316955566\n",
      "Epoch [42/50], Batch 45/120, Train Loss: 97.7990\n",
      "4504.985206604004\n",
      "Epoch [42/50], Batch 46/120, Train Loss: 94.0619\n",
      "4620.300430297852\n",
      "Epoch [42/50], Batch 47/120, Train Loss: 115.3152\n",
      "4701.295257568359\n",
      "Epoch [42/50], Batch 48/120, Train Loss: 80.9948\n",
      "4791.75749206543\n",
      "Epoch [42/50], Batch 49/120, Train Loss: 90.4622\n",
      "4896.586067199707\n",
      "Epoch [42/50], Batch 50/120, Train Loss: 104.8286\n",
      "4988.085182189941\n",
      "Epoch [42/50], Batch 51/120, Train Loss: 91.4991\n",
      "5092.696983337402\n",
      "Epoch [42/50], Batch 52/120, Train Loss: 104.6118\n",
      "5188.763595581055\n",
      "Epoch [42/50], Batch 53/120, Train Loss: 96.0666\n",
      "5266.33219909668\n",
      "Epoch [42/50], Batch 54/120, Train Loss: 77.5686\n",
      "5370.2735595703125\n",
      "Epoch [42/50], Batch 55/120, Train Loss: 103.9414\n",
      "5473.922409057617\n",
      "Epoch [42/50], Batch 56/120, Train Loss: 103.6488\n",
      "5586.939414978027\n",
      "Epoch [42/50], Batch 57/120, Train Loss: 113.0170\n",
      "5675.833198547363\n",
      "Epoch [42/50], Batch 58/120, Train Loss: 88.8938\n",
      "5795.992012023926\n",
      "Epoch [42/50], Batch 59/120, Train Loss: 120.1588\n",
      "5903.526504516602\n",
      "Epoch [42/50], Batch 60/120, Train Loss: 107.5345\n",
      "6001.554733276367\n",
      "Epoch [42/50], Batch 61/120, Train Loss: 98.0282\n",
      "6084.551383972168\n",
      "Epoch [42/50], Batch 62/120, Train Loss: 82.9967\n",
      "6174.128196716309\n",
      "Epoch [42/50], Batch 63/120, Train Loss: 89.5768\n",
      "6280.212547302246\n",
      "Epoch [42/50], Batch 64/120, Train Loss: 106.0844\n",
      "6374.35578918457\n",
      "Epoch [42/50], Batch 65/120, Train Loss: 94.1432\n",
      "6445.010177612305\n",
      "Epoch [42/50], Batch 66/120, Train Loss: 70.6544\n",
      "6547.030334472656\n",
      "Epoch [42/50], Batch 67/120, Train Loss: 102.0202\n",
      "6632.092864990234\n",
      "Epoch [42/50], Batch 68/120, Train Loss: 85.0625\n",
      "6727.858657836914\n",
      "Epoch [42/50], Batch 69/120, Train Loss: 95.7658\n",
      "6848.643005371094\n",
      "Epoch [42/50], Batch 70/120, Train Loss: 120.7843\n",
      "6953.071098327637\n",
      "Epoch [42/50], Batch 71/120, Train Loss: 104.4281\n",
      "7041.132736206055\n",
      "Epoch [42/50], Batch 72/120, Train Loss: 88.0616\n",
      "7165.834983825684\n",
      "Epoch [42/50], Batch 73/120, Train Loss: 124.7022\n",
      "7265.199882507324\n",
      "Epoch [42/50], Batch 74/120, Train Loss: 99.3649\n",
      "7365.3503341674805\n",
      "Epoch [42/50], Batch 75/120, Train Loss: 100.1505\n",
      "7458.835021972656\n",
      "Epoch [42/50], Batch 76/120, Train Loss: 93.4847\n",
      "7555.277420043945\n",
      "Epoch [42/50], Batch 77/120, Train Loss: 96.4424\n",
      "7665.9663162231445\n",
      "Epoch [42/50], Batch 78/120, Train Loss: 110.6889\n",
      "7763.041030883789\n",
      "Epoch [42/50], Batch 79/120, Train Loss: 97.0747\n",
      "7861.223983764648\n",
      "Epoch [42/50], Batch 80/120, Train Loss: 98.1830\n",
      "7955.616638183594\n",
      "Epoch [42/50], Batch 81/120, Train Loss: 94.3927\n",
      "8037.464309692383\n",
      "Epoch [42/50], Batch 82/120, Train Loss: 81.8477\n",
      "8136.983016967773\n",
      "Epoch [42/50], Batch 83/120, Train Loss: 99.5187\n",
      "8238.631050109863\n",
      "Epoch [42/50], Batch 84/120, Train Loss: 101.6480\n",
      "8335.766998291016\n",
      "Epoch [42/50], Batch 85/120, Train Loss: 97.1359\n",
      "8433.675811767578\n",
      "Epoch [42/50], Batch 86/120, Train Loss: 97.9088\n",
      "8515.477737426758\n",
      "Epoch [42/50], Batch 87/120, Train Loss: 81.8019\n",
      "8602.75\n",
      "Epoch [42/50], Batch 88/120, Train Loss: 87.2723\n",
      "8733.522766113281\n",
      "Epoch [42/50], Batch 89/120, Train Loss: 130.7728\n",
      "8835.598091125488\n",
      "Epoch [42/50], Batch 90/120, Train Loss: 102.0753\n",
      "8929.717964172363\n",
      "Epoch [42/50], Batch 91/120, Train Loss: 94.1199\n",
      "9023.330665588379\n",
      "Epoch [42/50], Batch 92/120, Train Loss: 93.6127\n",
      "9109.747230529785\n",
      "Epoch [42/50], Batch 93/120, Train Loss: 86.4166\n",
      "9198.28141784668\n",
      "Epoch [42/50], Batch 94/120, Train Loss: 88.5342\n",
      "9298.646286010742\n",
      "Epoch [42/50], Batch 95/120, Train Loss: 100.3649\n",
      "9400.61067199707\n",
      "Epoch [42/50], Batch 96/120, Train Loss: 101.9644\n",
      "9490.852081298828\n",
      "Epoch [42/50], Batch 97/120, Train Loss: 90.2414\n",
      "9597.197036743164\n",
      "Epoch [42/50], Batch 98/120, Train Loss: 106.3450\n",
      "9691.38385772705\n",
      "Epoch [42/50], Batch 99/120, Train Loss: 94.1868\n",
      "9780.829307556152\n",
      "Epoch [42/50], Batch 100/120, Train Loss: 89.4454\n",
      "9895.12947845459\n",
      "Epoch [42/50], Batch 101/120, Train Loss: 114.3002\n",
      "10005.704399108887\n",
      "Epoch [42/50], Batch 102/120, Train Loss: 110.5749\n",
      "10076.137657165527\n",
      "Epoch [42/50], Batch 103/120, Train Loss: 70.4333\n",
      "10175.577766418457\n",
      "Epoch [42/50], Batch 104/120, Train Loss: 99.4401\n",
      "10297.880653381348\n",
      "Epoch [42/50], Batch 105/120, Train Loss: 122.3029\n",
      "10393.68463897705\n",
      "Epoch [42/50], Batch 106/120, Train Loss: 95.8040\n",
      "10477.740493774414\n",
      "Epoch [42/50], Batch 107/120, Train Loss: 84.0559\n",
      "10580.841331481934\n",
      "Epoch [42/50], Batch 108/120, Train Loss: 103.1008\n",
      "10663.078643798828\n",
      "Epoch [42/50], Batch 109/120, Train Loss: 82.2373\n",
      "10760.644309997559\n",
      "Epoch [42/50], Batch 110/120, Train Loss: 97.5657\n",
      "10881.064170837402\n",
      "Epoch [42/50], Batch 111/120, Train Loss: 120.4199\n",
      "10967.678352355957\n",
      "Epoch [42/50], Batch 112/120, Train Loss: 86.6142\n",
      "11071.475715637207\n",
      "Epoch [42/50], Batch 113/120, Train Loss: 103.7974\n",
      "11149.045219421387\n",
      "Epoch [42/50], Batch 114/120, Train Loss: 77.5695\n",
      "11238.641761779785\n",
      "Epoch [42/50], Batch 115/120, Train Loss: 89.5965\n",
      "11329.548957824707\n",
      "Epoch [42/50], Batch 116/120, Train Loss: 90.9072\n",
      "11402.98250579834\n",
      "Epoch [42/50], Batch 117/120, Train Loss: 73.4335\n",
      "11514.774917602539\n",
      "Epoch [42/50], Batch 118/120, Train Loss: 111.7924\n",
      "11638.545516967773\n",
      "Epoch [42/50], Batch 119/120, Train Loss: 123.7706\n",
      "11743.990409851074\n",
      "Epoch [42/50], Batch 120/120, Train Loss: 105.4449\n",
      "Epoch [42/50], Train Loss: 97.8666, Validation Loss: 114.9810\n",
      "110.81253814697266\n",
      "Epoch [43/50], Batch 1/120, Train Loss: 110.8125\n",
      "182.13626861572266\n",
      "Epoch [43/50], Batch 2/120, Train Loss: 71.3237\n",
      "278.16510009765625\n",
      "Epoch [43/50], Batch 3/120, Train Loss: 96.0288\n",
      "369.3909454345703\n",
      "Epoch [43/50], Batch 4/120, Train Loss: 91.2258\n",
      "456.88795471191406\n",
      "Epoch [43/50], Batch 5/120, Train Loss: 87.4970\n",
      "555.2612380981445\n",
      "Epoch [43/50], Batch 6/120, Train Loss: 98.3733\n",
      "638.907829284668\n",
      "Epoch [43/50], Batch 7/120, Train Loss: 83.6466\n",
      "733.3415756225586\n",
      "Epoch [43/50], Batch 8/120, Train Loss: 94.4337\n",
      "840.2446975708008\n",
      "Epoch [43/50], Batch 9/120, Train Loss: 106.9031\n",
      "939.2607650756836\n",
      "Epoch [43/50], Batch 10/120, Train Loss: 99.0161\n",
      "1026.1001663208008\n",
      "Epoch [43/50], Batch 11/120, Train Loss: 86.8394\n",
      "1115.4003829956055\n",
      "Epoch [43/50], Batch 12/120, Train Loss: 89.3002\n",
      "1224.646339416504\n",
      "Epoch [43/50], Batch 13/120, Train Loss: 109.2460\n",
      "1308.7111434936523\n",
      "Epoch [43/50], Batch 14/120, Train Loss: 84.0648\n",
      "1371.7772369384766\n",
      "Epoch [43/50], Batch 15/120, Train Loss: 63.0661\n",
      "1479.3399505615234\n",
      "Epoch [43/50], Batch 16/120, Train Loss: 107.5627\n",
      "1567.1412963867188\n",
      "Epoch [43/50], Batch 17/120, Train Loss: 87.8013\n",
      "1668.324203491211\n",
      "Epoch [43/50], Batch 18/120, Train Loss: 101.1829\n",
      "1782.8023223876953\n",
      "Epoch [43/50], Batch 19/120, Train Loss: 114.4781\n",
      "1880.7314758300781\n",
      "Epoch [43/50], Batch 20/120, Train Loss: 97.9292\n",
      "1975.5789108276367\n",
      "Epoch [43/50], Batch 21/120, Train Loss: 94.8474\n",
      "2068.8684616088867\n",
      "Epoch [43/50], Batch 22/120, Train Loss: 93.2896\n",
      "2169.319267272949\n",
      "Epoch [43/50], Batch 23/120, Train Loss: 100.4508\n",
      "2280.6420974731445\n",
      "Epoch [43/50], Batch 24/120, Train Loss: 111.3228\n",
      "2379.911003112793\n",
      "Epoch [43/50], Batch 25/120, Train Loss: 99.2689\n",
      "2451.4112701416016\n",
      "Epoch [43/50], Batch 26/120, Train Loss: 71.5003\n",
      "2572.08740234375\n",
      "Epoch [43/50], Batch 27/120, Train Loss: 120.6761\n",
      "2670.919822692871\n",
      "Epoch [43/50], Batch 28/120, Train Loss: 98.8324\n",
      "2764.978843688965\n",
      "Epoch [43/50], Batch 29/120, Train Loss: 94.0590\n",
      "2866.9760513305664\n",
      "Epoch [43/50], Batch 30/120, Train Loss: 101.9972\n",
      "2996.056755065918\n",
      "Epoch [43/50], Batch 31/120, Train Loss: 129.0807\n",
      "3104.0333938598633\n",
      "Epoch [43/50], Batch 32/120, Train Loss: 107.9766\n",
      "3189.335075378418\n",
      "Epoch [43/50], Batch 33/120, Train Loss: 85.3017\n",
      "3260.4729919433594\n",
      "Epoch [43/50], Batch 34/120, Train Loss: 71.1379\n",
      "3364.401123046875\n",
      "Epoch [43/50], Batch 35/120, Train Loss: 103.9281\n",
      "3450.334297180176\n",
      "Epoch [43/50], Batch 36/120, Train Loss: 85.9332\n",
      "3544.525077819824\n",
      "Epoch [43/50], Batch 37/120, Train Loss: 94.1908\n",
      "3635.107810974121\n",
      "Epoch [43/50], Batch 38/120, Train Loss: 90.5827\n",
      "3748.287368774414\n",
      "Epoch [43/50], Batch 39/120, Train Loss: 113.1796\n",
      "3837.618019104004\n",
      "Epoch [43/50], Batch 40/120, Train Loss: 89.3307\n",
      "3954.826202392578\n",
      "Epoch [43/50], Batch 41/120, Train Loss: 117.2082\n",
      "4051.610420227051\n",
      "Epoch [43/50], Batch 42/120, Train Loss: 96.7842\n",
      "4167.297668457031\n",
      "Epoch [43/50], Batch 43/120, Train Loss: 115.6872\n",
      "4256.972229003906\n",
      "Epoch [43/50], Batch 44/120, Train Loss: 89.6746\n",
      "4379.492782592773\n",
      "Epoch [43/50], Batch 45/120, Train Loss: 122.5206\n",
      "4478.933486938477\n",
      "Epoch [43/50], Batch 46/120, Train Loss: 99.4407\n",
      "4583.875900268555\n",
      "Epoch [43/50], Batch 47/120, Train Loss: 104.9424\n",
      "4674.548782348633\n",
      "Epoch [43/50], Batch 48/120, Train Loss: 90.6729\n",
      "4760.162612915039\n",
      "Epoch [43/50], Batch 49/120, Train Loss: 85.6138\n",
      "4867.77286529541\n",
      "Epoch [43/50], Batch 50/120, Train Loss: 107.6103\n",
      "4981.040962219238\n",
      "Epoch [43/50], Batch 51/120, Train Loss: 113.2681\n",
      "5078.654945373535\n",
      "Epoch [43/50], Batch 52/120, Train Loss: 97.6140\n",
      "5151.346565246582\n",
      "Epoch [43/50], Batch 53/120, Train Loss: 72.6916\n",
      "5232.784278869629\n",
      "Epoch [43/50], Batch 54/120, Train Loss: 81.4377\n",
      "5311.828300476074\n",
      "Epoch [43/50], Batch 55/120, Train Loss: 79.0440\n",
      "5404.4968185424805\n",
      "Epoch [43/50], Batch 56/120, Train Loss: 92.6685\n",
      "5522.577667236328\n",
      "Epoch [43/50], Batch 57/120, Train Loss: 118.0808\n",
      "5615.525367736816\n",
      "Epoch [43/50], Batch 58/120, Train Loss: 92.9477\n",
      "5708.684715270996\n",
      "Epoch [43/50], Batch 59/120, Train Loss: 93.1593\n",
      "5828.651580810547\n",
      "Epoch [43/50], Batch 60/120, Train Loss: 119.9669\n",
      "5928.533805847168\n",
      "Epoch [43/50], Batch 61/120, Train Loss: 99.8822\n",
      "6013.967002868652\n",
      "Epoch [43/50], Batch 62/120, Train Loss: 85.4332\n",
      "6097.51301574707\n",
      "Epoch [43/50], Batch 63/120, Train Loss: 83.5460\n",
      "6217.374664306641\n",
      "Epoch [43/50], Batch 64/120, Train Loss: 119.8616\n",
      "6322.279098510742\n",
      "Epoch [43/50], Batch 65/120, Train Loss: 104.9044\n",
      "6382.577262878418\n",
      "Epoch [43/50], Batch 66/120, Train Loss: 60.2982\n",
      "6469.161842346191\n",
      "Epoch [43/50], Batch 67/120, Train Loss: 86.5846\n",
      "6541.220100402832\n",
      "Epoch [43/50], Batch 68/120, Train Loss: 72.0583\n",
      "6647.9727783203125\n",
      "Epoch [43/50], Batch 69/120, Train Loss: 106.7527\n",
      "6738.059196472168\n",
      "Epoch [43/50], Batch 70/120, Train Loss: 90.0864\n",
      "6833.23575592041\n",
      "Epoch [43/50], Batch 71/120, Train Loss: 95.1766\n",
      "6932.697059631348\n",
      "Epoch [43/50], Batch 72/120, Train Loss: 99.4613\n",
      "7039.039237976074\n",
      "Epoch [43/50], Batch 73/120, Train Loss: 106.3422\n",
      "7112.179946899414\n",
      "Epoch [43/50], Batch 74/120, Train Loss: 73.1407\n",
      "7200.84147644043\n",
      "Epoch [43/50], Batch 75/120, Train Loss: 88.6615\n",
      "7283.165435791016\n",
      "Epoch [43/50], Batch 76/120, Train Loss: 82.3240\n",
      "7378.90934753418\n",
      "Epoch [43/50], Batch 77/120, Train Loss: 95.7439\n",
      "7476.703018188477\n",
      "Epoch [43/50], Batch 78/120, Train Loss: 97.7937\n",
      "7578.860771179199\n",
      "Epoch [43/50], Batch 79/120, Train Loss: 102.1578\n",
      "7657.122596740723\n",
      "Epoch [43/50], Batch 80/120, Train Loss: 78.2618\n",
      "7765.332008361816\n",
      "Epoch [43/50], Batch 81/120, Train Loss: 108.2094\n",
      "7875.415946960449\n",
      "Epoch [43/50], Batch 82/120, Train Loss: 110.0839\n",
      "7970.962020874023\n",
      "Epoch [43/50], Batch 83/120, Train Loss: 95.5461\n",
      "8070.89501953125\n",
      "Epoch [43/50], Batch 84/120, Train Loss: 99.9330\n",
      "8174.552108764648\n",
      "Epoch [43/50], Batch 85/120, Train Loss: 103.6571\n",
      "8273.252052307129\n",
      "Epoch [43/50], Batch 86/120, Train Loss: 98.6999\n",
      "8370.038780212402\n",
      "Epoch [43/50], Batch 87/120, Train Loss: 96.7867\n",
      "8478.17163848877\n",
      "Epoch [43/50], Batch 88/120, Train Loss: 108.1329\n",
      "8551.7679977417\n",
      "Epoch [43/50], Batch 89/120, Train Loss: 73.5964\n",
      "8625.544410705566\n",
      "Epoch [43/50], Batch 90/120, Train Loss: 73.7764\n",
      "8737.917121887207\n",
      "Epoch [43/50], Batch 91/120, Train Loss: 112.3727\n",
      "8820.594528198242\n",
      "Epoch [43/50], Batch 92/120, Train Loss: 82.6774\n",
      "8919.132934570312\n",
      "Epoch [43/50], Batch 93/120, Train Loss: 98.5384\n",
      "9017.86735534668\n",
      "Epoch [43/50], Batch 94/120, Train Loss: 98.7344\n",
      "9121.875358581543\n",
      "Epoch [43/50], Batch 95/120, Train Loss: 104.0080\n",
      "9202.904289245605\n",
      "Epoch [43/50], Batch 96/120, Train Loss: 81.0289\n",
      "9305.315773010254\n",
      "Epoch [43/50], Batch 97/120, Train Loss: 102.4115\n",
      "9397.657623291016\n",
      "Epoch [43/50], Batch 98/120, Train Loss: 92.3419\n",
      "9496.596466064453\n",
      "Epoch [43/50], Batch 99/120, Train Loss: 98.9388\n",
      "9585.183868408203\n",
      "Epoch [43/50], Batch 100/120, Train Loss: 88.5874\n",
      "9657.116928100586\n",
      "Epoch [43/50], Batch 101/120, Train Loss: 71.9331\n",
      "9772.780952453613\n",
      "Epoch [43/50], Batch 102/120, Train Loss: 115.6640\n",
      "9882.549011230469\n",
      "Epoch [43/50], Batch 103/120, Train Loss: 109.7681\n",
      "10010.115196228027\n",
      "Epoch [43/50], Batch 104/120, Train Loss: 127.5662\n",
      "10083.776443481445\n",
      "Epoch [43/50], Batch 105/120, Train Loss: 73.6612\n",
      "10200.17414855957\n",
      "Epoch [43/50], Batch 106/120, Train Loss: 116.3977\n",
      "10291.139427185059\n",
      "Epoch [43/50], Batch 107/120, Train Loss: 90.9653\n",
      "10378.297882080078\n",
      "Epoch [43/50], Batch 108/120, Train Loss: 87.1585\n",
      "10475.056716918945\n",
      "Epoch [43/50], Batch 109/120, Train Loss: 96.7588\n",
      "10569.495513916016\n",
      "Epoch [43/50], Batch 110/120, Train Loss: 94.4388\n",
      "10649.727722167969\n",
      "Epoch [43/50], Batch 111/120, Train Loss: 80.2322\n",
      "10757.247817993164\n",
      "Epoch [43/50], Batch 112/120, Train Loss: 107.5201\n",
      "10889.067428588867\n",
      "Epoch [43/50], Batch 113/120, Train Loss: 131.8196\n",
      "10993.219268798828\n",
      "Epoch [43/50], Batch 114/120, Train Loss: 104.1518\n",
      "11089.095085144043\n",
      "Epoch [43/50], Batch 115/120, Train Loss: 95.8758\n",
      "11175.457015991211\n",
      "Epoch [43/50], Batch 116/120, Train Loss: 86.3619\n",
      "11256.42741394043\n",
      "Epoch [43/50], Batch 117/120, Train Loss: 80.9704\n",
      "11348.831787109375\n",
      "Epoch [43/50], Batch 118/120, Train Loss: 92.4044\n",
      "11463.00479888916\n",
      "Epoch [43/50], Batch 119/120, Train Loss: 114.1730\n",
      "11530.463150024414\n",
      "Epoch [43/50], Batch 120/120, Train Loss: 67.4584\n",
      "Epoch [43/50], Train Loss: 96.0872, Validation Loss: 113.5363\n",
      "94.34442138671875\n",
      "Epoch [44/50], Batch 1/120, Train Loss: 94.3444\n",
      "197.22888946533203\n",
      "Epoch [44/50], Batch 2/120, Train Loss: 102.8845\n",
      "278.6184310913086\n",
      "Epoch [44/50], Batch 3/120, Train Loss: 81.3895\n",
      "392.98380279541016\n",
      "Epoch [44/50], Batch 4/120, Train Loss: 114.3654\n",
      "488.44686126708984\n",
      "Epoch [44/50], Batch 5/120, Train Loss: 95.4631\n",
      "584.4810409545898\n",
      "Epoch [44/50], Batch 6/120, Train Loss: 96.0342\n",
      "700.8528213500977\n",
      "Epoch [44/50], Batch 7/120, Train Loss: 116.3718\n",
      "785.821907043457\n",
      "Epoch [44/50], Batch 8/120, Train Loss: 84.9691\n",
      "892.6532974243164\n",
      "Epoch [44/50], Batch 9/120, Train Loss: 106.8314\n",
      "998.1882858276367\n",
      "Epoch [44/50], Batch 10/120, Train Loss: 105.5350\n",
      "1091.6075057983398\n",
      "Epoch [44/50], Batch 11/120, Train Loss: 93.4192\n",
      "1186.0169982910156\n",
      "Epoch [44/50], Batch 12/120, Train Loss: 94.4095\n",
      "1282.4456481933594\n",
      "Epoch [44/50], Batch 13/120, Train Loss: 96.4286\n",
      "1390.8226699829102\n",
      "Epoch [44/50], Batch 14/120, Train Loss: 108.3770\n",
      "1459.3186874389648\n",
      "Epoch [44/50], Batch 15/120, Train Loss: 68.4960\n",
      "1554.6111221313477\n",
      "Epoch [44/50], Batch 16/120, Train Loss: 95.2924\n",
      "1654.140480041504\n",
      "Epoch [44/50], Batch 17/120, Train Loss: 99.5294\n",
      "1753.4856872558594\n",
      "Epoch [44/50], Batch 18/120, Train Loss: 99.3452\n",
      "1858.4551544189453\n",
      "Epoch [44/50], Batch 19/120, Train Loss: 104.9695\n",
      "1948.255615234375\n",
      "Epoch [44/50], Batch 20/120, Train Loss: 89.8005\n",
      "2053.5504608154297\n",
      "Epoch [44/50], Batch 21/120, Train Loss: 105.2948\n",
      "2151.5904998779297\n",
      "Epoch [44/50], Batch 22/120, Train Loss: 98.0400\n",
      "2245.8429565429688\n",
      "Epoch [44/50], Batch 23/120, Train Loss: 94.2525\n",
      "2353.2405014038086\n",
      "Epoch [44/50], Batch 24/120, Train Loss: 107.3975\n",
      "2453.515884399414\n",
      "Epoch [44/50], Batch 25/120, Train Loss: 100.2754\n",
      "2550.6900482177734\n",
      "Epoch [44/50], Batch 26/120, Train Loss: 97.1742\n",
      "2633.821708679199\n",
      "Epoch [44/50], Batch 27/120, Train Loss: 83.1317\n",
      "2734.4829635620117\n",
      "Epoch [44/50], Batch 28/120, Train Loss: 100.6613\n",
      "2834.2221603393555\n",
      "Epoch [44/50], Batch 29/120, Train Loss: 99.7392\n",
      "2907.683219909668\n",
      "Epoch [44/50], Batch 30/120, Train Loss: 73.4611\n",
      "2983.473533630371\n",
      "Epoch [44/50], Batch 31/120, Train Loss: 75.7903\n",
      "3086.6586303710938\n",
      "Epoch [44/50], Batch 32/120, Train Loss: 103.1851\n",
      "3194.907012939453\n",
      "Epoch [44/50], Batch 33/120, Train Loss: 108.2484\n",
      "3296.2540740966797\n",
      "Epoch [44/50], Batch 34/120, Train Loss: 101.3471\n",
      "3375.5794677734375\n",
      "Epoch [44/50], Batch 35/120, Train Loss: 79.3254\n",
      "3469.5638885498047\n",
      "Epoch [44/50], Batch 36/120, Train Loss: 93.9844\n",
      "3548.9624557495117\n",
      "Epoch [44/50], Batch 37/120, Train Loss: 79.3986\n",
      "3649.9762954711914\n",
      "Epoch [44/50], Batch 38/120, Train Loss: 101.0138\n",
      "3744.714988708496\n",
      "Epoch [44/50], Batch 39/120, Train Loss: 94.7387\n",
      "3854.9130325317383\n",
      "Epoch [44/50], Batch 40/120, Train Loss: 110.1980\n",
      "3943.4210357666016\n",
      "Epoch [44/50], Batch 41/120, Train Loss: 88.5080\n",
      "4045.426483154297\n",
      "Epoch [44/50], Batch 42/120, Train Loss: 102.0054\n",
      "4159.014083862305\n",
      "Epoch [44/50], Batch 43/120, Train Loss: 113.5876\n",
      "4243.04508972168\n",
      "Epoch [44/50], Batch 44/120, Train Loss: 84.0310\n",
      "4361.6125411987305\n",
      "Epoch [44/50], Batch 45/120, Train Loss: 118.5675\n",
      "4444.031799316406\n",
      "Epoch [44/50], Batch 46/120, Train Loss: 82.4193\n",
      "4551.135917663574\n",
      "Epoch [44/50], Batch 47/120, Train Loss: 107.1041\n",
      "4648.399436950684\n",
      "Epoch [44/50], Batch 48/120, Train Loss: 97.2635\n",
      "4740.704200744629\n",
      "Epoch [44/50], Batch 49/120, Train Loss: 92.3048\n",
      "4860.155448913574\n",
      "Epoch [44/50], Batch 50/120, Train Loss: 119.4512\n",
      "4940.336204528809\n",
      "Epoch [44/50], Batch 51/120, Train Loss: 80.1808\n",
      "5065.333641052246\n",
      "Epoch [44/50], Batch 52/120, Train Loss: 124.9974\n",
      "5158.897720336914\n",
      "Epoch [44/50], Batch 53/120, Train Loss: 93.5641\n",
      "5248.365051269531\n",
      "Epoch [44/50], Batch 54/120, Train Loss: 89.4673\n",
      "5351.5063552856445\n",
      "Epoch [44/50], Batch 55/120, Train Loss: 103.1413\n",
      "5451.907150268555\n",
      "Epoch [44/50], Batch 56/120, Train Loss: 100.4008\n",
      "5552.61491394043\n",
      "Epoch [44/50], Batch 57/120, Train Loss: 100.7078\n",
      "5651.0366287231445\n",
      "Epoch [44/50], Batch 58/120, Train Loss: 98.4217\n",
      "5734.891532897949\n",
      "Epoch [44/50], Batch 59/120, Train Loss: 83.8549\n",
      "5832.621238708496\n",
      "Epoch [44/50], Batch 60/120, Train Loss: 97.7297\n",
      "5899.610984802246\n",
      "Epoch [44/50], Batch 61/120, Train Loss: 66.9897\n",
      "5961.7416915893555\n",
      "Epoch [44/50], Batch 62/120, Train Loss: 62.1307\n",
      "6049.737190246582\n",
      "Epoch [44/50], Batch 63/120, Train Loss: 87.9955\n",
      "6153.46257019043\n",
      "Epoch [44/50], Batch 64/120, Train Loss: 103.7254\n",
      "6236.434921264648\n",
      "Epoch [44/50], Batch 65/120, Train Loss: 82.9724\n",
      "6323.397262573242\n",
      "Epoch [44/50], Batch 66/120, Train Loss: 86.9623\n",
      "6434.046676635742\n",
      "Epoch [44/50], Batch 67/120, Train Loss: 110.6494\n",
      "6529.753120422363\n",
      "Epoch [44/50], Batch 68/120, Train Loss: 95.7064\n",
      "6613.931938171387\n",
      "Epoch [44/50], Batch 69/120, Train Loss: 84.1788\n",
      "6707.28263092041\n",
      "Epoch [44/50], Batch 70/120, Train Loss: 93.3507\n",
      "6809.934677124023\n",
      "Epoch [44/50], Batch 71/120, Train Loss: 102.6520\n",
      "6902.069107055664\n",
      "Epoch [44/50], Batch 72/120, Train Loss: 92.1344\n",
      "6995.069519042969\n",
      "Epoch [44/50], Batch 73/120, Train Loss: 93.0004\n",
      "7093.974670410156\n",
      "Epoch [44/50], Batch 74/120, Train Loss: 98.9052\n",
      "7181.490379333496\n",
      "Epoch [44/50], Batch 75/120, Train Loss: 87.5157\n",
      "7261.473701477051\n",
      "Epoch [44/50], Batch 76/120, Train Loss: 79.9833\n",
      "7361.120185852051\n",
      "Epoch [44/50], Batch 77/120, Train Loss: 99.6465\n",
      "7449.878364562988\n",
      "Epoch [44/50], Batch 78/120, Train Loss: 88.7582\n",
      "7530.7128829956055\n",
      "Epoch [44/50], Batch 79/120, Train Loss: 80.8345\n",
      "7639.4038162231445\n",
      "Epoch [44/50], Batch 80/120, Train Loss: 108.6909\n",
      "7739.063781738281\n",
      "Epoch [44/50], Batch 81/120, Train Loss: 99.6600\n",
      "7825.0714111328125\n",
      "Epoch [44/50], Batch 82/120, Train Loss: 86.0076\n",
      "7956.156967163086\n",
      "Epoch [44/50], Batch 83/120, Train Loss: 131.0856\n",
      "8029.400856018066\n",
      "Epoch [44/50], Batch 84/120, Train Loss: 73.2439\n",
      "8110.629997253418\n",
      "Epoch [44/50], Batch 85/120, Train Loss: 81.2291\n",
      "8226.494911193848\n",
      "Epoch [44/50], Batch 86/120, Train Loss: 115.8649\n",
      "8297.664817810059\n",
      "Epoch [44/50], Batch 87/120, Train Loss: 71.1699\n",
      "8380.782066345215\n",
      "Epoch [44/50], Batch 88/120, Train Loss: 83.1172\n",
      "8472.744491577148\n",
      "Epoch [44/50], Batch 89/120, Train Loss: 91.9624\n",
      "8570.837104797363\n",
      "Epoch [44/50], Batch 90/120, Train Loss: 98.0926\n",
      "8662.507835388184\n",
      "Epoch [44/50], Batch 91/120, Train Loss: 91.6707\n",
      "8739.942749023438\n",
      "Epoch [44/50], Batch 92/120, Train Loss: 77.4349\n",
      "8813.722686767578\n",
      "Epoch [44/50], Batch 93/120, Train Loss: 73.7799\n",
      "8903.82772064209\n",
      "Epoch [44/50], Batch 94/120, Train Loss: 90.1050\n",
      "8999.128410339355\n",
      "Epoch [44/50], Batch 95/120, Train Loss: 95.3007\n",
      "9089.506843566895\n",
      "Epoch [44/50], Batch 96/120, Train Loss: 90.3784\n",
      "9177.200294494629\n",
      "Epoch [44/50], Batch 97/120, Train Loss: 87.6935\n",
      "9245.929008483887\n",
      "Epoch [44/50], Batch 98/120, Train Loss: 68.7287\n",
      "9358.802291870117\n",
      "Epoch [44/50], Batch 99/120, Train Loss: 112.8733\n",
      "9452.999130249023\n",
      "Epoch [44/50], Batch 100/120, Train Loss: 94.1968\n",
      "9528.468521118164\n",
      "Epoch [44/50], Batch 101/120, Train Loss: 75.4694\n",
      "9630.24040222168\n",
      "Epoch [44/50], Batch 102/120, Train Loss: 101.7719\n",
      "9719.30224609375\n",
      "Epoch [44/50], Batch 103/120, Train Loss: 89.0618\n",
      "9818.921409606934\n",
      "Epoch [44/50], Batch 104/120, Train Loss: 99.6192\n",
      "9905.417747497559\n",
      "Epoch [44/50], Batch 105/120, Train Loss: 86.4963\n",
      "9991.918167114258\n",
      "Epoch [44/50], Batch 106/120, Train Loss: 86.5004\n",
      "10095.845581054688\n",
      "Epoch [44/50], Batch 107/120, Train Loss: 103.9274\n",
      "10212.403526306152\n",
      "Epoch [44/50], Batch 108/120, Train Loss: 116.5579\n",
      "10311.392921447754\n",
      "Epoch [44/50], Batch 109/120, Train Loss: 98.9894\n",
      "10394.743705749512\n",
      "Epoch [44/50], Batch 110/120, Train Loss: 83.3508\n",
      "10485.809593200684\n",
      "Epoch [44/50], Batch 111/120, Train Loss: 91.0659\n",
      "10600.747611999512\n",
      "Epoch [44/50], Batch 112/120, Train Loss: 114.9380\n",
      "10707.097221374512\n",
      "Epoch [44/50], Batch 113/120, Train Loss: 106.3496\n",
      "10815.664421081543\n",
      "Epoch [44/50], Batch 114/120, Train Loss: 108.5672\n",
      "10907.928100585938\n",
      "Epoch [44/50], Batch 115/120, Train Loss: 92.2637\n",
      "11010.062042236328\n",
      "Epoch [44/50], Batch 116/120, Train Loss: 102.1339\n",
      "11106.909934997559\n",
      "Epoch [44/50], Batch 117/120, Train Loss: 96.8479\n",
      "11195.4838180542\n",
      "Epoch [44/50], Batch 118/120, Train Loss: 88.5739\n",
      "11293.462196350098\n",
      "Epoch [44/50], Batch 119/120, Train Loss: 97.9784\n",
      "11395.952659606934\n",
      "Epoch [44/50], Batch 120/120, Train Loss: 102.4905\n",
      "Epoch [44/50], Train Loss: 94.9663, Validation Loss: 114.7785\n",
      "82.01569366455078\n",
      "Epoch [45/50], Batch 1/120, Train Loss: 82.0157\n",
      "176.0761489868164\n",
      "Epoch [45/50], Batch 2/120, Train Loss: 94.0605\n",
      "294.2452392578125\n",
      "Epoch [45/50], Batch 3/120, Train Loss: 118.1691\n",
      "372.171142578125\n",
      "Epoch [45/50], Batch 4/120, Train Loss: 77.9259\n",
      "461.1299514770508\n",
      "Epoch [45/50], Batch 5/120, Train Loss: 88.9588\n",
      "551.0630416870117\n",
      "Epoch [45/50], Batch 6/120, Train Loss: 89.9331\n",
      "633.8456420898438\n",
      "Epoch [45/50], Batch 7/120, Train Loss: 82.7826\n",
      "736.5631256103516\n",
      "Epoch [45/50], Batch 8/120, Train Loss: 102.7175\n",
      "842.5907592773438\n",
      "Epoch [45/50], Batch 9/120, Train Loss: 106.0276\n",
      "914.4603576660156\n",
      "Epoch [45/50], Batch 10/120, Train Loss: 71.8696\n",
      "996.4767913818359\n",
      "Epoch [45/50], Batch 11/120, Train Loss: 82.0164\n",
      "1083.9195861816406\n",
      "Epoch [45/50], Batch 12/120, Train Loss: 87.4428\n",
      "1180.7833099365234\n",
      "Epoch [45/50], Batch 13/120, Train Loss: 96.8637\n",
      "1253.5686340332031\n",
      "Epoch [45/50], Batch 14/120, Train Loss: 72.7853\n",
      "1338.669090270996\n",
      "Epoch [45/50], Batch 15/120, Train Loss: 85.1005\n",
      "1423.2478103637695\n",
      "Epoch [45/50], Batch 16/120, Train Loss: 84.5787\n",
      "1524.649543762207\n",
      "Epoch [45/50], Batch 17/120, Train Loss: 101.4017\n",
      "1611.3926467895508\n",
      "Epoch [45/50], Batch 18/120, Train Loss: 86.7431\n",
      "1700.4402694702148\n",
      "Epoch [45/50], Batch 19/120, Train Loss: 89.0476\n",
      "1791.3311233520508\n",
      "Epoch [45/50], Batch 20/120, Train Loss: 90.8909\n",
      "1867.9947052001953\n",
      "Epoch [45/50], Batch 21/120, Train Loss: 76.6636\n",
      "1971.5955200195312\n",
      "Epoch [45/50], Batch 22/120, Train Loss: 103.6008\n",
      "2075.7578735351562\n",
      "Epoch [45/50], Batch 23/120, Train Loss: 104.1624\n",
      "2174.5026245117188\n",
      "Epoch [45/50], Batch 24/120, Train Loss: 98.7448\n",
      "2261.540237426758\n",
      "Epoch [45/50], Batch 25/120, Train Loss: 87.0376\n",
      "2371.212432861328\n",
      "Epoch [45/50], Batch 26/120, Train Loss: 109.6722\n",
      "2483.1128540039062\n",
      "Epoch [45/50], Batch 27/120, Train Loss: 111.9004\n",
      "2583.295051574707\n",
      "Epoch [45/50], Batch 28/120, Train Loss: 100.1822\n",
      "2656.377342224121\n",
      "Epoch [45/50], Batch 29/120, Train Loss: 73.0823\n",
      "2754.5451889038086\n",
      "Epoch [45/50], Batch 30/120, Train Loss: 98.1678\n",
      "2852.1998291015625\n",
      "Epoch [45/50], Batch 31/120, Train Loss: 97.6546\n",
      "2948.3079681396484\n",
      "Epoch [45/50], Batch 32/120, Train Loss: 96.1081\n",
      "3050.8047256469727\n",
      "Epoch [45/50], Batch 33/120, Train Loss: 102.4968\n",
      "3164.5564041137695\n",
      "Epoch [45/50], Batch 34/120, Train Loss: 113.7517\n",
      "3248.7708587646484\n",
      "Epoch [45/50], Batch 35/120, Train Loss: 84.2145\n",
      "3330.690872192383\n",
      "Epoch [45/50], Batch 36/120, Train Loss: 81.9200\n",
      "3414.572578430176\n",
      "Epoch [45/50], Batch 37/120, Train Loss: 83.8817\n",
      "3516.2713165283203\n",
      "Epoch [45/50], Batch 38/120, Train Loss: 101.6987\n",
      "3635.721824645996\n",
      "Epoch [45/50], Batch 39/120, Train Loss: 119.4505\n",
      "3736.106346130371\n",
      "Epoch [45/50], Batch 40/120, Train Loss: 100.3845\n",
      "3840.0725326538086\n",
      "Epoch [45/50], Batch 41/120, Train Loss: 103.9662\n",
      "3966.1466903686523\n",
      "Epoch [45/50], Batch 42/120, Train Loss: 126.0742\n",
      "4070.8019943237305\n",
      "Epoch [45/50], Batch 43/120, Train Loss: 104.6553\n",
      "4168.821876525879\n",
      "Epoch [45/50], Batch 44/120, Train Loss: 98.0199\n",
      "4253.353706359863\n",
      "Epoch [45/50], Batch 45/120, Train Loss: 84.5318\n",
      "4337.303665161133\n",
      "Epoch [45/50], Batch 46/120, Train Loss: 83.9500\n",
      "4419.560363769531\n",
      "Epoch [45/50], Batch 47/120, Train Loss: 82.2567\n",
      "4536.052230834961\n",
      "Epoch [45/50], Batch 48/120, Train Loss: 116.4919\n",
      "4653.125732421875\n",
      "Epoch [45/50], Batch 49/120, Train Loss: 117.0735\n",
      "4742.9713134765625\n",
      "Epoch [45/50], Batch 50/120, Train Loss: 89.8456\n",
      "4824.845428466797\n",
      "Epoch [45/50], Batch 51/120, Train Loss: 81.8741\n",
      "4915.459617614746\n",
      "Epoch [45/50], Batch 52/120, Train Loss: 90.6142\n",
      "5013.44149017334\n",
      "Epoch [45/50], Batch 53/120, Train Loss: 97.9819\n",
      "5095.166297912598\n",
      "Epoch [45/50], Batch 54/120, Train Loss: 81.7248\n",
      "5174.267143249512\n",
      "Epoch [45/50], Batch 55/120, Train Loss: 79.1008\n",
      "5250.8449630737305\n",
      "Epoch [45/50], Batch 56/120, Train Loss: 76.5778\n",
      "5351.0559005737305\n",
      "Epoch [45/50], Batch 57/120, Train Loss: 100.2109\n",
      "5459.668113708496\n",
      "Epoch [45/50], Batch 58/120, Train Loss: 108.6122\n",
      "5557.960792541504\n",
      "Epoch [45/50], Batch 59/120, Train Loss: 98.2927\n",
      "5643.928977966309\n",
      "Epoch [45/50], Batch 60/120, Train Loss: 85.9682\n",
      "5736.338706970215\n",
      "Epoch [45/50], Batch 61/120, Train Loss: 92.4097\n",
      "5853.624061584473\n",
      "Epoch [45/50], Batch 62/120, Train Loss: 117.2854\n",
      "5953.4804763793945\n",
      "Epoch [45/50], Batch 63/120, Train Loss: 99.8564\n",
      "6047.724555969238\n",
      "Epoch [45/50], Batch 64/120, Train Loss: 94.2441\n",
      "6146.28133392334\n",
      "Epoch [45/50], Batch 65/120, Train Loss: 98.5568\n",
      "6263.336807250977\n",
      "Epoch [45/50], Batch 66/120, Train Loss: 117.0555\n",
      "6352.374565124512\n",
      "Epoch [45/50], Batch 67/120, Train Loss: 89.0378\n",
      "6442.220481872559\n",
      "Epoch [45/50], Batch 68/120, Train Loss: 89.8459\n",
      "6528.549301147461\n",
      "Epoch [45/50], Batch 69/120, Train Loss: 86.3288\n",
      "6629.804138183594\n",
      "Epoch [45/50], Batch 70/120, Train Loss: 101.2548\n",
      "6705.768089294434\n",
      "Epoch [45/50], Batch 71/120, Train Loss: 75.9640\n",
      "6811.628761291504\n",
      "Epoch [45/50], Batch 72/120, Train Loss: 105.8607\n",
      "6899.987083435059\n",
      "Epoch [45/50], Batch 73/120, Train Loss: 88.3583\n",
      "6979.416053771973\n",
      "Epoch [45/50], Batch 74/120, Train Loss: 79.4290\n",
      "7059.942695617676\n",
      "Epoch [45/50], Batch 75/120, Train Loss: 80.5266\n",
      "7157.512916564941\n",
      "Epoch [45/50], Batch 76/120, Train Loss: 97.5702\n",
      "7255.220634460449\n",
      "Epoch [45/50], Batch 77/120, Train Loss: 97.7077\n",
      "7356.441650390625\n",
      "Epoch [45/50], Batch 78/120, Train Loss: 101.2210\n",
      "7474.509056091309\n",
      "Epoch [45/50], Batch 79/120, Train Loss: 118.0674\n",
      "7553.549629211426\n",
      "Epoch [45/50], Batch 80/120, Train Loss: 79.0406\n",
      "7631.761405944824\n",
      "Epoch [45/50], Batch 81/120, Train Loss: 78.2118\n",
      "7714.437446594238\n",
      "Epoch [45/50], Batch 82/120, Train Loss: 82.6760\n",
      "7813.51505279541\n",
      "Epoch [45/50], Batch 83/120, Train Loss: 99.0776\n",
      "7926.131202697754\n",
      "Epoch [45/50], Batch 84/120, Train Loss: 112.6161\n",
      "8013.294204711914\n",
      "Epoch [45/50], Batch 85/120, Train Loss: 87.1630\n",
      "8118.371520996094\n",
      "Epoch [45/50], Batch 86/120, Train Loss: 105.0773\n",
      "8204.168334960938\n",
      "Epoch [45/50], Batch 87/120, Train Loss: 85.7968\n",
      "8298.385429382324\n",
      "Epoch [45/50], Batch 88/120, Train Loss: 94.2171\n",
      "8404.620735168457\n",
      "Epoch [45/50], Batch 89/120, Train Loss: 106.2353\n",
      "8498.695030212402\n",
      "Epoch [45/50], Batch 90/120, Train Loss: 94.0743\n",
      "8585.899040222168\n",
      "Epoch [45/50], Batch 91/120, Train Loss: 87.2040\n",
      "8690.59383392334\n",
      "Epoch [45/50], Batch 92/120, Train Loss: 104.6948\n",
      "8794.737800598145\n",
      "Epoch [45/50], Batch 93/120, Train Loss: 104.1440\n",
      "8865.738456726074\n",
      "Epoch [45/50], Batch 94/120, Train Loss: 71.0007\n",
      "8963.198440551758\n",
      "Epoch [45/50], Batch 95/120, Train Loss: 97.4600\n",
      "9036.493911743164\n",
      "Epoch [45/50], Batch 96/120, Train Loss: 73.2955\n",
      "9124.531440734863\n",
      "Epoch [45/50], Batch 97/120, Train Loss: 88.0375\n",
      "9225.343772888184\n",
      "Epoch [45/50], Batch 98/120, Train Loss: 100.8123\n",
      "9341.660858154297\n",
      "Epoch [45/50], Batch 99/120, Train Loss: 116.3171\n",
      "9448.771614074707\n",
      "Epoch [45/50], Batch 100/120, Train Loss: 107.1108\n",
      "9553.744132995605\n",
      "Epoch [45/50], Batch 101/120, Train Loss: 104.9725\n",
      "9659.134635925293\n",
      "Epoch [45/50], Batch 102/120, Train Loss: 105.3905\n",
      "9755.791580200195\n",
      "Epoch [45/50], Batch 103/120, Train Loss: 96.6569\n",
      "9839.875305175781\n",
      "Epoch [45/50], Batch 104/120, Train Loss: 84.0837\n",
      "9924.877578735352\n",
      "Epoch [45/50], Batch 105/120, Train Loss: 85.0023\n",
      "10014.695037841797\n",
      "Epoch [45/50], Batch 106/120, Train Loss: 89.8175\n",
      "10130.857749938965\n",
      "Epoch [45/50], Batch 107/120, Train Loss: 116.1627\n",
      "10216.191673278809\n",
      "Epoch [45/50], Batch 108/120, Train Loss: 85.3339\n",
      "10306.639427185059\n",
      "Epoch [45/50], Batch 109/120, Train Loss: 90.4478\n",
      "10383.248191833496\n",
      "Epoch [45/50], Batch 110/120, Train Loss: 76.6088\n",
      "10466.391716003418\n",
      "Epoch [45/50], Batch 111/120, Train Loss: 83.1435\n",
      "10529.894584655762\n",
      "Epoch [45/50], Batch 112/120, Train Loss: 63.5029\n",
      "10622.795463562012\n",
      "Epoch [45/50], Batch 113/120, Train Loss: 92.9009\n",
      "10714.747261047363\n",
      "Epoch [45/50], Batch 114/120, Train Loss: 91.9518\n",
      "10816.314483642578\n",
      "Epoch [45/50], Batch 115/120, Train Loss: 101.5672\n",
      "10929.393608093262\n",
      "Epoch [45/50], Batch 116/120, Train Loss: 113.0791\n",
      "11028.456764221191\n",
      "Epoch [45/50], Batch 117/120, Train Loss: 99.0632\n",
      "11118.688415527344\n",
      "Epoch [45/50], Batch 118/120, Train Loss: 90.2317\n",
      "11217.150100708008\n",
      "Epoch [45/50], Batch 119/120, Train Loss: 98.4617\n",
      "11334.570404052734\n",
      "Epoch [45/50], Batch 120/120, Train Loss: 117.4203\n",
      "Epoch [45/50], Train Loss: 94.4548, Validation Loss: 113.9975\n",
      "104.38856506347656\n",
      "Epoch [46/50], Batch 1/120, Train Loss: 104.3886\n",
      "211.1890869140625\n",
      "Epoch [46/50], Batch 2/120, Train Loss: 106.8005\n",
      "307.6057434082031\n",
      "Epoch [46/50], Batch 3/120, Train Loss: 96.4167\n",
      "371.89717864990234\n",
      "Epoch [46/50], Batch 4/120, Train Loss: 64.2914\n",
      "473.5255126953125\n",
      "Epoch [46/50], Batch 5/120, Train Loss: 101.6283\n",
      "563.2111511230469\n",
      "Epoch [46/50], Batch 6/120, Train Loss: 89.6856\n",
      "650.2105712890625\n",
      "Epoch [46/50], Batch 7/120, Train Loss: 86.9994\n",
      "745.8555450439453\n",
      "Epoch [46/50], Batch 8/120, Train Loss: 95.6450\n",
      "857.8358383178711\n",
      "Epoch [46/50], Batch 9/120, Train Loss: 111.9803\n",
      "945.8819198608398\n",
      "Epoch [46/50], Batch 10/120, Train Loss: 88.0461\n",
      "1044.5275955200195\n",
      "Epoch [46/50], Batch 11/120, Train Loss: 98.6457\n",
      "1123.4354629516602\n",
      "Epoch [46/50], Batch 12/120, Train Loss: 78.9079\n",
      "1208.5768814086914\n",
      "Epoch [46/50], Batch 13/120, Train Loss: 85.1414\n",
      "1297.4987335205078\n",
      "Epoch [46/50], Batch 14/120, Train Loss: 88.9219\n",
      "1369.7171783447266\n",
      "Epoch [46/50], Batch 15/120, Train Loss: 72.2184\n",
      "1478.0909881591797\n",
      "Epoch [46/50], Batch 16/120, Train Loss: 108.3738\n",
      "1560.792106628418\n",
      "Epoch [46/50], Batch 17/120, Train Loss: 82.7011\n",
      "1654.9910278320312\n",
      "Epoch [46/50], Batch 18/120, Train Loss: 94.1989\n",
      "1735.5961303710938\n",
      "Epoch [46/50], Batch 19/120, Train Loss: 80.6051\n",
      "1827.7410354614258\n",
      "Epoch [46/50], Batch 20/120, Train Loss: 92.1449\n",
      "1952.8510513305664\n",
      "Epoch [46/50], Batch 21/120, Train Loss: 125.1100\n",
      "2051.354835510254\n",
      "Epoch [46/50], Batch 22/120, Train Loss: 98.5038\n",
      "2147.6548614501953\n",
      "Epoch [46/50], Batch 23/120, Train Loss: 96.3000\n",
      "2263.134796142578\n",
      "Epoch [46/50], Batch 24/120, Train Loss: 115.4799\n",
      "2364.7101135253906\n",
      "Epoch [46/50], Batch 25/120, Train Loss: 101.5753\n",
      "2457.7252655029297\n",
      "Epoch [46/50], Batch 26/120, Train Loss: 93.0152\n",
      "2545.608444213867\n",
      "Epoch [46/50], Batch 27/120, Train Loss: 87.8832\n",
      "2645.398193359375\n",
      "Epoch [46/50], Batch 28/120, Train Loss: 99.7897\n",
      "2732.6261672973633\n",
      "Epoch [46/50], Batch 29/120, Train Loss: 87.2280\n",
      "2840.5518112182617\n",
      "Epoch [46/50], Batch 30/120, Train Loss: 107.9256\n",
      "2926.234474182129\n",
      "Epoch [46/50], Batch 31/120, Train Loss: 85.6827\n",
      "3018.942939758301\n",
      "Epoch [46/50], Batch 32/120, Train Loss: 92.7085\n",
      "3101.9530487060547\n",
      "Epoch [46/50], Batch 33/120, Train Loss: 83.0101\n",
      "3192.032402038574\n",
      "Epoch [46/50], Batch 34/120, Train Loss: 90.0794\n",
      "3276.3370361328125\n",
      "Epoch [46/50], Batch 35/120, Train Loss: 84.3046\n",
      "3371.4752807617188\n",
      "Epoch [46/50], Batch 36/120, Train Loss: 95.1382\n",
      "3479.26123046875\n",
      "Epoch [46/50], Batch 37/120, Train Loss: 107.7859\n",
      "3588.886947631836\n",
      "Epoch [46/50], Batch 38/120, Train Loss: 109.6257\n",
      "3686.728416442871\n",
      "Epoch [46/50], Batch 39/120, Train Loss: 97.8415\n",
      "3783.6575469970703\n",
      "Epoch [46/50], Batch 40/120, Train Loss: 96.9291\n",
      "3886.4560546875\n",
      "Epoch [46/50], Batch 41/120, Train Loss: 102.7985\n",
      "3977.7621459960938\n",
      "Epoch [46/50], Batch 42/120, Train Loss: 91.3061\n",
      "4079.4938049316406\n",
      "Epoch [46/50], Batch 43/120, Train Loss: 101.7317\n",
      "4179.329055786133\n",
      "Epoch [46/50], Batch 44/120, Train Loss: 99.8353\n",
      "4276.294006347656\n",
      "Epoch [46/50], Batch 45/120, Train Loss: 96.9650\n",
      "4369.3743896484375\n",
      "Epoch [46/50], Batch 46/120, Train Loss: 93.0804\n",
      "4452.232955932617\n",
      "Epoch [46/50], Batch 47/120, Train Loss: 82.8586\n",
      "4533.249603271484\n",
      "Epoch [46/50], Batch 48/120, Train Loss: 81.0166\n",
      "4646.196914672852\n",
      "Epoch [46/50], Batch 49/120, Train Loss: 112.9473\n",
      "4739.574241638184\n",
      "Epoch [46/50], Batch 50/120, Train Loss: 93.3773\n",
      "4852.537315368652\n",
      "Epoch [46/50], Batch 51/120, Train Loss: 112.9631\n",
      "4927.4340744018555\n",
      "Epoch [46/50], Batch 52/120, Train Loss: 74.8968\n",
      "5018.661674499512\n",
      "Epoch [46/50], Batch 53/120, Train Loss: 91.2276\n",
      "5117.749320983887\n",
      "Epoch [46/50], Batch 54/120, Train Loss: 99.0876\n",
      "5199.9736404418945\n",
      "Epoch [46/50], Batch 55/120, Train Loss: 82.2243\n",
      "5305.478416442871\n",
      "Epoch [46/50], Batch 56/120, Train Loss: 105.5048\n",
      "5390.221221923828\n",
      "Epoch [46/50], Batch 57/120, Train Loss: 84.7428\n",
      "5508.157333374023\n",
      "Epoch [46/50], Batch 58/120, Train Loss: 117.9361\n",
      "5607.039176940918\n",
      "Epoch [46/50], Batch 59/120, Train Loss: 98.8818\n",
      "5708.28768157959\n",
      "Epoch [46/50], Batch 60/120, Train Loss: 101.2485\n",
      "5786.3679122924805\n",
      "Epoch [46/50], Batch 61/120, Train Loss: 78.0802\n",
      "5877.542091369629\n",
      "Epoch [46/50], Batch 62/120, Train Loss: 91.1742\n",
      "5968.0412673950195\n",
      "Epoch [46/50], Batch 63/120, Train Loss: 90.4992\n",
      "6083.713394165039\n",
      "Epoch [46/50], Batch 64/120, Train Loss: 115.6721\n",
      "6171.1998291015625\n",
      "Epoch [46/50], Batch 65/120, Train Loss: 87.4864\n",
      "6273.212951660156\n",
      "Epoch [46/50], Batch 66/120, Train Loss: 102.0131\n",
      "6380.080360412598\n",
      "Epoch [46/50], Batch 67/120, Train Loss: 106.8674\n",
      "6445.56827545166\n",
      "Epoch [46/50], Batch 68/120, Train Loss: 65.4879\n",
      "6530.150764465332\n",
      "Epoch [46/50], Batch 69/120, Train Loss: 84.5825\n",
      "6615.336387634277\n",
      "Epoch [46/50], Batch 70/120, Train Loss: 85.1856\n",
      "6733.901710510254\n",
      "Epoch [46/50], Batch 71/120, Train Loss: 118.5653\n",
      "6825.79337310791\n",
      "Epoch [46/50], Batch 72/120, Train Loss: 91.8917\n",
      "6923.987976074219\n",
      "Epoch [46/50], Batch 73/120, Train Loss: 98.1946\n",
      "7041.599189758301\n",
      "Epoch [46/50], Batch 74/120, Train Loss: 117.6112\n",
      "7137.498794555664\n",
      "Epoch [46/50], Batch 75/120, Train Loss: 95.8996\n",
      "7243.811981201172\n",
      "Epoch [46/50], Batch 76/120, Train Loss: 106.3132\n",
      "7347.107269287109\n",
      "Epoch [46/50], Batch 77/120, Train Loss: 103.2953\n",
      "7446.299278259277\n",
      "Epoch [46/50], Batch 78/120, Train Loss: 99.1920\n",
      "7527.22957611084\n",
      "Epoch [46/50], Batch 79/120, Train Loss: 80.9303\n",
      "7615.98161315918\n",
      "Epoch [46/50], Batch 80/120, Train Loss: 88.7520\n",
      "7728.472915649414\n",
      "Epoch [46/50], Batch 81/120, Train Loss: 112.4913\n",
      "7820.328475952148\n",
      "Epoch [46/50], Batch 82/120, Train Loss: 91.8556\n",
      "7929.656173706055\n",
      "Epoch [46/50], Batch 83/120, Train Loss: 109.3277\n",
      "8022.938247680664\n",
      "Epoch [46/50], Batch 84/120, Train Loss: 93.2821\n",
      "8105.940933227539\n",
      "Epoch [46/50], Batch 85/120, Train Loss: 83.0027\n",
      "8193.147491455078\n",
      "Epoch [46/50], Batch 86/120, Train Loss: 87.2066\n",
      "8304.677047729492\n",
      "Epoch [46/50], Batch 87/120, Train Loss: 111.5296\n",
      "8407.056381225586\n",
      "Epoch [46/50], Batch 88/120, Train Loss: 102.3793\n",
      "8487.906066894531\n",
      "Epoch [46/50], Batch 89/120, Train Loss: 80.8497\n",
      "8576.806350708008\n",
      "Epoch [46/50], Batch 90/120, Train Loss: 88.9003\n",
      "8670.811416625977\n",
      "Epoch [46/50], Batch 91/120, Train Loss: 94.0051\n",
      "8752.237503051758\n",
      "Epoch [46/50], Batch 92/120, Train Loss: 81.4261\n",
      "8837.689483642578\n",
      "Epoch [46/50], Batch 93/120, Train Loss: 85.4520\n",
      "8940.344589233398\n",
      "Epoch [46/50], Batch 94/120, Train Loss: 102.6551\n",
      "9044.876739501953\n",
      "Epoch [46/50], Batch 95/120, Train Loss: 104.5322\n",
      "9142.634788513184\n",
      "Epoch [46/50], Batch 96/120, Train Loss: 97.7580\n",
      "9228.797546386719\n",
      "Epoch [46/50], Batch 97/120, Train Loss: 86.1628\n",
      "9340.087585449219\n",
      "Epoch [46/50], Batch 98/120, Train Loss: 111.2900\n",
      "9437.497940063477\n",
      "Epoch [46/50], Batch 99/120, Train Loss: 97.4104\n",
      "9535.527801513672\n",
      "Epoch [46/50], Batch 100/120, Train Loss: 98.0299\n",
      "9621.385040283203\n",
      "Epoch [46/50], Batch 101/120, Train Loss: 85.8572\n",
      "9702.348083496094\n",
      "Epoch [46/50], Batch 102/120, Train Loss: 80.9630\n",
      "9773.232711791992\n",
      "Epoch [46/50], Batch 103/120, Train Loss: 70.8846\n",
      "9862.402503967285\n",
      "Epoch [46/50], Batch 104/120, Train Loss: 89.1698\n",
      "9945.699600219727\n",
      "Epoch [46/50], Batch 105/120, Train Loss: 83.2971\n",
      "10065.47055053711\n",
      "Epoch [46/50], Batch 106/120, Train Loss: 119.7710\n",
      "10160.029739379883\n",
      "Epoch [46/50], Batch 107/120, Train Loss: 94.5592\n",
      "10257.494903564453\n",
      "Epoch [46/50], Batch 108/120, Train Loss: 97.4652\n",
      "10352.627059936523\n",
      "Epoch [46/50], Batch 109/120, Train Loss: 95.1322\n",
      "10452.902069091797\n",
      "Epoch [46/50], Batch 110/120, Train Loss: 100.2750\n",
      "10547.760040283203\n",
      "Epoch [46/50], Batch 111/120, Train Loss: 94.8580\n",
      "10640.569625854492\n",
      "Epoch [46/50], Batch 112/120, Train Loss: 92.8096\n",
      "10739.772338867188\n",
      "Epoch [46/50], Batch 113/120, Train Loss: 99.2027\n",
      "10846.872512817383\n",
      "Epoch [46/50], Batch 114/120, Train Loss: 107.1002\n",
      "10930.886665344238\n",
      "Epoch [46/50], Batch 115/120, Train Loss: 84.0142\n",
      "11035.987983703613\n",
      "Epoch [46/50], Batch 116/120, Train Loss: 105.1013\n",
      "11132.683601379395\n",
      "Epoch [46/50], Batch 117/120, Train Loss: 96.6956\n",
      "11247.936477661133\n",
      "Epoch [46/50], Batch 118/120, Train Loss: 115.2529\n",
      "11340.255271911621\n",
      "Epoch [46/50], Batch 119/120, Train Loss: 92.3188\n",
      "11434.234558105469\n",
      "Epoch [46/50], Batch 120/120, Train Loss: 93.9793\n",
      "Epoch [46/50], Train Loss: 95.2853, Validation Loss: 114.5119\n",
      "94.8812255859375\n",
      "Epoch [47/50], Batch 1/120, Train Loss: 94.8812\n",
      "187.41159057617188\n",
      "Epoch [47/50], Batch 2/120, Train Loss: 92.5304\n",
      "281.53529357910156\n",
      "Epoch [47/50], Batch 3/120, Train Loss: 94.1237\n",
      "382.0529479980469\n",
      "Epoch [47/50], Batch 4/120, Train Loss: 100.5177\n",
      "488.92786407470703\n",
      "Epoch [47/50], Batch 5/120, Train Loss: 106.8749\n",
      "565.8713836669922\n",
      "Epoch [47/50], Batch 6/120, Train Loss: 76.9435\n",
      "654.5933837890625\n",
      "Epoch [47/50], Batch 7/120, Train Loss: 88.7220\n",
      "733.4496688842773\n",
      "Epoch [47/50], Batch 8/120, Train Loss: 78.8563\n",
      "830.1063842773438\n",
      "Epoch [47/50], Batch 9/120, Train Loss: 96.6567\n",
      "927.5723495483398\n",
      "Epoch [47/50], Batch 10/120, Train Loss: 97.4660\n",
      "1008.0710067749023\n",
      "Epoch [47/50], Batch 11/120, Train Loss: 80.4987\n",
      "1135.5621490478516\n",
      "Epoch [47/50], Batch 12/120, Train Loss: 127.4911\n",
      "1211.702537536621\n",
      "Epoch [47/50], Batch 13/120, Train Loss: 76.1404\n",
      "1287.3160858154297\n",
      "Epoch [47/50], Batch 14/120, Train Loss: 75.6135\n",
      "1357.1671905517578\n",
      "Epoch [47/50], Batch 15/120, Train Loss: 69.8511\n",
      "1434.7968673706055\n",
      "Epoch [47/50], Batch 16/120, Train Loss: 77.6297\n",
      "1528.140022277832\n",
      "Epoch [47/50], Batch 17/120, Train Loss: 93.3432\n",
      "1627.2653427124023\n",
      "Epoch [47/50], Batch 18/120, Train Loss: 99.1253\n",
      "1729.0208740234375\n",
      "Epoch [47/50], Batch 19/120, Train Loss: 101.7555\n",
      "1824.2827529907227\n",
      "Epoch [47/50], Batch 20/120, Train Loss: 95.2619\n",
      "1915.975227355957\n",
      "Epoch [47/50], Batch 21/120, Train Loss: 91.6925\n",
      "2006.4864883422852\n",
      "Epoch [47/50], Batch 22/120, Train Loss: 90.5113\n",
      "2098.0892791748047\n",
      "Epoch [47/50], Batch 23/120, Train Loss: 91.6028\n",
      "2173.385414123535\n",
      "Epoch [47/50], Batch 24/120, Train Loss: 75.2961\n",
      "2264.7895584106445\n",
      "Epoch [47/50], Batch 25/120, Train Loss: 91.4041\n",
      "2362.568962097168\n",
      "Epoch [47/50], Batch 26/120, Train Loss: 97.7794\n",
      "2463.369972229004\n",
      "Epoch [47/50], Batch 27/120, Train Loss: 100.8010\n",
      "2574.4535751342773\n",
      "Epoch [47/50], Batch 28/120, Train Loss: 111.0836\n",
      "2687.3920364379883\n",
      "Epoch [47/50], Batch 29/120, Train Loss: 112.9385\n",
      "2765.498565673828\n",
      "Epoch [47/50], Batch 30/120, Train Loss: 78.1065\n",
      "2856.0998764038086\n",
      "Epoch [47/50], Batch 31/120, Train Loss: 90.6013\n",
      "2966.334457397461\n",
      "Epoch [47/50], Batch 32/120, Train Loss: 110.2346\n",
      "3047.9750366210938\n",
      "Epoch [47/50], Batch 33/120, Train Loss: 81.6406\n",
      "3151.979461669922\n",
      "Epoch [47/50], Batch 34/120, Train Loss: 104.0044\n",
      "3252.8998794555664\n",
      "Epoch [47/50], Batch 35/120, Train Loss: 100.9204\n",
      "3342.718147277832\n",
      "Epoch [47/50], Batch 36/120, Train Loss: 89.8183\n",
      "3461.20206451416\n",
      "Epoch [47/50], Batch 37/120, Train Loss: 118.4839\n",
      "3559.000907897949\n",
      "Epoch [47/50], Batch 38/120, Train Loss: 97.7988\n",
      "3672.255630493164\n",
      "Epoch [47/50], Batch 39/120, Train Loss: 113.2547\n",
      "3763.3217163085938\n",
      "Epoch [47/50], Batch 40/120, Train Loss: 91.0661\n",
      "3873.6359634399414\n",
      "Epoch [47/50], Batch 41/120, Train Loss: 110.3142\n",
      "3961.1936569213867\n",
      "Epoch [47/50], Batch 42/120, Train Loss: 87.5577\n",
      "4031.3274993896484\n",
      "Epoch [47/50], Batch 43/120, Train Loss: 70.1338\n",
      "4140.836700439453\n",
      "Epoch [47/50], Batch 44/120, Train Loss: 109.5092\n",
      "4230.548408508301\n",
      "Epoch [47/50], Batch 45/120, Train Loss: 89.7117\n",
      "4333.451683044434\n",
      "Epoch [47/50], Batch 46/120, Train Loss: 102.9033\n",
      "4426.503845214844\n",
      "Epoch [47/50], Batch 47/120, Train Loss: 93.0522\n",
      "4525.140777587891\n",
      "Epoch [47/50], Batch 48/120, Train Loss: 98.6369\n",
      "4613.060852050781\n",
      "Epoch [47/50], Batch 49/120, Train Loss: 87.9201\n",
      "4712.1962814331055\n",
      "Epoch [47/50], Batch 50/120, Train Loss: 99.1354\n",
      "4799.656669616699\n",
      "Epoch [47/50], Batch 51/120, Train Loss: 87.4604\n",
      "4876.244316101074\n",
      "Epoch [47/50], Batch 52/120, Train Loss: 76.5876\n",
      "4970.4545974731445\n",
      "Epoch [47/50], Batch 53/120, Train Loss: 94.2103\n",
      "5052.20548248291\n",
      "Epoch [47/50], Batch 54/120, Train Loss: 81.7509\n",
      "5153.5009841918945\n",
      "Epoch [47/50], Batch 55/120, Train Loss: 101.2955\n",
      "5224.165596008301\n",
      "Epoch [47/50], Batch 56/120, Train Loss: 70.6646\n",
      "5323.39794921875\n",
      "Epoch [47/50], Batch 57/120, Train Loss: 99.2324\n",
      "5417.884353637695\n",
      "Epoch [47/50], Batch 58/120, Train Loss: 94.4864\n",
      "5528.089248657227\n",
      "Epoch [47/50], Batch 59/120, Train Loss: 110.2049\n",
      "5611.729751586914\n",
      "Epoch [47/50], Batch 60/120, Train Loss: 83.6405\n",
      "5709.386154174805\n",
      "Epoch [47/50], Batch 61/120, Train Loss: 97.6564\n",
      "5805.727821350098\n",
      "Epoch [47/50], Batch 62/120, Train Loss: 96.3417\n",
      "5891.386688232422\n",
      "Epoch [47/50], Batch 63/120, Train Loss: 85.6589\n",
      "5974.151947021484\n",
      "Epoch [47/50], Batch 64/120, Train Loss: 82.7653\n",
      "6067.641456604004\n",
      "Epoch [47/50], Batch 65/120, Train Loss: 93.4895\n",
      "6182.6804122924805\n",
      "Epoch [47/50], Batch 66/120, Train Loss: 115.0390\n",
      "6271.838691711426\n",
      "Epoch [47/50], Batch 67/120, Train Loss: 89.1583\n",
      "6357.085182189941\n",
      "Epoch [47/50], Batch 68/120, Train Loss: 85.2465\n",
      "6470.322731018066\n",
      "Epoch [47/50], Batch 69/120, Train Loss: 113.2375\n",
      "6552.532020568848\n",
      "Epoch [47/50], Batch 70/120, Train Loss: 82.2093\n",
      "6644.694061279297\n",
      "Epoch [47/50], Batch 71/120, Train Loss: 92.1620\n",
      "6728.424362182617\n",
      "Epoch [47/50], Batch 72/120, Train Loss: 83.7303\n",
      "6829.6168212890625\n",
      "Epoch [47/50], Batch 73/120, Train Loss: 101.1925\n",
      "6918.968482971191\n",
      "Epoch [47/50], Batch 74/120, Train Loss: 89.3517\n",
      "7017.945960998535\n",
      "Epoch [47/50], Batch 75/120, Train Loss: 98.9775\n",
      "7136.584861755371\n",
      "Epoch [47/50], Batch 76/120, Train Loss: 118.6389\n",
      "7228.758232116699\n",
      "Epoch [47/50], Batch 77/120, Train Loss: 92.1734\n",
      "7322.403099060059\n",
      "Epoch [47/50], Batch 78/120, Train Loss: 93.6449\n",
      "7426.973876953125\n",
      "Epoch [47/50], Batch 79/120, Train Loss: 104.5708\n",
      "7522.249176025391\n",
      "Epoch [47/50], Batch 80/120, Train Loss: 95.2753\n",
      "7618.035171508789\n",
      "Epoch [47/50], Batch 81/120, Train Loss: 95.7860\n",
      "7700.78938293457\n",
      "Epoch [47/50], Batch 82/120, Train Loss: 82.7542\n",
      "7762.601455688477\n",
      "Epoch [47/50], Batch 83/120, Train Loss: 61.8121\n",
      "7847.67578125\n",
      "Epoch [47/50], Batch 84/120, Train Loss: 85.0743\n",
      "7949.6429443359375\n",
      "Epoch [47/50], Batch 85/120, Train Loss: 101.9672\n",
      "8071.4449462890625\n",
      "Epoch [47/50], Batch 86/120, Train Loss: 121.8020\n",
      "8160.399475097656\n",
      "Epoch [47/50], Batch 87/120, Train Loss: 88.9545\n",
      "8246.329414367676\n",
      "Epoch [47/50], Batch 88/120, Train Loss: 85.9299\n",
      "8347.924575805664\n",
      "Epoch [47/50], Batch 89/120, Train Loss: 101.5952\n",
      "8440.1304397583\n",
      "Epoch [47/50], Batch 90/120, Train Loss: 92.2059\n",
      "8534.057121276855\n",
      "Epoch [47/50], Batch 91/120, Train Loss: 93.9267\n",
      "8632.992958068848\n",
      "Epoch [47/50], Batch 92/120, Train Loss: 98.9358\n",
      "8732.069328308105\n",
      "Epoch [47/50], Batch 93/120, Train Loss: 99.0764\n",
      "8844.077430725098\n",
      "Epoch [47/50], Batch 94/120, Train Loss: 112.0081\n",
      "8925.160484313965\n",
      "Epoch [47/50], Batch 95/120, Train Loss: 81.0831\n",
      "9018.093421936035\n",
      "Epoch [47/50], Batch 96/120, Train Loss: 92.9329\n",
      "9114.77490234375\n",
      "Epoch [47/50], Batch 97/120, Train Loss: 96.6815\n",
      "9203.843307495117\n",
      "Epoch [47/50], Batch 98/120, Train Loss: 89.0684\n",
      "9292.962509155273\n",
      "Epoch [47/50], Batch 99/120, Train Loss: 89.1192\n",
      "9397.685523986816\n",
      "Epoch [47/50], Batch 100/120, Train Loss: 104.7230\n",
      "9488.979286193848\n",
      "Epoch [47/50], Batch 101/120, Train Loss: 91.2938\n",
      "9573.169609069824\n",
      "Epoch [47/50], Batch 102/120, Train Loss: 84.1903\n",
      "9679.237754821777\n",
      "Epoch [47/50], Batch 103/120, Train Loss: 106.0681\n",
      "9782.401321411133\n",
      "Epoch [47/50], Batch 104/120, Train Loss: 103.1636\n",
      "9892.252197265625\n",
      "Epoch [47/50], Batch 105/120, Train Loss: 109.8509\n",
      "9975.241394042969\n",
      "Epoch [47/50], Batch 106/120, Train Loss: 82.9892\n",
      "10063.351974487305\n",
      "Epoch [47/50], Batch 107/120, Train Loss: 88.1106\n",
      "10141.181495666504\n",
      "Epoch [47/50], Batch 108/120, Train Loss: 77.8295\n",
      "10226.92488861084\n",
      "Epoch [47/50], Batch 109/120, Train Loss: 85.7434\n",
      "10331.36693572998\n",
      "Epoch [47/50], Batch 110/120, Train Loss: 104.4420\n",
      "10418.989585876465\n",
      "Epoch [47/50], Batch 111/120, Train Loss: 87.6227\n",
      "10524.202690124512\n",
      "Epoch [47/50], Batch 112/120, Train Loss: 105.2131\n",
      "10621.413261413574\n",
      "Epoch [47/50], Batch 113/120, Train Loss: 97.2106\n",
      "10699.25845336914\n",
      "Epoch [47/50], Batch 114/120, Train Loss: 77.8452\n",
      "10825.693572998047\n",
      "Epoch [47/50], Batch 115/120, Train Loss: 126.4351\n",
      "10937.047149658203\n",
      "Epoch [47/50], Batch 116/120, Train Loss: 111.3536\n",
      "11035.51058959961\n",
      "Epoch [47/50], Batch 117/120, Train Loss: 98.4634\n",
      "11127.156799316406\n",
      "Epoch [47/50], Batch 118/120, Train Loss: 91.6462\n",
      "11210.288986206055\n",
      "Epoch [47/50], Batch 119/120, Train Loss: 83.1322\n",
      "11319.342758178711\n",
      "Epoch [47/50], Batch 120/120, Train Loss: 109.0538\n",
      "Epoch [47/50], Train Loss: 94.3279, Validation Loss: 115.4467\n",
      "82.6544418334961\n",
      "Epoch [48/50], Batch 1/120, Train Loss: 82.6544\n",
      "179.34180450439453\n",
      "Epoch [48/50], Batch 2/120, Train Loss: 96.6874\n",
      "287.80651092529297\n",
      "Epoch [48/50], Batch 3/120, Train Loss: 108.4647\n",
      "366.9192352294922\n",
      "Epoch [48/50], Batch 4/120, Train Loss: 79.1127\n",
      "449.9708251953125\n",
      "Epoch [48/50], Batch 5/120, Train Loss: 83.0516\n",
      "548.4412231445312\n",
      "Epoch [48/50], Batch 6/120, Train Loss: 98.4704\n",
      "655.0384902954102\n",
      "Epoch [48/50], Batch 7/120, Train Loss: 106.5973\n",
      "734.3782424926758\n",
      "Epoch [48/50], Batch 8/120, Train Loss: 79.3398\n",
      "853.1369400024414\n",
      "Epoch [48/50], Batch 9/120, Train Loss: 118.7587\n",
      "951.9426345825195\n",
      "Epoch [48/50], Batch 10/120, Train Loss: 98.8057\n",
      "1055.3161544799805\n",
      "Epoch [48/50], Batch 11/120, Train Loss: 103.3735\n",
      "1134.095100402832\n",
      "Epoch [48/50], Batch 12/120, Train Loss: 78.7789\n",
      "1235.0698165893555\n",
      "Epoch [48/50], Batch 13/120, Train Loss: 100.9747\n",
      "1319.2025756835938\n",
      "Epoch [48/50], Batch 14/120, Train Loss: 84.1328\n",
      "1394.5160827636719\n",
      "Epoch [48/50], Batch 15/120, Train Loss: 75.3135\n",
      "1486.5740585327148\n",
      "Epoch [48/50], Batch 16/120, Train Loss: 92.0580\n",
      "1570.248146057129\n",
      "Epoch [48/50], Batch 17/120, Train Loss: 83.6741\n",
      "1665.0321426391602\n",
      "Epoch [48/50], Batch 18/120, Train Loss: 94.7840\n",
      "1755.2548904418945\n",
      "Epoch [48/50], Batch 19/120, Train Loss: 90.2227\n",
      "1864.8843154907227\n",
      "Epoch [48/50], Batch 20/120, Train Loss: 109.6294\n",
      "1997.6216354370117\n",
      "Epoch [48/50], Batch 21/120, Train Loss: 132.7373\n",
      "2080.1734619140625\n",
      "Epoch [48/50], Batch 22/120, Train Loss: 82.5518\n",
      "2189.966896057129\n",
      "Epoch [48/50], Batch 23/120, Train Loss: 109.7934\n",
      "2267.97322845459\n",
      "Epoch [48/50], Batch 24/120, Train Loss: 78.0063\n",
      "2365.0484161376953\n",
      "Epoch [48/50], Batch 25/120, Train Loss: 97.0752\n",
      "2480.2236938476562\n",
      "Epoch [48/50], Batch 26/120, Train Loss: 115.1753\n",
      "2578.283905029297\n",
      "Epoch [48/50], Batch 27/120, Train Loss: 98.0602\n",
      "2659.1536178588867\n",
      "Epoch [48/50], Batch 28/120, Train Loss: 80.8697\n",
      "2739.628089904785\n",
      "Epoch [48/50], Batch 29/120, Train Loss: 80.4745\n",
      "2843.6862716674805\n",
      "Epoch [48/50], Batch 30/120, Train Loss: 104.0582\n",
      "2931.7483139038086\n",
      "Epoch [48/50], Batch 31/120, Train Loss: 88.0620\n",
      "3009.532325744629\n",
      "Epoch [48/50], Batch 32/120, Train Loss: 77.7840\n",
      "3097.6491470336914\n",
      "Epoch [48/50], Batch 33/120, Train Loss: 88.1168\n",
      "3185.472267150879\n",
      "Epoch [48/50], Batch 34/120, Train Loss: 87.8231\n",
      "3289.63224029541\n",
      "Epoch [48/50], Batch 35/120, Train Loss: 104.1600\n",
      "3366.6340866088867\n",
      "Epoch [48/50], Batch 36/120, Train Loss: 77.0018\n",
      "3479.5051040649414\n",
      "Epoch [48/50], Batch 37/120, Train Loss: 112.8710\n",
      "3582.3921279907227\n",
      "Epoch [48/50], Batch 38/120, Train Loss: 102.8870\n",
      "3658.6318435668945\n",
      "Epoch [48/50], Batch 39/120, Train Loss: 76.2397\n",
      "3757.39102935791\n",
      "Epoch [48/50], Batch 40/120, Train Loss: 98.7592\n",
      "3851.633804321289\n",
      "Epoch [48/50], Batch 41/120, Train Loss: 94.2428\n",
      "3947.2810974121094\n",
      "Epoch [48/50], Batch 42/120, Train Loss: 95.6473\n",
      "4046.0756607055664\n",
      "Epoch [48/50], Batch 43/120, Train Loss: 98.7946\n",
      "4132.274337768555\n",
      "Epoch [48/50], Batch 44/120, Train Loss: 86.1987\n",
      "4213.891136169434\n",
      "Epoch [48/50], Batch 45/120, Train Loss: 81.6168\n",
      "4320.632743835449\n",
      "Epoch [48/50], Batch 46/120, Train Loss: 106.7416\n",
      "4402.874893188477\n",
      "Epoch [48/50], Batch 47/120, Train Loss: 82.2421\n",
      "4504.210479736328\n",
      "Epoch [48/50], Batch 48/120, Train Loss: 101.3356\n",
      "4593.030288696289\n",
      "Epoch [48/50], Batch 49/120, Train Loss: 88.8198\n",
      "4690.579376220703\n",
      "Epoch [48/50], Batch 50/120, Train Loss: 97.5491\n",
      "4773.078834533691\n",
      "Epoch [48/50], Batch 51/120, Train Loss: 82.4995\n",
      "4897.712051391602\n",
      "Epoch [48/50], Batch 52/120, Train Loss: 124.6332\n",
      "4979.6622314453125\n",
      "Epoch [48/50], Batch 53/120, Train Loss: 81.9502\n",
      "5076.054214477539\n",
      "Epoch [48/50], Batch 54/120, Train Loss: 96.3920\n",
      "5164.984901428223\n",
      "Epoch [48/50], Batch 55/120, Train Loss: 88.9307\n",
      "5258.597877502441\n",
      "Epoch [48/50], Batch 56/120, Train Loss: 93.6130\n",
      "5379.426742553711\n",
      "Epoch [48/50], Batch 57/120, Train Loss: 120.8289\n",
      "5473.852104187012\n",
      "Epoch [48/50], Batch 58/120, Train Loss: 94.4254\n",
      "5556.8610916137695\n",
      "Epoch [48/50], Batch 59/120, Train Loss: 83.0090\n",
      "5661.857093811035\n",
      "Epoch [48/50], Batch 60/120, Train Loss: 104.9960\n",
      "5766.200553894043\n",
      "Epoch [48/50], Batch 61/120, Train Loss: 104.3435\n",
      "5856.802955627441\n",
      "Epoch [48/50], Batch 62/120, Train Loss: 90.6024\n",
      "5952.1325607299805\n",
      "Epoch [48/50], Batch 63/120, Train Loss: 95.3296\n",
      "6054.203880310059\n",
      "Epoch [48/50], Batch 64/120, Train Loss: 102.0713\n",
      "6129.532440185547\n",
      "Epoch [48/50], Batch 65/120, Train Loss: 75.3286\n",
      "6233.576156616211\n",
      "Epoch [48/50], Batch 66/120, Train Loss: 104.0437\n",
      "6326.236999511719\n",
      "Epoch [48/50], Batch 67/120, Train Loss: 92.6608\n",
      "6448.155197143555\n",
      "Epoch [48/50], Batch 68/120, Train Loss: 121.9182\n",
      "6536.198104858398\n",
      "Epoch [48/50], Batch 69/120, Train Loss: 88.0429\n",
      "6624.089950561523\n",
      "Epoch [48/50], Batch 70/120, Train Loss: 87.8918\n",
      "6751.348106384277\n",
      "Epoch [48/50], Batch 71/120, Train Loss: 127.2582\n",
      "6849.139930725098\n",
      "Epoch [48/50], Batch 72/120, Train Loss: 97.7918\n",
      "6945.879379272461\n",
      "Epoch [48/50], Batch 73/120, Train Loss: 96.7394\n",
      "7026.608963012695\n",
      "Epoch [48/50], Batch 74/120, Train Loss: 80.7296\n",
      "7098.451431274414\n",
      "Epoch [48/50], Batch 75/120, Train Loss: 71.8425\n",
      "7188.058387756348\n",
      "Epoch [48/50], Batch 76/120, Train Loss: 89.6070\n",
      "7290.875221252441\n",
      "Epoch [48/50], Batch 77/120, Train Loss: 102.8168\n",
      "7392.837623596191\n",
      "Epoch [48/50], Batch 78/120, Train Loss: 101.9624\n",
      "7501.526611328125\n",
      "Epoch [48/50], Batch 79/120, Train Loss: 108.6890\n",
      "7598.003486633301\n",
      "Epoch [48/50], Batch 80/120, Train Loss: 96.4769\n",
      "7690.590888977051\n",
      "Epoch [48/50], Batch 81/120, Train Loss: 92.5874\n",
      "7785.036415100098\n",
      "Epoch [48/50], Batch 82/120, Train Loss: 94.4455\n",
      "7860.918800354004\n",
      "Epoch [48/50], Batch 83/120, Train Loss: 75.8824\n",
      "7940.1120681762695\n",
      "Epoch [48/50], Batch 84/120, Train Loss: 79.1933\n",
      "8033.806541442871\n",
      "Epoch [48/50], Batch 85/120, Train Loss: 93.6945\n",
      "8144.740867614746\n",
      "Epoch [48/50], Batch 86/120, Train Loss: 110.9343\n",
      "8241.197746276855\n",
      "Epoch [48/50], Batch 87/120, Train Loss: 96.4569\n",
      "8354.882270812988\n",
      "Epoch [48/50], Batch 88/120, Train Loss: 113.6845\n",
      "8431.120681762695\n",
      "Epoch [48/50], Batch 89/120, Train Loss: 76.2384\n",
      "8532.375045776367\n",
      "Epoch [48/50], Batch 90/120, Train Loss: 101.2544\n",
      "8627.094184875488\n",
      "Epoch [48/50], Batch 91/120, Train Loss: 94.7191\n",
      "8732.572898864746\n",
      "Epoch [48/50], Batch 92/120, Train Loss: 105.4787\n",
      "8833.346214294434\n",
      "Epoch [48/50], Batch 93/120, Train Loss: 100.7733\n",
      "8926.114555358887\n",
      "Epoch [48/50], Batch 94/120, Train Loss: 92.7683\n",
      "9019.550872802734\n",
      "Epoch [48/50], Batch 95/120, Train Loss: 93.4363\n",
      "9101.910873413086\n",
      "Epoch [48/50], Batch 96/120, Train Loss: 82.3600\n",
      "9205.126831054688\n",
      "Epoch [48/50], Batch 97/120, Train Loss: 103.2160\n",
      "9280.347145080566\n",
      "Epoch [48/50], Batch 98/120, Train Loss: 75.2203\n",
      "9367.481620788574\n",
      "Epoch [48/50], Batch 99/120, Train Loss: 87.1345\n",
      "9440.51392364502\n",
      "Epoch [48/50], Batch 100/120, Train Loss: 73.0323\n",
      "9524.304466247559\n",
      "Epoch [48/50], Batch 101/120, Train Loss: 83.7905\n",
      "9603.343589782715\n",
      "Epoch [48/50], Batch 102/120, Train Loss: 79.0391\n",
      "9691.218467712402\n",
      "Epoch [48/50], Batch 103/120, Train Loss: 87.8749\n",
      "9793.65983581543\n",
      "Epoch [48/50], Batch 104/120, Train Loss: 102.4414\n",
      "9886.430686950684\n",
      "Epoch [48/50], Batch 105/120, Train Loss: 92.7709\n",
      "9971.367958068848\n",
      "Epoch [48/50], Batch 106/120, Train Loss: 84.9373\n",
      "10079.281303405762\n",
      "Epoch [48/50], Batch 107/120, Train Loss: 107.9133\n",
      "10168.864265441895\n",
      "Epoch [48/50], Batch 108/120, Train Loss: 89.5830\n",
      "10278.524543762207\n",
      "Epoch [48/50], Batch 109/120, Train Loss: 109.6603\n",
      "10356.814666748047\n",
      "Epoch [48/50], Batch 110/120, Train Loss: 78.2901\n",
      "10467.644088745117\n",
      "Epoch [48/50], Batch 111/120, Train Loss: 110.8294\n",
      "10571.216857910156\n",
      "Epoch [48/50], Batch 112/120, Train Loss: 103.5728\n",
      "10672.777618408203\n",
      "Epoch [48/50], Batch 113/120, Train Loss: 101.5608\n",
      "10766.381240844727\n",
      "Epoch [48/50], Batch 114/120, Train Loss: 93.6036\n",
      "10833.113586425781\n",
      "Epoch [48/50], Batch 115/120, Train Loss: 66.7323\n",
      "10930.839973449707\n",
      "Epoch [48/50], Batch 116/120, Train Loss: 97.7264\n",
      "11038.760879516602\n",
      "Epoch [48/50], Batch 117/120, Train Loss: 107.9209\n",
      "11140.120063781738\n",
      "Epoch [48/50], Batch 118/120, Train Loss: 101.3592\n",
      "11231.512954711914\n",
      "Epoch [48/50], Batch 119/120, Train Loss: 91.3929\n",
      "11319.98046875\n",
      "Epoch [48/50], Batch 120/120, Train Loss: 88.4675\n",
      "Epoch [48/50], Train Loss: 94.3332, Validation Loss: 114.4444\n",
      "107.73023223876953\n",
      "Epoch [49/50], Batch 1/120, Train Loss: 107.7302\n",
      "191.77474212646484\n",
      "Epoch [49/50], Batch 2/120, Train Loss: 84.0445\n",
      "272.5714797973633\n",
      "Epoch [49/50], Batch 3/120, Train Loss: 80.7967\n",
      "358.90367889404297\n",
      "Epoch [49/50], Batch 4/120, Train Loss: 86.3322\n",
      "454.9148483276367\n",
      "Epoch [49/50], Batch 5/120, Train Loss: 96.0112\n",
      "570.7072372436523\n",
      "Epoch [49/50], Batch 6/120, Train Loss: 115.7924\n",
      "677.8024063110352\n",
      "Epoch [49/50], Batch 7/120, Train Loss: 107.0952\n",
      "776.8304214477539\n",
      "Epoch [49/50], Batch 8/120, Train Loss: 99.0280\n",
      "871.7122268676758\n",
      "Epoch [49/50], Batch 9/120, Train Loss: 94.8818\n",
      "954.5300750732422\n",
      "Epoch [49/50], Batch 10/120, Train Loss: 82.8178\n",
      "1051.7534408569336\n",
      "Epoch [49/50], Batch 11/120, Train Loss: 97.2234\n",
      "1137.8079528808594\n",
      "Epoch [49/50], Batch 12/120, Train Loss: 86.0545\n",
      "1227.7360382080078\n",
      "Epoch [49/50], Batch 13/120, Train Loss: 89.9281\n",
      "1332.3033294677734\n",
      "Epoch [49/50], Batch 14/120, Train Loss: 104.5673\n",
      "1422.111587524414\n",
      "Epoch [49/50], Batch 15/120, Train Loss: 89.8083\n",
      "1532.769157409668\n",
      "Epoch [49/50], Batch 16/120, Train Loss: 110.6576\n",
      "1632.6245040893555\n",
      "Epoch [49/50], Batch 17/120, Train Loss: 99.8553\n",
      "1711.208152770996\n",
      "Epoch [49/50], Batch 18/120, Train Loss: 78.5836\n",
      "1795.237648010254\n",
      "Epoch [49/50], Batch 19/120, Train Loss: 84.0295\n",
      "1875.5680923461914\n",
      "Epoch [49/50], Batch 20/120, Train Loss: 80.3304\n",
      "1962.595443725586\n",
      "Epoch [49/50], Batch 21/120, Train Loss: 87.0274\n",
      "2031.0084915161133\n",
      "Epoch [49/50], Batch 22/120, Train Loss: 68.4130\n",
      "2124.4638748168945\n",
      "Epoch [49/50], Batch 23/120, Train Loss: 93.4554\n",
      "2195.2480850219727\n",
      "Epoch [49/50], Batch 24/120, Train Loss: 70.7842\n",
      "2302.62850189209\n",
      "Epoch [49/50], Batch 25/120, Train Loss: 107.3804\n",
      "2399.838981628418\n",
      "Epoch [49/50], Batch 26/120, Train Loss: 97.2105\n",
      "2498.216926574707\n",
      "Epoch [49/50], Batch 27/120, Train Loss: 98.3779\n",
      "2591.3178787231445\n",
      "Epoch [49/50], Batch 28/120, Train Loss: 93.1010\n",
      "2664.0905685424805\n",
      "Epoch [49/50], Batch 29/120, Train Loss: 72.7727\n",
      "2752.552177429199\n",
      "Epoch [49/50], Batch 30/120, Train Loss: 88.4616\n",
      "2858.073616027832\n",
      "Epoch [49/50], Batch 31/120, Train Loss: 105.5214\n",
      "2955.61808013916\n",
      "Epoch [49/50], Batch 32/120, Train Loss: 97.5445\n",
      "3050.3504943847656\n",
      "Epoch [49/50], Batch 33/120, Train Loss: 94.7324\n",
      "3157.204620361328\n",
      "Epoch [49/50], Batch 34/120, Train Loss: 106.8541\n",
      "3255.9417877197266\n",
      "Epoch [49/50], Batch 35/120, Train Loss: 98.7372\n",
      "3342.827522277832\n",
      "Epoch [49/50], Batch 36/120, Train Loss: 86.8857\n",
      "3447.5693435668945\n",
      "Epoch [49/50], Batch 37/120, Train Loss: 104.7418\n",
      "3543.860061645508\n",
      "Epoch [49/50], Batch 38/120, Train Loss: 96.2907\n",
      "3646.457992553711\n",
      "Epoch [49/50], Batch 39/120, Train Loss: 102.5979\n",
      "3752.41748046875\n",
      "Epoch [49/50], Batch 40/120, Train Loss: 105.9595\n",
      "3839.7590942382812\n",
      "Epoch [49/50], Batch 41/120, Train Loss: 87.3416\n",
      "3933.744483947754\n",
      "Epoch [49/50], Batch 42/120, Train Loss: 93.9854\n",
      "4002.026527404785\n",
      "Epoch [49/50], Batch 43/120, Train Loss: 68.2820\n",
      "4075.9704208374023\n",
      "Epoch [49/50], Batch 44/120, Train Loss: 73.9439\n",
      "4169.907554626465\n",
      "Epoch [49/50], Batch 45/120, Train Loss: 93.9371\n",
      "4251.676452636719\n",
      "Epoch [49/50], Batch 46/120, Train Loss: 81.7689\n",
      "4340.674217224121\n",
      "Epoch [49/50], Batch 47/120, Train Loss: 88.9978\n",
      "4427.429817199707\n",
      "Epoch [49/50], Batch 48/120, Train Loss: 86.7556\n",
      "4523.312240600586\n",
      "Epoch [49/50], Batch 49/120, Train Loss: 95.8824\n",
      "4626.748474121094\n",
      "Epoch [49/50], Batch 50/120, Train Loss: 103.4362\n",
      "4710.175445556641\n",
      "Epoch [49/50], Batch 51/120, Train Loss: 83.4270\n",
      "4786.891799926758\n",
      "Epoch [49/50], Batch 52/120, Train Loss: 76.7164\n",
      "4893.405578613281\n",
      "Epoch [49/50], Batch 53/120, Train Loss: 106.5138\n",
      "5013.280517578125\n",
      "Epoch [49/50], Batch 54/120, Train Loss: 119.8749\n",
      "5128.054595947266\n",
      "Epoch [49/50], Batch 55/120, Train Loss: 114.7741\n",
      "5215.505241394043\n",
      "Epoch [49/50], Batch 56/120, Train Loss: 87.4506\n",
      "5305.611068725586\n",
      "Epoch [49/50], Batch 57/120, Train Loss: 90.1058\n",
      "5399.130554199219\n",
      "Epoch [49/50], Batch 58/120, Train Loss: 93.5195\n",
      "5483.686508178711\n",
      "Epoch [49/50], Batch 59/120, Train Loss: 84.5560\n",
      "5587.616607666016\n",
      "Epoch [49/50], Batch 60/120, Train Loss: 103.9301\n",
      "5655.992622375488\n",
      "Epoch [49/50], Batch 61/120, Train Loss: 68.3760\n",
      "5738.184379577637\n",
      "Epoch [49/50], Batch 62/120, Train Loss: 82.1918\n",
      "5840.252655029297\n",
      "Epoch [49/50], Batch 63/120, Train Loss: 102.0683\n",
      "5939.230178833008\n",
      "Epoch [49/50], Batch 64/120, Train Loss: 98.9775\n",
      "6047.05973815918\n",
      "Epoch [49/50], Batch 65/120, Train Loss: 107.8296\n",
      "6123.385269165039\n",
      "Epoch [49/50], Batch 66/120, Train Loss: 76.3255\n",
      "6195.831985473633\n",
      "Epoch [49/50], Batch 67/120, Train Loss: 72.4467\n",
      "6300.0595779418945\n",
      "Epoch [49/50], Batch 68/120, Train Loss: 104.2276\n",
      "6402.697891235352\n",
      "Epoch [49/50], Batch 69/120, Train Loss: 102.6383\n",
      "6488.258010864258\n",
      "Epoch [49/50], Batch 70/120, Train Loss: 85.5601\n",
      "6573.396026611328\n",
      "Epoch [49/50], Batch 71/120, Train Loss: 85.1380\n",
      "6681.62158203125\n",
      "Epoch [49/50], Batch 72/120, Train Loss: 108.2256\n",
      "6784.202590942383\n",
      "Epoch [49/50], Batch 73/120, Train Loss: 102.5810\n",
      "6875.973793029785\n",
      "Epoch [49/50], Batch 74/120, Train Loss: 91.7712\n",
      "6970.881683349609\n",
      "Epoch [49/50], Batch 75/120, Train Loss: 94.9079\n",
      "7063.568016052246\n",
      "Epoch [49/50], Batch 76/120, Train Loss: 92.6863\n",
      "7130.731071472168\n",
      "Epoch [49/50], Batch 77/120, Train Loss: 67.1631\n",
      "7206.5151290893555\n",
      "Epoch [49/50], Batch 78/120, Train Loss: 75.7841\n",
      "7292.592124938965\n",
      "Epoch [49/50], Batch 79/120, Train Loss: 86.0770\n",
      "7367.101463317871\n",
      "Epoch [49/50], Batch 80/120, Train Loss: 74.5093\n",
      "7466.992378234863\n",
      "Epoch [49/50], Batch 81/120, Train Loss: 99.8909\n",
      "7548.007682800293\n",
      "Epoch [49/50], Batch 82/120, Train Loss: 81.0153\n",
      "7648.456169128418\n",
      "Epoch [49/50], Batch 83/120, Train Loss: 100.4485\n",
      "7762.0324783325195\n",
      "Epoch [49/50], Batch 84/120, Train Loss: 113.5763\n",
      "7835.637168884277\n",
      "Epoch [49/50], Batch 85/120, Train Loss: 73.6047\n",
      "7926.092887878418\n",
      "Epoch [49/50], Batch 86/120, Train Loss: 90.4557\n",
      "8001.670928955078\n",
      "Epoch [49/50], Batch 87/120, Train Loss: 75.5780\n",
      "8094.632438659668\n",
      "Epoch [49/50], Batch 88/120, Train Loss: 92.9615\n",
      "8187.775337219238\n",
      "Epoch [49/50], Batch 89/120, Train Loss: 93.1429\n",
      "8286.148513793945\n",
      "Epoch [49/50], Batch 90/120, Train Loss: 98.3732\n",
      "8388.971588134766\n",
      "Epoch [49/50], Batch 91/120, Train Loss: 102.8231\n",
      "8488.000076293945\n",
      "Epoch [49/50], Batch 92/120, Train Loss: 99.0285\n",
      "8566.946258544922\n",
      "Epoch [49/50], Batch 93/120, Train Loss: 78.9462\n",
      "8634.259887695312\n",
      "Epoch [49/50], Batch 94/120, Train Loss: 67.3136\n",
      "8742.630653381348\n",
      "Epoch [49/50], Batch 95/120, Train Loss: 108.3708\n",
      "8833.047538757324\n",
      "Epoch [49/50], Batch 96/120, Train Loss: 90.4169\n",
      "8923.244522094727\n",
      "Epoch [49/50], Batch 97/120, Train Loss: 90.1970\n",
      "9029.088882446289\n",
      "Epoch [49/50], Batch 98/120, Train Loss: 105.8444\n",
      "9133.882949829102\n",
      "Epoch [49/50], Batch 99/120, Train Loss: 104.7941\n",
      "9205.723793029785\n",
      "Epoch [49/50], Batch 100/120, Train Loss: 71.8408\n",
      "9294.477333068848\n",
      "Epoch [49/50], Batch 101/120, Train Loss: 88.7535\n",
      "9382.196640014648\n",
      "Epoch [49/50], Batch 102/120, Train Loss: 87.7193\n",
      "9481.399978637695\n",
      "Epoch [49/50], Batch 103/120, Train Loss: 99.2033\n",
      "9587.258987426758\n",
      "Epoch [49/50], Batch 104/120, Train Loss: 105.8590\n",
      "9681.747848510742\n",
      "Epoch [49/50], Batch 105/120, Train Loss: 94.4889\n",
      "9765.703598022461\n",
      "Epoch [49/50], Batch 106/120, Train Loss: 83.9557\n",
      "9862.904159545898\n",
      "Epoch [49/50], Batch 107/120, Train Loss: 97.2006\n",
      "9975.280906677246\n",
      "Epoch [49/50], Batch 108/120, Train Loss: 112.3767\n",
      "10050.00643157959\n",
      "Epoch [49/50], Batch 109/120, Train Loss: 74.7255\n",
      "10140.331321716309\n",
      "Epoch [49/50], Batch 110/120, Train Loss: 90.3249\n",
      "10257.223770141602\n",
      "Epoch [49/50], Batch 111/120, Train Loss: 116.8924\n",
      "10361.496566772461\n",
      "Epoch [49/50], Batch 112/120, Train Loss: 104.2728\n",
      "10454.047637939453\n",
      "Epoch [49/50], Batch 113/120, Train Loss: 92.5511\n",
      "10565.214065551758\n",
      "Epoch [49/50], Batch 114/120, Train Loss: 111.1664\n",
      "10679.199867248535\n",
      "Epoch [49/50], Batch 115/120, Train Loss: 113.9858\n",
      "10780.277503967285\n",
      "Epoch [49/50], Batch 116/120, Train Loss: 101.0776\n",
      "10866.907096862793\n",
      "Epoch [49/50], Batch 117/120, Train Loss: 86.6296\n",
      "10953.631004333496\n",
      "Epoch [49/50], Batch 118/120, Train Loss: 86.7239\n",
      "11065.524505615234\n",
      "Epoch [49/50], Batch 119/120, Train Loss: 111.8935\n",
      "11177.9580078125\n",
      "Epoch [49/50], Batch 120/120, Train Loss: 112.4335\n",
      "Epoch [49/50], Train Loss: 93.1497, Validation Loss: 115.6839\n",
      "95.01591491699219\n",
      "Epoch [50/50], Batch 1/120, Train Loss: 95.0159\n",
      "197.4022216796875\n",
      "Epoch [50/50], Batch 2/120, Train Loss: 102.3863\n",
      "292.3916702270508\n",
      "Epoch [50/50], Batch 3/120, Train Loss: 94.9894\n",
      "374.8083190917969\n",
      "Epoch [50/50], Batch 4/120, Train Loss: 82.4166\n",
      "464.2024383544922\n",
      "Epoch [50/50], Batch 5/120, Train Loss: 89.3941\n",
      "567.9307708740234\n",
      "Epoch [50/50], Batch 6/120, Train Loss: 103.7283\n",
      "660.8493881225586\n",
      "Epoch [50/50], Batch 7/120, Train Loss: 92.9186\n",
      "753.8144454956055\n",
      "Epoch [50/50], Batch 8/120, Train Loss: 92.9651\n",
      "830.0280838012695\n",
      "Epoch [50/50], Batch 9/120, Train Loss: 76.2136\n",
      "912.7663803100586\n",
      "Epoch [50/50], Batch 10/120, Train Loss: 82.7383\n",
      "997.8017883300781\n",
      "Epoch [50/50], Batch 11/120, Train Loss: 85.0354\n",
      "1092.524429321289\n",
      "Epoch [50/50], Batch 12/120, Train Loss: 94.7226\n",
      "1189.1449737548828\n",
      "Epoch [50/50], Batch 13/120, Train Loss: 96.6205\n",
      "1283.5315246582031\n",
      "Epoch [50/50], Batch 14/120, Train Loss: 94.3866\n",
      "1402.7452011108398\n",
      "Epoch [50/50], Batch 15/120, Train Loss: 119.2137\n",
      "1498.1624603271484\n",
      "Epoch [50/50], Batch 16/120, Train Loss: 95.4173\n",
      "1570.8843612670898\n",
      "Epoch [50/50], Batch 17/120, Train Loss: 72.7219\n",
      "1655.9498977661133\n",
      "Epoch [50/50], Batch 18/120, Train Loss: 85.0655\n",
      "1746.1758270263672\n",
      "Epoch [50/50], Batch 19/120, Train Loss: 90.2259\n",
      "1832.3813781738281\n",
      "Epoch [50/50], Batch 20/120, Train Loss: 86.2056\n",
      "1917.7671508789062\n",
      "Epoch [50/50], Batch 21/120, Train Loss: 85.3858\n",
      "2026.1520462036133\n",
      "Epoch [50/50], Batch 22/120, Train Loss: 108.3849\n",
      "2090.968681335449\n",
      "Epoch [50/50], Batch 23/120, Train Loss: 64.8166\n",
      "2189.3072052001953\n",
      "Epoch [50/50], Batch 24/120, Train Loss: 98.3385\n",
      "2288.020706176758\n",
      "Epoch [50/50], Batch 25/120, Train Loss: 98.7135\n",
      "2348.2694091796875\n",
      "Epoch [50/50], Batch 26/120, Train Loss: 60.2487\n",
      "2467.231735229492\n",
      "Epoch [50/50], Batch 27/120, Train Loss: 118.9623\n",
      "2549.343635559082\n",
      "Epoch [50/50], Batch 28/120, Train Loss: 82.1119\n",
      "2630.436668395996\n",
      "Epoch [50/50], Batch 29/120, Train Loss: 81.0930\n",
      "2726.467460632324\n",
      "Epoch [50/50], Batch 30/120, Train Loss: 96.0308\n",
      "2813.2406997680664\n",
      "Epoch [50/50], Batch 31/120, Train Loss: 86.7732\n",
      "2907.4096908569336\n",
      "Epoch [50/50], Batch 32/120, Train Loss: 94.1690\n",
      "2993.213691711426\n",
      "Epoch [50/50], Batch 33/120, Train Loss: 85.8040\n",
      "3092.6469955444336\n",
      "Epoch [50/50], Batch 34/120, Train Loss: 99.4333\n",
      "3172.6728744506836\n",
      "Epoch [50/50], Batch 35/120, Train Loss: 80.0259\n",
      "3270.900215148926\n",
      "Epoch [50/50], Batch 36/120, Train Loss: 98.2273\n",
      "3369.0788192749023\n",
      "Epoch [50/50], Batch 37/120, Train Loss: 98.1786\n",
      "3462.1909713745117\n",
      "Epoch [50/50], Batch 38/120, Train Loss: 93.1122\n",
      "3541.457344055176\n",
      "Epoch [50/50], Batch 39/120, Train Loss: 79.2664\n",
      "3653.7033767700195\n",
      "Epoch [50/50], Batch 40/120, Train Loss: 112.2460\n",
      "3784.49471282959\n",
      "Epoch [50/50], Batch 41/120, Train Loss: 130.7913\n",
      "3901.5375213623047\n",
      "Epoch [50/50], Batch 42/120, Train Loss: 117.0428\n",
      "3999.7558517456055\n",
      "Epoch [50/50], Batch 43/120, Train Loss: 98.2183\n",
      "4117.147636413574\n",
      "Epoch [50/50], Batch 44/120, Train Loss: 117.3918\n",
      "4208.420783996582\n",
      "Epoch [50/50], Batch 45/120, Train Loss: 91.2731\n",
      "4302.898323059082\n",
      "Epoch [50/50], Batch 46/120, Train Loss: 94.4775\n",
      "4399.738624572754\n",
      "Epoch [50/50], Batch 47/120, Train Loss: 96.8403\n",
      "4484.826210021973\n",
      "Epoch [50/50], Batch 48/120, Train Loss: 85.0876\n",
      "4602.197441101074\n",
      "Epoch [50/50], Batch 49/120, Train Loss: 117.3712\n",
      "4730.2470626831055\n",
      "Epoch [50/50], Batch 50/120, Train Loss: 128.0496\n",
      "4817.58349609375\n",
      "Epoch [50/50], Batch 51/120, Train Loss: 87.3364\n",
      "4923.378875732422\n",
      "Epoch [50/50], Batch 52/120, Train Loss: 105.7954\n",
      "5009.698631286621\n",
      "Epoch [50/50], Batch 53/120, Train Loss: 86.3198\n",
      "5109.799186706543\n",
      "Epoch [50/50], Batch 54/120, Train Loss: 100.1006\n",
      "5188.094062805176\n",
      "Epoch [50/50], Batch 55/120, Train Loss: 78.2949\n",
      "5277.505729675293\n",
      "Epoch [50/50], Batch 56/120, Train Loss: 89.4117\n",
      "5374.828842163086\n",
      "Epoch [50/50], Batch 57/120, Train Loss: 97.3231\n",
      "5447.127731323242\n",
      "Epoch [50/50], Batch 58/120, Train Loss: 72.2989\n",
      "5545.834121704102\n",
      "Epoch [50/50], Batch 59/120, Train Loss: 98.7064\n",
      "5661.541664123535\n",
      "Epoch [50/50], Batch 60/120, Train Loss: 115.7075\n",
      "5764.588157653809\n",
      "Epoch [50/50], Batch 61/120, Train Loss: 103.0465\n",
      "5856.213623046875\n",
      "Epoch [50/50], Batch 62/120, Train Loss: 91.6255\n",
      "5951.301460266113\n",
      "Epoch [50/50], Batch 63/120, Train Loss: 95.0878\n",
      "6036.228691101074\n",
      "Epoch [50/50], Batch 64/120, Train Loss: 84.9272\n",
      "6133.377830505371\n",
      "Epoch [50/50], Batch 65/120, Train Loss: 97.1491\n",
      "6217.371116638184\n",
      "Epoch [50/50], Batch 66/120, Train Loss: 83.9933\n",
      "6296.4942626953125\n",
      "Epoch [50/50], Batch 67/120, Train Loss: 79.1231\n",
      "6389.823791503906\n",
      "Epoch [50/50], Batch 68/120, Train Loss: 93.3295\n",
      "6493.361770629883\n",
      "Epoch [50/50], Batch 69/120, Train Loss: 103.5380\n",
      "6598.392425537109\n",
      "Epoch [50/50], Batch 70/120, Train Loss: 105.0307\n",
      "6683.993347167969\n",
      "Epoch [50/50], Batch 71/120, Train Loss: 85.6009\n",
      "6764.321960449219\n",
      "Epoch [50/50], Batch 72/120, Train Loss: 80.3286\n",
      "6837.587379455566\n",
      "Epoch [50/50], Batch 73/120, Train Loss: 73.2654\n",
      "6928.606819152832\n",
      "Epoch [50/50], Batch 74/120, Train Loss: 91.0194\n",
      "7024.061981201172\n",
      "Epoch [50/50], Batch 75/120, Train Loss: 95.4552\n",
      "7110.167175292969\n",
      "Epoch [50/50], Batch 76/120, Train Loss: 86.1052\n",
      "7183.4384689331055\n",
      "Epoch [50/50], Batch 77/120, Train Loss: 73.2713\n",
      "7299.439254760742\n",
      "Epoch [50/50], Batch 78/120, Train Loss: 116.0008\n",
      "7396.474472045898\n",
      "Epoch [50/50], Batch 79/120, Train Loss: 97.0352\n",
      "7467.7989501953125\n",
      "Epoch [50/50], Batch 80/120, Train Loss: 71.3245\n",
      "7550.546646118164\n",
      "Epoch [50/50], Batch 81/120, Train Loss: 82.7477\n",
      "7632.558502197266\n",
      "Epoch [50/50], Batch 82/120, Train Loss: 82.0119\n",
      "7739.804168701172\n",
      "Epoch [50/50], Batch 83/120, Train Loss: 107.2457\n",
      "7853.622619628906\n",
      "Epoch [50/50], Batch 84/120, Train Loss: 113.8185\n",
      "7969.664886474609\n",
      "Epoch [50/50], Batch 85/120, Train Loss: 116.0423\n",
      "8042.3593673706055\n",
      "Epoch [50/50], Batch 86/120, Train Loss: 72.6945\n",
      "8145.4946212768555\n",
      "Epoch [50/50], Batch 87/120, Train Loss: 103.1353\n",
      "8235.371147155762\n",
      "Epoch [50/50], Batch 88/120, Train Loss: 89.8765\n",
      "8344.071678161621\n",
      "Epoch [50/50], Batch 89/120, Train Loss: 108.7005\n",
      "8430.115447998047\n",
      "Epoch [50/50], Batch 90/120, Train Loss: 86.0438\n",
      "8519.755462646484\n",
      "Epoch [50/50], Batch 91/120, Train Loss: 89.6400\n",
      "8598.98365020752\n",
      "Epoch [50/50], Batch 92/120, Train Loss: 79.2282\n",
      "8682.292274475098\n",
      "Epoch [50/50], Batch 93/120, Train Loss: 83.3086\n",
      "8755.858032226562\n",
      "Epoch [50/50], Batch 94/120, Train Loss: 73.5658\n",
      "8861.973129272461\n",
      "Epoch [50/50], Batch 95/120, Train Loss: 106.1151\n",
      "8957.629013061523\n",
      "Epoch [50/50], Batch 96/120, Train Loss: 95.6559\n",
      "9050.39079284668\n",
      "Epoch [50/50], Batch 97/120, Train Loss: 92.7618\n",
      "9149.600776672363\n",
      "Epoch [50/50], Batch 98/120, Train Loss: 99.2100\n",
      "9244.050582885742\n",
      "Epoch [50/50], Batch 99/120, Train Loss: 94.4498\n",
      "9337.671043395996\n",
      "Epoch [50/50], Batch 100/120, Train Loss: 93.6205\n",
      "9424.662742614746\n",
      "Epoch [50/50], Batch 101/120, Train Loss: 86.9917\n",
      "9541.229377746582\n",
      "Epoch [50/50], Batch 102/120, Train Loss: 116.5666\n",
      "9653.36710357666\n",
      "Epoch [50/50], Batch 103/120, Train Loss: 112.1377\n",
      "9749.656600952148\n",
      "Epoch [50/50], Batch 104/120, Train Loss: 96.2895\n",
      "9842.450912475586\n",
      "Epoch [50/50], Batch 105/120, Train Loss: 92.7943\n",
      "9936.02018737793\n",
      "Epoch [50/50], Batch 106/120, Train Loss: 93.5693\n",
      "10031.162200927734\n",
      "Epoch [50/50], Batch 107/120, Train Loss: 95.1420\n",
      "10143.290222167969\n",
      "Epoch [50/50], Batch 108/120, Train Loss: 112.1280\n",
      "10240.724807739258\n",
      "Epoch [50/50], Batch 109/120, Train Loss: 97.4346\n",
      "10330.623069763184\n",
      "Epoch [50/50], Batch 110/120, Train Loss: 89.8983\n",
      "10396.82048034668\n",
      "Epoch [50/50], Batch 111/120, Train Loss: 66.1974\n",
      "10506.700927734375\n",
      "Epoch [50/50], Batch 112/120, Train Loss: 109.8804\n",
      "10602.58797454834\n",
      "Epoch [50/50], Batch 113/120, Train Loss: 95.8870\n",
      "10711.653579711914\n",
      "Epoch [50/50], Batch 114/120, Train Loss: 109.0656\n",
      "10828.93775177002\n",
      "Epoch [50/50], Batch 115/120, Train Loss: 117.2842\n",
      "10914.706748962402\n",
      "Epoch [50/50], Batch 116/120, Train Loss: 85.7690\n",
      "11002.255645751953\n",
      "Epoch [50/50], Batch 117/120, Train Loss: 87.5489\n",
      "11088.024307250977\n",
      "Epoch [50/50], Batch 118/120, Train Loss: 85.7687\n",
      "11202.634956359863\n",
      "Epoch [50/50], Batch 119/120, Train Loss: 114.6106\n",
      "11299.889961242676\n",
      "Epoch [50/50], Batch 120/120, Train Loss: 97.2550\n",
      "Epoch [50/50], Train Loss: 94.1657, Validation Loss: 114.9874\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def write_accuracies(message, file_path):\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(message)\n",
    "        file.write('\\n')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch = 1\n",
    "    total_train_loss = 0\n",
    "    \n",
    "\n",
    "    # Training loop\n",
    "    for i, (images, labels) in enumerate(trainLoader):\n",
    "        # permute the image dimensions\n",
    "        number = len(images)\n",
    "        arr = [torch.tensor(i).permute(2, 0, 1) for i in images]\n",
    "        images = torch.stack(arr)\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimiser.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), torch.tensor(labels, dtype=torch.float))\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        total_train_loss += (loss.item())\n",
    "        print(total_train_loss)\n",
    "        # Memory cleanup\n",
    "        del images, labels, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        #Print progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch {batch}/{len(trainLoader)}, Train Loss: {loss.item():.4f}\")\n",
    "        batch += 1\n",
    "\n",
    "    # Calculate training accuracy and loss\n",
    "    training_loss = total_train_loss / len(trainLoader)\n",
    "    trainLoss.append(training_loss)\n",
    "\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "\n",
    "\n",
    "        for images, labels in validLoader:\n",
    "            # permute the image dimensions\n",
    "            number = len(images)\n",
    "            arr = [torch.tensor(i).permute(2, 0, 1) for i in images]\n",
    "            images = torch.stack(arr)\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "\n",
    "            total_val_loss += (criterion(outputs, labels).item())\n",
    "\n",
    "    # Calculate validation accuracy and loss\n",
    "    validation_loss = total_val_loss / len(validLoader)\n",
    "\n",
    "    validLoss.append(validation_loss)\n",
    "    \n",
    "    #Print epoch summary\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {training_loss:.4f}, Validation Loss: {validation_loss:.4f}')\n",
    "\n",
    "    #Write losses to file\n",
    "    write_accuracies(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {training_loss:.4f}, Validation Loss: {validation_loss:.4f}', \"accuracies.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6351/2806525297.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  arr = [torch.tensor(i).permute(2, 0, 1) for i in images]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss of the model on the test data: 127.6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayushraina/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for images, targets in testLoader:\n",
    "        # permute the image dimensions\n",
    "        number = len(images)\n",
    "        arr = [torch.tensor(i).permute(2, 0, 1) for i in images]\n",
    "        images = torch.stack(arr)\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets.float())  # Using the same regression loss as in training\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "\n",
    "    # Calculate average test loss\n",
    "    test_loss = total_test_loss / len(testLoader)\n",
    "\n",
    "    print('Test Loss of the model on the test data: {:.4f}'.format(test_loss))\n",
    "    write_accuracies('Test Loss of the model on the test data: {:.4f}'.format(test_loss), \"accuracies.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Generate x values\n",
    "x = list(range(1, num_epochs + 1))\n",
    "\n",
    "# Plot train and validation losses\n",
    "plt.plot(x, trainLoss, label='Train Loss', marker='o', color='b', linewidth=2)\n",
    "plt.plot(x, validLoss, label='Validation Loss', marker='s', color='r', linewidth=2)\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(validLoss)\n",
    "min_val_loss_epoch = validLoss.index(min_val_loss) + 1\n",
    "\n",
    "# Add labels to minimum validation loss point\n",
    "plt.scatter(min_val_loss_epoch, min_val_loss, color='g', s=100, label=f'Min Validation Loss: {min_val_loss:.4f}')\n",
    "plt.text(min_val_loss_epoch + 0.5, min_val_loss - 0.1, f'({min_val_loss_epoch}, {min_val_loss:.4f})', fontsize=12)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.title('Training and Validation Loss', fontsize=16)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Add grid and set grid style\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.show()\n",
    "\n",
    "# save the plot\n",
    "plt.savefig('loss_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate plot for train loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot test loss\n",
    "plt.plot(x, trainLoss, label='Test Loss', marker='o', color='b', linewidth=2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.title('Test Loss', fontsize=16)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Add grid and set grid style\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate plot for validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot validation loss\n",
    "plt.plot(x, validLoss, label='Validation Loss', marker='s', color='r', linewidth=2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "plt.title('Validation Loss', fontsize=16)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Add grid and set grid style\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
